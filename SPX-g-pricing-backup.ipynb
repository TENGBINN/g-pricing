{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPX $g$-Pricing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import statsmodels.api as sm\n",
    "from scipy import spatial, interpolate\n",
    "from matplotlib import pyplot as plt\n",
    "import mpl_toolkits.mplot3d\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward-Backward Stochastic Differential Equations\n",
    "\\begin{align}\n",
    "  &X_t = X_0 + \\int_0^t rX_s ~\\text{d}s + \\int_0^t \\sigma(s, X_s) ~\\text{d} W_s, \\\\\n",
    "  &Y_t = \\phi(X_T,K) + \\int_t^T g(s, X_s, Y_s, Z_s) ~\\text{d} s - \\int_t^T Z_s ~\\text{d} W_s. \n",
    "\\end{align}\n",
    "For _European call options_, the terminal condition $\\phi_c(X_T, K) = (X_T-K)^+$; For _European put options_, the terminal condition $\\phi_p(X_T, K) = (K - X_T)^+$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters: \n",
    "N = 16   # Time-Steps\n",
    "I = 128  # minibatch size\n",
    "M = 32   # number of trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Raw Data:\n",
    "idata = pd.read_csv(\"BS-Sample-0.15.csv\", encoding=\"utf8\")\n",
    "idata[\"mid(C)\"] = (idata[\"bid(C)\"] + idata[\"ask(C)\"]) / 2\n",
    "idata[\"mid(P)\"] = (idata[\"bid(P)\"] + idata[\"ask(P)\"]) / 2\n",
    "idata = idata[(idata[\"Y(P)\"] >= 0.01) & (idata[\"Y(C)\"] >= 0.01)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training & Validation: \n",
    "idata_train = idata[idata[\"date\"] < \"2020-12-01\"]\n",
    "idata_valid = idata[idata[\"date\"] >= \"2020-12-01\"]\n",
    "del idata_train[\"date\"]\n",
    "del idata_valid[\"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau</th>\n",
       "      <th>K</th>\n",
       "      <th>S</th>\n",
       "      <th>bid(C)</th>\n",
       "      <th>ask(C)</th>\n",
       "      <th>bid(P)</th>\n",
       "      <th>ask(P)</th>\n",
       "      <th>Y(C)</th>\n",
       "      <th>Z(C)</th>\n",
       "      <th>Y(P)</th>\n",
       "      <th>Z(P)</th>\n",
       "      <th>mid(C)</th>\n",
       "      <th>mid(P)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3060</td>\n",
       "      <td>3381</td>\n",
       "      <td>322.1</td>\n",
       "      <td>325.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>323.526381</td>\n",
       "      <td>506.923900</td>\n",
       "      <td>0.012095</td>\n",
       "      <td>-0.226100</td>\n",
       "      <td>324.00</td>\n",
       "      <td>5.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3065</td>\n",
       "      <td>3381</td>\n",
       "      <td>316.8</td>\n",
       "      <td>321.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>318.533224</td>\n",
       "      <td>506.876289</td>\n",
       "      <td>0.014829</td>\n",
       "      <td>-0.273711</td>\n",
       "      <td>318.95</td>\n",
       "      <td>5.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3070</td>\n",
       "      <td>3381</td>\n",
       "      <td>312.1</td>\n",
       "      <td>316.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>313.540632</td>\n",
       "      <td>506.819647</td>\n",
       "      <td>0.018129</td>\n",
       "      <td>-0.330353</td>\n",
       "      <td>314.10</td>\n",
       "      <td>6.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3075</td>\n",
       "      <td>3381</td>\n",
       "      <td>307.3</td>\n",
       "      <td>311.6</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>308.548711</td>\n",
       "      <td>506.752473</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>-0.397527</td>\n",
       "      <td>309.45</td>\n",
       "      <td>6.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3080</td>\n",
       "      <td>3381</td>\n",
       "      <td>302.6</td>\n",
       "      <td>306.9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.8</td>\n",
       "      <td>303.557583</td>\n",
       "      <td>506.673059</td>\n",
       "      <td>0.026863</td>\n",
       "      <td>-0.476941</td>\n",
       "      <td>304.75</td>\n",
       "      <td>6.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3085</td>\n",
       "      <td>3381</td>\n",
       "      <td>297.8</td>\n",
       "      <td>302.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>7.1</td>\n",
       "      <td>298.567389</td>\n",
       "      <td>506.579465</td>\n",
       "      <td>0.032561</td>\n",
       "      <td>-0.570535</td>\n",
       "      <td>300.00</td>\n",
       "      <td>6.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3090</td>\n",
       "      <td>3381</td>\n",
       "      <td>293.6</td>\n",
       "      <td>297.4</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>293.578292</td>\n",
       "      <td>506.469505</td>\n",
       "      <td>0.039356</td>\n",
       "      <td>-0.680495</td>\n",
       "      <td>295.50</td>\n",
       "      <td>7.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3095</td>\n",
       "      <td>3381</td>\n",
       "      <td>288.9</td>\n",
       "      <td>292.5</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>288.590481</td>\n",
       "      <td>506.340713</td>\n",
       "      <td>0.047437</td>\n",
       "      <td>-0.809287</td>\n",
       "      <td>290.70</td>\n",
       "      <td>7.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3100</td>\n",
       "      <td>3381</td>\n",
       "      <td>283.7</td>\n",
       "      <td>287.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.9</td>\n",
       "      <td>283.604171</td>\n",
       "      <td>506.190330</td>\n",
       "      <td>0.057018</td>\n",
       "      <td>-0.959670</td>\n",
       "      <td>285.70</td>\n",
       "      <td>7.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3105</td>\n",
       "      <td>3381</td>\n",
       "      <td>279.5</td>\n",
       "      <td>283.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>278.619608</td>\n",
       "      <td>506.015272</td>\n",
       "      <td>0.068346</td>\n",
       "      <td>-1.134728</td>\n",
       "      <td>281.30</td>\n",
       "      <td>8.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3110</td>\n",
       "      <td>3381</td>\n",
       "      <td>274.8</td>\n",
       "      <td>278.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.6</td>\n",
       "      <td>273.637071</td>\n",
       "      <td>505.812112</td>\n",
       "      <td>0.081701</td>\n",
       "      <td>-1.337888</td>\n",
       "      <td>276.70</td>\n",
       "      <td>8.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3115</td>\n",
       "      <td>3381</td>\n",
       "      <td>269.7</td>\n",
       "      <td>273.9</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>268.656879</td>\n",
       "      <td>505.577052</td>\n",
       "      <td>0.097401</td>\n",
       "      <td>-1.572948</td>\n",
       "      <td>271.80</td>\n",
       "      <td>8.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3120</td>\n",
       "      <td>3381</td>\n",
       "      <td>265.5</td>\n",
       "      <td>269.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>263.679391</td>\n",
       "      <td>505.305906</td>\n",
       "      <td>0.115805</td>\n",
       "      <td>-1.844094</td>\n",
       "      <td>267.30</td>\n",
       "      <td>9.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3125</td>\n",
       "      <td>3381</td>\n",
       "      <td>260.4</td>\n",
       "      <td>264.6</td>\n",
       "      <td>9.4</td>\n",
       "      <td>9.7</td>\n",
       "      <td>258.705014</td>\n",
       "      <td>504.994071</td>\n",
       "      <td>0.137319</td>\n",
       "      <td>-2.155929</td>\n",
       "      <td>262.50</td>\n",
       "      <td>9.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3130</td>\n",
       "      <td>3381</td>\n",
       "      <td>255.8</td>\n",
       "      <td>260.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>253.734201</td>\n",
       "      <td>504.636515</td>\n",
       "      <td>0.162398</td>\n",
       "      <td>-2.513485</td>\n",
       "      <td>257.90</td>\n",
       "      <td>9.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3135</td>\n",
       "      <td>3381</td>\n",
       "      <td>251.2</td>\n",
       "      <td>255.4</td>\n",
       "      <td>10.1</td>\n",
       "      <td>10.4</td>\n",
       "      <td>248.767464</td>\n",
       "      <td>504.227753</td>\n",
       "      <td>0.191553</td>\n",
       "      <td>-2.922247</td>\n",
       "      <td>253.30</td>\n",
       "      <td>10.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3140</td>\n",
       "      <td>3381</td>\n",
       "      <td>246.6</td>\n",
       "      <td>250.8</td>\n",
       "      <td>10.5</td>\n",
       "      <td>10.9</td>\n",
       "      <td>243.805371</td>\n",
       "      <td>503.761835</td>\n",
       "      <td>0.225352</td>\n",
       "      <td>-3.388165</td>\n",
       "      <td>248.70</td>\n",
       "      <td>10.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3145</td>\n",
       "      <td>3381</td>\n",
       "      <td>242.1</td>\n",
       "      <td>246.3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>238.848556</td>\n",
       "      <td>503.232335</td>\n",
       "      <td>0.264428</td>\n",
       "      <td>-3.917665</td>\n",
       "      <td>244.20</td>\n",
       "      <td>11.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3150</td>\n",
       "      <td>3381</td>\n",
       "      <td>237.5</td>\n",
       "      <td>241.7</td>\n",
       "      <td>11.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>233.897720</td>\n",
       "      <td>502.632341</td>\n",
       "      <td>0.309484</td>\n",
       "      <td>-4.517659</td>\n",
       "      <td>239.60</td>\n",
       "      <td>11.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3155</td>\n",
       "      <td>3381</td>\n",
       "      <td>233.0</td>\n",
       "      <td>237.2</td>\n",
       "      <td>11.9</td>\n",
       "      <td>12.2</td>\n",
       "      <td>228.953638</td>\n",
       "      <td>501.954455</td>\n",
       "      <td>0.361294</td>\n",
       "      <td>-5.195545</td>\n",
       "      <td>235.10</td>\n",
       "      <td>12.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3160</td>\n",
       "      <td>3381</td>\n",
       "      <td>228.5</td>\n",
       "      <td>232.6</td>\n",
       "      <td>12.4</td>\n",
       "      <td>12.7</td>\n",
       "      <td>224.017164</td>\n",
       "      <td>501.190788</td>\n",
       "      <td>0.420711</td>\n",
       "      <td>-5.959212</td>\n",
       "      <td>230.55</td>\n",
       "      <td>12.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3165</td>\n",
       "      <td>3381</td>\n",
       "      <td>224.4</td>\n",
       "      <td>228.1</td>\n",
       "      <td>12.8</td>\n",
       "      <td>13.2</td>\n",
       "      <td>219.089234</td>\n",
       "      <td>500.332977</td>\n",
       "      <td>0.488673</td>\n",
       "      <td>-6.817023</td>\n",
       "      <td>226.25</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3170</td>\n",
       "      <td>3381</td>\n",
       "      <td>219.9</td>\n",
       "      <td>223.6</td>\n",
       "      <td>13.3</td>\n",
       "      <td>13.7</td>\n",
       "      <td>214.170873</td>\n",
       "      <td>499.372189</td>\n",
       "      <td>0.566203</td>\n",
       "      <td>-7.777811</td>\n",
       "      <td>221.75</td>\n",
       "      <td>13.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3175</td>\n",
       "      <td>3381</td>\n",
       "      <td>215.0</td>\n",
       "      <td>219.1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>14.2</td>\n",
       "      <td>209.263196</td>\n",
       "      <td>498.299146</td>\n",
       "      <td>0.654418</td>\n",
       "      <td>-8.850854</td>\n",
       "      <td>217.05</td>\n",
       "      <td>14.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3180</td>\n",
       "      <td>3381</td>\n",
       "      <td>210.5</td>\n",
       "      <td>214.7</td>\n",
       "      <td>14.4</td>\n",
       "      <td>14.8</td>\n",
       "      <td>204.367416</td>\n",
       "      <td>497.104154</td>\n",
       "      <td>0.754530</td>\n",
       "      <td>-10.045846</td>\n",
       "      <td>212.60</td>\n",
       "      <td>14.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3185</td>\n",
       "      <td>3381</td>\n",
       "      <td>206.1</td>\n",
       "      <td>210.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>199.484844</td>\n",
       "      <td>495.777131</td>\n",
       "      <td>0.867850</td>\n",
       "      <td>-11.372869</td>\n",
       "      <td>208.15</td>\n",
       "      <td>15.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3190</td>\n",
       "      <td>3381</td>\n",
       "      <td>202.1</td>\n",
       "      <td>205.8</td>\n",
       "      <td>15.6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>194.616897</td>\n",
       "      <td>494.307656</td>\n",
       "      <td>0.995795</td>\n",
       "      <td>-12.842344</td>\n",
       "      <td>203.95</td>\n",
       "      <td>15.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3195</td>\n",
       "      <td>3381</td>\n",
       "      <td>197.3</td>\n",
       "      <td>201.4</td>\n",
       "      <td>16.2</td>\n",
       "      <td>16.6</td>\n",
       "      <td>189.765095</td>\n",
       "      <td>492.685016</td>\n",
       "      <td>1.139884</td>\n",
       "      <td>-14.464984</td>\n",
       "      <td>199.35</td>\n",
       "      <td>16.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3200</td>\n",
       "      <td>3381</td>\n",
       "      <td>193.5</td>\n",
       "      <td>196.9</td>\n",
       "      <td>16.8</td>\n",
       "      <td>17.2</td>\n",
       "      <td>184.931068</td>\n",
       "      <td>490.898265</td>\n",
       "      <td>1.301749</td>\n",
       "      <td>-16.251735</td>\n",
       "      <td>195.20</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>3205</td>\n",
       "      <td>3381</td>\n",
       "      <td>188.7</td>\n",
       "      <td>192.7</td>\n",
       "      <td>17.5</td>\n",
       "      <td>17.9</td>\n",
       "      <td>180.116556</td>\n",
       "      <td>488.936290</td>\n",
       "      <td>1.483128</td>\n",
       "      <td>-18.213710</td>\n",
       "      <td>190.70</td>\n",
       "      <td>17.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107226</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>3850</td>\n",
       "      <td>3622</td>\n",
       "      <td>258.9</td>\n",
       "      <td>271.0</td>\n",
       "      <td>565.1</td>\n",
       "      <td>575.5</td>\n",
       "      <td>276.917442</td>\n",
       "      <td>274.508363</td>\n",
       "      <td>350.703060</td>\n",
       "      <td>-268.791637</td>\n",
       "      <td>264.95</td>\n",
       "      <td>570.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107227</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>3875</td>\n",
       "      <td>3622</td>\n",
       "      <td>247.9</td>\n",
       "      <td>259.8</td>\n",
       "      <td>578.8</td>\n",
       "      <td>589.2</td>\n",
       "      <td>266.973566</td>\n",
       "      <td>267.966915</td>\n",
       "      <td>364.757792</td>\n",
       "      <td>-275.333085</td>\n",
       "      <td>253.85</td>\n",
       "      <td>584.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107228</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>3900</td>\n",
       "      <td>3622</td>\n",
       "      <td>237.1</td>\n",
       "      <td>249.0</td>\n",
       "      <td>592.8</td>\n",
       "      <td>603.1</td>\n",
       "      <td>257.310091</td>\n",
       "      <td>261.470845</td>\n",
       "      <td>379.092924</td>\n",
       "      <td>-281.829155</td>\n",
       "      <td>243.05</td>\n",
       "      <td>597.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107229</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>3925</td>\n",
       "      <td>3622</td>\n",
       "      <td>226.7</td>\n",
       "      <td>238.5</td>\n",
       "      <td>607.1</td>\n",
       "      <td>617.4</td>\n",
       "      <td>247.923167</td>\n",
       "      <td>255.025328</td>\n",
       "      <td>393.704609</td>\n",
       "      <td>-288.274672</td>\n",
       "      <td>232.60</td>\n",
       "      <td>612.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107230</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>3950</td>\n",
       "      <td>3622</td>\n",
       "      <td>216.6</td>\n",
       "      <td>228.3</td>\n",
       "      <td>621.7</td>\n",
       "      <td>632.0</td>\n",
       "      <td>238.808781</td>\n",
       "      <td>248.635311</td>\n",
       "      <td>408.588831</td>\n",
       "      <td>-294.664689</td>\n",
       "      <td>222.45</td>\n",
       "      <td>626.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107231</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>3975</td>\n",
       "      <td>3622</td>\n",
       "      <td>206.8</td>\n",
       "      <td>218.5</td>\n",
       "      <td>636.6</td>\n",
       "      <td>646.9</td>\n",
       "      <td>229.962767</td>\n",
       "      <td>242.305501</td>\n",
       "      <td>423.741425</td>\n",
       "      <td>-300.994499</td>\n",
       "      <td>212.65</td>\n",
       "      <td>641.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107232</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>4000</td>\n",
       "      <td>3622</td>\n",
       "      <td>199.8</td>\n",
       "      <td>208.9</td>\n",
       "      <td>651.8</td>\n",
       "      <td>662.1</td>\n",
       "      <td>221.380818</td>\n",
       "      <td>236.040366</td>\n",
       "      <td>439.158083</td>\n",
       "      <td>-307.259634</td>\n",
       "      <td>204.35</td>\n",
       "      <td>656.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107233</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>4025</td>\n",
       "      <td>3622</td>\n",
       "      <td>188.2</td>\n",
       "      <td>199.6</td>\n",
       "      <td>667.4</td>\n",
       "      <td>677.7</td>\n",
       "      <td>213.058499</td>\n",
       "      <td>229.844129</td>\n",
       "      <td>454.834372</td>\n",
       "      <td>-313.455871</td>\n",
       "      <td>193.90</td>\n",
       "      <td>672.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107234</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>4050</td>\n",
       "      <td>3622</td>\n",
       "      <td>179.4</td>\n",
       "      <td>190.7</td>\n",
       "      <td>683.3</td>\n",
       "      <td>693.5</td>\n",
       "      <td>204.991262</td>\n",
       "      <td>223.720766</td>\n",
       "      <td>470.765744</td>\n",
       "      <td>-319.579234</td>\n",
       "      <td>185.05</td>\n",
       "      <td>688.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107235</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>4075</td>\n",
       "      <td>3622</td>\n",
       "      <td>170.9</td>\n",
       "      <td>182.1</td>\n",
       "      <td>699.5</td>\n",
       "      <td>709.7</td>\n",
       "      <td>197.174457</td>\n",
       "      <td>217.674005</td>\n",
       "      <td>486.947546</td>\n",
       "      <td>-325.625995</td>\n",
       "      <td>176.50</td>\n",
       "      <td>704.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107236</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>4100</td>\n",
       "      <td>3622</td>\n",
       "      <td>162.8</td>\n",
       "      <td>173.9</td>\n",
       "      <td>716.1</td>\n",
       "      <td>726.2</td>\n",
       "      <td>189.603342</td>\n",
       "      <td>211.707326</td>\n",
       "      <td>503.375039</td>\n",
       "      <td>-331.592674</td>\n",
       "      <td>168.35</td>\n",
       "      <td>721.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107237</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>4125</td>\n",
       "      <td>3622</td>\n",
       "      <td>154.9</td>\n",
       "      <td>165.9</td>\n",
       "      <td>732.9</td>\n",
       "      <td>743.0</td>\n",
       "      <td>182.273097</td>\n",
       "      <td>205.823964</td>\n",
       "      <td>520.043402</td>\n",
       "      <td>-337.476036</td>\n",
       "      <td>160.40</td>\n",
       "      <td>737.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107238</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>4150</td>\n",
       "      <td>3622</td>\n",
       "      <td>147.4</td>\n",
       "      <td>158.3</td>\n",
       "      <td>750.1</td>\n",
       "      <td>760.2</td>\n",
       "      <td>175.178834</td>\n",
       "      <td>200.026906</td>\n",
       "      <td>536.947747</td>\n",
       "      <td>-343.273094</td>\n",
       "      <td>152.85</td>\n",
       "      <td>755.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107239</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>4175</td>\n",
       "      <td>3622</td>\n",
       "      <td>140.2</td>\n",
       "      <td>151.0</td>\n",
       "      <td>767.7</td>\n",
       "      <td>777.6</td>\n",
       "      <td>168.315611</td>\n",
       "      <td>194.318897</td>\n",
       "      <td>554.083132</td>\n",
       "      <td>-348.981103</td>\n",
       "      <td>145.60</td>\n",
       "      <td>772.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107240</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>4200</td>\n",
       "      <td>3622</td>\n",
       "      <td>133.4</td>\n",
       "      <td>143.9</td>\n",
       "      <td>785.5</td>\n",
       "      <td>795.4</td>\n",
       "      <td>161.678438</td>\n",
       "      <td>188.702442</td>\n",
       "      <td>571.444566</td>\n",
       "      <td>-354.597558</td>\n",
       "      <td>138.65</td>\n",
       "      <td>790.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107241</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>4300</td>\n",
       "      <td>3622</td>\n",
       "      <td>108.9</td>\n",
       "      <td>118.9</td>\n",
       "      <td>859.9</td>\n",
       "      <td>869.5</td>\n",
       "      <td>137.289433</td>\n",
       "      <td>167.194083</td>\n",
       "      <td>643.049993</td>\n",
       "      <td>-376.105917</td>\n",
       "      <td>113.90</td>\n",
       "      <td>864.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107242</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>4400</td>\n",
       "      <td>3622</td>\n",
       "      <td>89.0</td>\n",
       "      <td>98.4</td>\n",
       "      <td>922.1</td>\n",
       "      <td>962.8</td>\n",
       "      <td>116.112878</td>\n",
       "      <td>147.291613</td>\n",
       "      <td>717.867870</td>\n",
       "      <td>-396.008387</td>\n",
       "      <td>93.70</td>\n",
       "      <td>942.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107243</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>4500</td>\n",
       "      <td>3622</td>\n",
       "      <td>72.9</td>\n",
       "      <td>81.8</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>97.827550</td>\n",
       "      <td>129.051021</td>\n",
       "      <td>795.576973</td>\n",
       "      <td>-414.248979</td>\n",
       "      <td>77.35</td>\n",
       "      <td>1025.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107244</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>4600</td>\n",
       "      <td>3622</td>\n",
       "      <td>60.1</td>\n",
       "      <td>68.5</td>\n",
       "      <td>1086.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>82.121704</td>\n",
       "      <td>112.482018</td>\n",
       "      <td>875.865559</td>\n",
       "      <td>-430.817982</td>\n",
       "      <td>64.30</td>\n",
       "      <td>1112.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107245</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>4700</td>\n",
       "      <td>3622</td>\n",
       "      <td>50.0</td>\n",
       "      <td>57.8</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>68.698612</td>\n",
       "      <td>97.555829</td>\n",
       "      <td>958.436899</td>\n",
       "      <td>-445.744171</td>\n",
       "      <td>53.90</td>\n",
       "      <td>1201.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107246</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>4800</td>\n",
       "      <td>3622</td>\n",
       "      <td>42.2</td>\n",
       "      <td>49.3</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>1318.0</td>\n",
       "      <td>57.280503</td>\n",
       "      <td>84.213094</td>\n",
       "      <td>1043.013221</td>\n",
       "      <td>-459.086906</td>\n",
       "      <td>45.75</td>\n",
       "      <td>1291.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107247</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>4900</td>\n",
       "      <td>3622</td>\n",
       "      <td>35.9</td>\n",
       "      <td>42.6</td>\n",
       "      <td>1357.0</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>47.611100</td>\n",
       "      <td>72.371429</td>\n",
       "      <td>1129.338250</td>\n",
       "      <td>-470.928571</td>\n",
       "      <td>39.25</td>\n",
       "      <td>1383.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107248</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>5000</td>\n",
       "      <td>3622</td>\n",
       "      <td>30.9</td>\n",
       "      <td>37.2</td>\n",
       "      <td>1451.0</td>\n",
       "      <td>1504.0</td>\n",
       "      <td>39.456966</td>\n",
       "      <td>61.932307</td>\n",
       "      <td>1217.178548</td>\n",
       "      <td>-481.367693</td>\n",
       "      <td>34.05</td>\n",
       "      <td>1477.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107249</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>5100</td>\n",
       "      <td>3622</td>\n",
       "      <td>26.9</td>\n",
       "      <td>29.5</td>\n",
       "      <td>1546.0</td>\n",
       "      <td>1597.0</td>\n",
       "      <td>32.607872</td>\n",
       "      <td>52.787097</td>\n",
       "      <td>1306.323886</td>\n",
       "      <td>-490.512903</td>\n",
       "      <td>28.20</td>\n",
       "      <td>1571.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107250</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>5200</td>\n",
       "      <td>3622</td>\n",
       "      <td>23.5</td>\n",
       "      <td>26.1</td>\n",
       "      <td>1641.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>26.876415</td>\n",
       "      <td>44.822156</td>\n",
       "      <td>1396.586860</td>\n",
       "      <td>-498.477844</td>\n",
       "      <td>24.80</td>\n",
       "      <td>1666.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107251</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>5300</td>\n",
       "      <td>3622</td>\n",
       "      <td>20.8</td>\n",
       "      <td>23.1</td>\n",
       "      <td>1738.0</td>\n",
       "      <td>1788.0</td>\n",
       "      <td>22.097067</td>\n",
       "      <td>37.922964</td>\n",
       "      <td>1487.801943</td>\n",
       "      <td>-505.377036</td>\n",
       "      <td>21.95</td>\n",
       "      <td>1763.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107252</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>5400</td>\n",
       "      <td>3622</td>\n",
       "      <td>18.4</td>\n",
       "      <td>20.8</td>\n",
       "      <td>1834.0</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>18.124838</td>\n",
       "      <td>31.977359</td>\n",
       "      <td>1579.824146</td>\n",
       "      <td>-511.322641</td>\n",
       "      <td>19.60</td>\n",
       "      <td>1859.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107253</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>5500</td>\n",
       "      <td>3622</td>\n",
       "      <td>16.3</td>\n",
       "      <td>18.7</td>\n",
       "      <td>1931.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>14.833688</td>\n",
       "      <td>26.877945</td>\n",
       "      <td>1672.527428</td>\n",
       "      <td>-516.422055</td>\n",
       "      <td>17.50</td>\n",
       "      <td>1955.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107254</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>5700</td>\n",
       "      <td>3622</td>\n",
       "      <td>12.9</td>\n",
       "      <td>15.4</td>\n",
       "      <td>2126.0</td>\n",
       "      <td>2173.0</td>\n",
       "      <td>9.874844</td>\n",
       "      <td>18.821439</td>\n",
       "      <td>1859.557447</td>\n",
       "      <td>-524.478561</td>\n",
       "      <td>14.15</td>\n",
       "      <td>2149.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107255</th>\n",
       "      <td>2.0440</td>\n",
       "      <td>6000</td>\n",
       "      <td>3622</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>2420.0</td>\n",
       "      <td>2466.0</td>\n",
       "      <td>5.291252</td>\n",
       "      <td>10.813861</td>\n",
       "      <td>2142.957150</td>\n",
       "      <td>-532.486139</td>\n",
       "      <td>10.20</td>\n",
       "      <td>2443.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68901 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           tau     K     S  bid(C)  ask(C)  bid(P)  ask(P)        Y(C)  \\\n",
       "200     0.0411  3060  3381   322.1   325.9     5.6     5.8  323.526381   \n",
       "201     0.0411  3065  3381   316.8   321.1     5.8     6.1  318.533224   \n",
       "202     0.0411  3070  3381   312.1   316.1     6.0     6.3  313.540632   \n",
       "203     0.0411  3075  3381   307.3   311.6     6.3     6.5  308.548711   \n",
       "204     0.0411  3080  3381   302.6   306.9     6.5     6.8  303.557583   \n",
       "205     0.0411  3085  3381   297.8   302.2     6.8     7.1  298.567389   \n",
       "206     0.0411  3090  3381   293.6   297.4     7.1     7.3  293.578292   \n",
       "207     0.0411  3095  3381   288.9   292.5     7.4     7.6  288.590481   \n",
       "208     0.0411  3100  3381   283.7   287.7     7.7     7.9  283.604171   \n",
       "209     0.0411  3105  3381   279.5   283.1     8.0     8.3  278.619608   \n",
       "210     0.0411  3110  3381   274.8   278.6     8.3     8.6  273.637071   \n",
       "211     0.0411  3115  3381   269.7   273.9     8.6     8.9  268.656879   \n",
       "212     0.0411  3120  3381   265.5   269.1     9.0     9.3  263.679391   \n",
       "213     0.0411  3125  3381   260.4   264.6     9.4     9.7  258.705014   \n",
       "214     0.0411  3130  3381   255.8   260.0     9.7    10.0  253.734201   \n",
       "215     0.0411  3135  3381   251.2   255.4    10.1    10.4  248.767464   \n",
       "216     0.0411  3140  3381   246.6   250.8    10.5    10.9  243.805371   \n",
       "217     0.0411  3145  3381   242.1   246.3    11.0    11.3  238.848556   \n",
       "218     0.0411  3150  3381   237.5   241.7    11.4    11.7  233.897720   \n",
       "219     0.0411  3155  3381   233.0   237.2    11.9    12.2  228.953638   \n",
       "220     0.0411  3160  3381   228.5   232.6    12.4    12.7  224.017164   \n",
       "221     0.0411  3165  3381   224.4   228.1    12.8    13.2  219.089234   \n",
       "222     0.0411  3170  3381   219.9   223.6    13.3    13.7  214.170873   \n",
       "223     0.0411  3175  3381   215.0   219.1    13.9    14.2  209.263196   \n",
       "224     0.0411  3180  3381   210.5   214.7    14.4    14.8  204.367416   \n",
       "225     0.0411  3185  3381   206.1   210.2    15.0    15.4  199.484844   \n",
       "226     0.0411  3190  3381   202.1   205.8    15.6    16.0  194.616897   \n",
       "227     0.0411  3195  3381   197.3   201.4    16.2    16.6  189.765095   \n",
       "228     0.0411  3200  3381   193.5   196.9    16.8    17.2  184.931068   \n",
       "229     0.0411  3205  3381   188.7   192.7    17.5    17.9  180.116556   \n",
       "...        ...   ...   ...     ...     ...     ...     ...         ...   \n",
       "107226  2.0440  3850  3622   258.9   271.0   565.1   575.5  276.917442   \n",
       "107227  2.0440  3875  3622   247.9   259.8   578.8   589.2  266.973566   \n",
       "107228  2.0440  3900  3622   237.1   249.0   592.8   603.1  257.310091   \n",
       "107229  2.0440  3925  3622   226.7   238.5   607.1   617.4  247.923167   \n",
       "107230  2.0440  3950  3622   216.6   228.3   621.7   632.0  238.808781   \n",
       "107231  2.0440  3975  3622   206.8   218.5   636.6   646.9  229.962767   \n",
       "107232  2.0440  4000  3622   199.8   208.9   651.8   662.1  221.380818   \n",
       "107233  2.0440  4025  3622   188.2   199.6   667.4   677.7  213.058499   \n",
       "107234  2.0440  4050  3622   179.4   190.7   683.3   693.5  204.991262   \n",
       "107235  2.0440  4075  3622   170.9   182.1   699.5   709.7  197.174457   \n",
       "107236  2.0440  4100  3622   162.8   173.9   716.1   726.2  189.603342   \n",
       "107237  2.0440  4125  3622   154.9   165.9   732.9   743.0  182.273097   \n",
       "107238  2.0440  4150  3622   147.4   158.3   750.1   760.2  175.178834   \n",
       "107239  2.0440  4175  3622   140.2   151.0   767.7   777.6  168.315611   \n",
       "107240  2.0440  4200  3622   133.4   143.9   785.5   795.4  161.678438   \n",
       "107241  2.0440  4300  3622   108.9   118.9   859.9   869.5  137.289433   \n",
       "107242  2.0440  4400  3622    89.0    98.4   922.1   962.8  116.112878   \n",
       "107243  2.0440  4500  3622    72.9    81.8  1005.0  1046.0   97.827550   \n",
       "107244  2.0440  4600  3622    60.1    68.5  1086.0  1138.0   82.121704   \n",
       "107245  2.0440  4700  3622    50.0    57.8  1175.0  1227.0   68.698612   \n",
       "107246  2.0440  4800  3622    42.2    49.3  1265.0  1318.0   57.280503   \n",
       "107247  2.0440  4900  3622    35.9    42.6  1357.0  1410.0   47.611100   \n",
       "107248  2.0440  5000  3622    30.9    37.2  1451.0  1504.0   39.456966   \n",
       "107249  2.0440  5100  3622    26.9    29.5  1546.0  1597.0   32.607872   \n",
       "107250  2.0440  5200  3622    23.5    26.1  1641.0  1692.0   26.876415   \n",
       "107251  2.0440  5300  3622    20.8    23.1  1738.0  1788.0   22.097067   \n",
       "107252  2.0440  5400  3622    18.4    20.8  1834.0  1884.0   18.124838   \n",
       "107253  2.0440  5500  3622    16.3    18.7  1931.0  1980.0   14.833688   \n",
       "107254  2.0440  5700  3622    12.9    15.4  2126.0  2173.0    9.874844   \n",
       "107255  2.0440  6000  3622     9.0    11.4  2420.0  2466.0    5.291252   \n",
       "\n",
       "              Z(C)         Y(P)        Z(P)  mid(C)   mid(P)  \n",
       "200     506.923900     0.012095   -0.226100  324.00     5.70  \n",
       "201     506.876289     0.014829   -0.273711  318.95     5.95  \n",
       "202     506.819647     0.018129   -0.330353  314.10     6.15  \n",
       "203     506.752473     0.022100   -0.397527  309.45     6.40  \n",
       "204     506.673059     0.026863   -0.476941  304.75     6.65  \n",
       "205     506.579465     0.032561   -0.570535  300.00     6.95  \n",
       "206     506.469505     0.039356   -0.680495  295.50     7.20  \n",
       "207     506.340713     0.047437   -0.809287  290.70     7.50  \n",
       "208     506.190330     0.057018   -0.959670  285.70     7.80  \n",
       "209     506.015272     0.068346   -1.134728  281.30     8.15  \n",
       "210     505.812112     0.081701   -1.337888  276.70     8.45  \n",
       "211     505.577052     0.097401   -1.572948  271.80     8.75  \n",
       "212     505.305906     0.115805   -1.844094  267.30     9.15  \n",
       "213     504.994071     0.137319   -2.155929  262.50     9.55  \n",
       "214     504.636515     0.162398   -2.513485  257.90     9.85  \n",
       "215     504.227753     0.191553   -2.922247  253.30    10.25  \n",
       "216     503.761835     0.225352   -3.388165  248.70    10.70  \n",
       "217     503.232335     0.264428   -3.917665  244.20    11.15  \n",
       "218     502.632341     0.309484   -4.517659  239.60    11.55  \n",
       "219     501.954455     0.361294   -5.195545  235.10    12.05  \n",
       "220     501.190788     0.420711   -5.959212  230.55    12.55  \n",
       "221     500.332977     0.488673   -6.817023  226.25    13.00  \n",
       "222     499.372189     0.566203   -7.777811  221.75    13.50  \n",
       "223     498.299146     0.654418   -8.850854  217.05    14.05  \n",
       "224     497.104154     0.754530  -10.045846  212.60    14.60  \n",
       "225     495.777131     0.867850  -11.372869  208.15    15.20  \n",
       "226     494.307656     0.995795  -12.842344  203.95    15.80  \n",
       "227     492.685016     1.139884  -14.464984  199.35    16.40  \n",
       "228     490.898265     1.301749  -16.251735  195.20    17.00  \n",
       "229     488.936290     1.483128  -18.213710  190.70    17.70  \n",
       "...            ...          ...         ...     ...      ...  \n",
       "107226  274.508363   350.703060 -268.791637  264.95   570.30  \n",
       "107227  267.966915   364.757792 -275.333085  253.85   584.00  \n",
       "107228  261.470845   379.092924 -281.829155  243.05   597.95  \n",
       "107229  255.025328   393.704609 -288.274672  232.60   612.25  \n",
       "107230  248.635311   408.588831 -294.664689  222.45   626.85  \n",
       "107231  242.305501   423.741425 -300.994499  212.65   641.75  \n",
       "107232  236.040366   439.158083 -307.259634  204.35   656.95  \n",
       "107233  229.844129   454.834372 -313.455871  193.90   672.55  \n",
       "107234  223.720766   470.765744 -319.579234  185.05   688.40  \n",
       "107235  217.674005   486.947546 -325.625995  176.50   704.60  \n",
       "107236  211.707326   503.375039 -331.592674  168.35   721.15  \n",
       "107237  205.823964   520.043402 -337.476036  160.40   737.95  \n",
       "107238  200.026906   536.947747 -343.273094  152.85   755.15  \n",
       "107239  194.318897   554.083132 -348.981103  145.60   772.65  \n",
       "107240  188.702442   571.444566 -354.597558  138.65   790.45  \n",
       "107241  167.194083   643.049993 -376.105917  113.90   864.70  \n",
       "107242  147.291613   717.867870 -396.008387   93.70   942.45  \n",
       "107243  129.051021   795.576973 -414.248979   77.35  1025.50  \n",
       "107244  112.482018   875.865559 -430.817982   64.30  1112.00  \n",
       "107245   97.555829   958.436899 -445.744171   53.90  1201.00  \n",
       "107246   84.213094  1043.013221 -459.086906   45.75  1291.50  \n",
       "107247   72.371429  1129.338250 -470.928571   39.25  1383.50  \n",
       "107248   61.932307  1217.178548 -481.367693   34.05  1477.50  \n",
       "107249   52.787097  1306.323886 -490.512903   28.20  1571.50  \n",
       "107250   44.822156  1396.586860 -498.477844   24.80  1666.50  \n",
       "107251   37.922964  1487.801943 -505.377036   21.95  1763.00  \n",
       "107252   31.977359  1579.824146 -511.322641   19.60  1859.00  \n",
       "107253   26.877945  1672.527428 -516.422055   17.50  1955.50  \n",
       "107254   18.821439  1859.557447 -524.478561   14.15  2149.50  \n",
       "107255   10.813861  2142.957150 -532.486139   10.20  2443.00  \n",
       "\n",
       "[68901 rows x 13 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idata_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense(name, prev_layer, num_units, is_training, reuse=False):\n",
    "    layer = tf.layers.dense(prev_layer, num_units, use_bias=True, activation=\"relu\", name=name, reuse=reuse)\n",
    "    return layer\n",
    "\n",
    "def dense_batch_norm(name, prev_layer, num_units, is_training, reuse=False):\n",
    "    layer = tf.layers.dense(prev_layer, num_units, use_bias=False, activation=None, name=name+\"-dense\", reuse=reuse) # , kernel_initializer=tf.initializers.variance_scaling()\n",
    "    layer = tf.layers.batch_normalization(layer, training=is_training, name=name+\"-batchnorm\", reuse=reuse)\n",
    "    layer = tf.nn.tanh(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Network: \n",
    "def network_sigma(_t, _Xt): \n",
    "    return 0.25 * tf.pow(_Xt, - 0.05 + 1.)\n",
    "\n",
    "def network_g(_t, _Xt, _Yt, _Zt): \n",
    "    with tf.variable_scope(\"Lock-NET-g\", reuse=tf.AUTO_REUSE): \n",
    "        _h_t = dense(\"H-t\", tf.tile(_t,[1,M,1]), 50, is_training=is_training, reuse=tf.AUTO_REUSE)\n",
    "        _h_X = dense(\"H-X\", _Xt, 50, is_training=is_training, reuse=tf.AUTO_REUSE)\n",
    "        _h_Y = dense(\"H-Y\", _Yt, 50, is_training=is_training, reuse=tf.AUTO_REUSE)\n",
    "        _h_Z = dense(\"H-Z\", _Zt, 50, is_training=is_training, reuse=tf.AUTO_REUSE)\n",
    "        _h = tf.concat([_h_t, _h_X, _h_Y, _h_Z], axis=-1)\n",
    "        _h = dense(\"H2\", _h, 256, is_training=is_training, reuse=tf.AUTO_REUSE)\n",
    "        _h = dense(\"H3\", _h, 256, is_training=is_training, reuse=tf.AUTO_REUSE)\n",
    "        _h = dense(\"H4\", _h, 256, is_training=is_training, reuse=tf.AUTO_REUSE)\n",
    "        _h = dense(\"H5\", _h, 128, is_training=is_training, reuse=tf.AUTO_REUSE)\n",
    "        _output = tf.layers.dense(_h, units=1, activation=None, name=\"G\", reuse=tf.AUTO_REUSE)\n",
    "    return _output\n",
    "\n",
    "def network_Z(typ, _t, _Xt, _K, _T): \n",
    "    with tf.variable_scope(\"Lock-%s-NET-Z\"%typ, reuse=tf.AUTO_REUSE): \n",
    "        _h_t = dense(\"H-t\", tf.tile(_t,[1,M,1]), 50, is_training=is_training, reuse=tf.AUTO_REUSE)\n",
    "        _h_X = dense(\"H-X\", _Xt, 50, is_training=is_training, reuse=tf.AUTO_REUSE)\n",
    "        _h_K = dense(\"H-K\", tf.tile(_K,[1,M,1]), 50, is_training=is_training, reuse=tf.AUTO_REUSE)\n",
    "        _h_T = dense(\"H-T\", tf.tile(_T,[1,M,1]), 50, is_training=is_training, reuse=tf.AUTO_REUSE)\n",
    "        _h = tf.concat([_h_t, _h_X, _h_K, _h_T], axis=-1)\n",
    "        _h = dense(\"H2\", _h, 256, is_training=is_training, reuse=tf.AUTO_REUSE)\n",
    "        _h = dense(\"H3\", _h, 256, is_training=is_training, reuse=tf.AUTO_REUSE)\n",
    "        _h = dense(\"H4\", _h, 256, is_training=is_training, reuse=tf.AUTO_REUSE)\n",
    "        _h = dense(\"H5\", _h, 128, is_training=is_training, reuse=tf.AUTO_REUSE)\n",
    "        _output = tf.layers.dense(_h, units=1, activation=None, name=\"Z\", reuse=tf.AUTO_REUSE)\n",
    "    return _output\n",
    "\n",
    "def network_U(typ, _t, _Xt, _K, _T): \n",
    "    with tf.variable_scope(\"Lock-%s-NET-U\"%typ, reuse=tf.AUTO_REUSE): \n",
    "        _h_t = dense(\"H-t\", tf.tile(_t,[1,M,1]), 50, is_training=is_training, reuse=tf.AUTO_REUSE)\n",
    "        _h_X = dense(\"H-X\", _Xt, 50, is_training=is_training, reuse=tf.AUTO_REUSE)\n",
    "        _h_K = dense(\"H-K\", tf.tile(_K,[1,M,1]), 50, is_training=is_training, reuse=tf.AUTO_REUSE)\n",
    "        _h_T = dense(\"H-T\", tf.tile(_T,[1,M,1]), 50, is_training=is_training, reuse=tf.AUTO_REUSE)\n",
    "        _h = tf.concat([_h_t, _h_X, _h_K, _h_T], axis=-1)\n",
    "        _h = dense(\"H2\", _h, 256, is_training=is_training, reuse=tf.AUTO_REUSE)\n",
    "        _h = dense(\"H3\", _h, 256, is_training=is_training, reuse=tf.AUTO_REUSE)\n",
    "        _h = dense(\"H4\", _h, 256, is_training=is_training, reuse=tf.AUTO_REUSE)\n",
    "        _h = dense(\"H5\", _h, 128, is_training=is_training, reuse=tf.AUTO_REUSE)\n",
    "        _output = tf.layers.dense(_h, units=1, activation=None, name=\"U\", reuse=tf.AUTO_REUSE)\n",
    "    return _output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Brownian motions (standard normal variable, not scaled): \n",
    "_dws = [tf.placeholder(tf.float32, [None,M,1], name=\"ph_dw_%.0f\"%n) for n in range(N)]  # I x M x 1 (x N)\n",
    "\n",
    "# Define strikes, time-to-maturity & time intervals (varying in a mini-batch): \n",
    "_K_c_ask = tf.placeholder(tf.float32, [None,1,1], name=\"ph_K-C-ASK\")  # I x 1 x 1\n",
    "_K_p_ask = tf.placeholder(tf.float32, [None,1,1], name=\"ph_K-P-ASK\")  # I x 1 x 1\n",
    "_T_c_ask = tf.placeholder(tf.float32, [None,1,1], name=\"ph_T-C-ASK\")  # I x 1 x 1\n",
    "_T_p_ask = tf.placeholder(tf.float32, [None,1,1], name=\"ph_T-P-ASK\")  # I x 1 x 1\n",
    "_dt_c_ask = _T_c_ask / N                                      # I x 1 x 1\n",
    "_dt_p_ask = _T_p_ask / N                                      # I x 1 x 1\n",
    "\n",
    "# Define a training signal: \n",
    "is_training = tf.placeholder(tf.bool, name=\"ph_is_training\") \n",
    "\n",
    "# The forward SDE: \n",
    "_X0_c_ask = tf.placeholder(tf.float32, [None,1], name=\"ph_X0_c_ask\")     # I x 1\n",
    "_X0_p_ask = tf.placeholder(tf.float32, [None,1], name=\"ph_X0_p_ask\")     # I x 1\n",
    "_ts_c_ask = [n * _dt_c_ask for n in range(N+1)]                          # I x 1 x 1 (x N+1)\n",
    "_ts_p_ask = [n * _dt_p_ask for n in range(N+1)]                          # I x 1 x 1 (x N+1)\n",
    "_Xs_c_ask = [tf.tile(tf.reshape(_X0_c_ask, [-1,1,1]), [1,M,1])]    # I x M x 1 (x N+1)\n",
    "_Xs_p_ask = [tf.tile(tf.reshape(_X0_p_ask, [-1,1,1]), [1,M,1])]    # I x M x 1 (x N+1)\n",
    "_Ys_c_ask = []                               # I x M x 1 (x N+1)\n",
    "_Ys_p_ask = []                               # I x M x 1 (x N+1)\n",
    "_Zs_c_ask = []                               # I x M x 1 (x N)\n",
    "_Zs_p_ask = []                               # I x M x 1 (x N)\n",
    "_Us_c_ask = []                               # I x M x 1 (x N)\n",
    "_Us_p_ask = []                               # I x M x 1 (x N)\n",
    "_sigma_c_ask = []\n",
    "_sigma_p_ask = []\n",
    "for n in range(N): \n",
    "    _cur_t_c_ask = _ts_c_ask[n]   # I x 1 x 1\n",
    "    _cur_t_p_ask = _ts_p_ask[n]   # I x 1 x 1\n",
    "    _cur_X_c_ask = _Xs_c_ask[n]   # I x M x 1\n",
    "    _cur_X_p_ask = _Xs_p_ask[n]   # I x M x 1\n",
    "    _cur_sigma_c_ask = network_sigma(_cur_t_c_ask, _cur_X_c_ask)\n",
    "    _cur_sigma_p_ask = network_sigma(_cur_t_p_ask, _cur_X_p_ask)\n",
    "    _nxt_X_c_ask = _cur_X_c_ask + _cur_sigma_c_ask * tf.sqrt(_dt_c_ask) * _dws[n]\n",
    "    _nxt_X_p_ask = _cur_X_p_ask + _cur_sigma_p_ask * tf.sqrt(_dt_p_ask) * _dws[n]\n",
    "    _Xs_c_ask.append(_nxt_X_c_ask)\n",
    "    _Xs_p_ask.append(_nxt_X_p_ask)\n",
    "    _Ys_c_ask.append(np.nan)\n",
    "    _Ys_p_ask.append(np.nan)\n",
    "    _cur_U_c_ask = network_U(\"C-ASK\", _cur_t_c_ask, _cur_X_c_ask, _K_c_ask, _T_c_ask)\n",
    "    _cur_U_p_ask = network_U(\"P-ASK\", _cur_t_p_ask, _cur_X_p_ask, _K_p_ask, _T_p_ask)\n",
    "    _cur_Z_c_ask = network_Z(\"C-ASK\", _cur_t_c_ask, _cur_X_c_ask, _K_c_ask, _T_c_ask)\n",
    "    _cur_Z_p_ask = network_Z(\"P-ASK\", _cur_t_p_ask, _cur_X_p_ask, _K_p_ask, _T_p_ask)\n",
    "    _Us_c_ask.append(_cur_U_c_ask)\n",
    "    _Us_p_ask.append(_cur_U_p_ask)\n",
    "    _Zs_c_ask.append(_cur_Z_c_ask)\n",
    "    _Zs_p_ask.append(_cur_Z_p_ask)\n",
    "    _sigma_c_ask.append(_cur_sigma_c_ask)\n",
    "    _sigma_p_ask.append(_cur_sigma_p_ask)\n",
    "\n",
    "# The backward SDE: \n",
    "_loss_UY_c_ask = 0.\n",
    "_loss_UY_p_ask = 0.\n",
    "_loss_DYZ_c_ask = 0.\n",
    "_loss_DYZ_p_ask = 0.\n",
    "_Ys_c_ask.append(tf.maximum(_Xs_c_ask[N] - _K_c_ask, 0.))    # I x M x 1 (x N+1)\n",
    "_Ys_p_ask.append(tf.maximum(_K_p_ask - _Xs_p_ask[N], 0.))    # I x M x 1 (x N+1)\n",
    "for n in range(N-1, -1, -1): \n",
    "    _cur_t_c_ask = _ts_c_ask[n]   # I x 1 x 1\n",
    "    _cur_t_p_ask = _ts_p_ask[n]   # I x 1 x 1\n",
    "    _cur_X_c_ask = _Xs_c_ask[n]   # I x M x 1\n",
    "    _cur_X_p_ask = _Xs_p_ask[n]   # I x M x 1\n",
    "    _cur_U_c_ask = _Us_c_ask[n]   # I x M x 1\n",
    "    _cur_U_p_ask = _Us_p_ask[n]   # I x M x 1\n",
    "    _cur_Z_c_ask = _Zs_c_ask[n]   # I x M x 1\n",
    "    _cur_Z_p_ask = _Zs_p_ask[n]   # I x M x 1\n",
    "    _cur_Y_c_ask = _Ys_c_ask[n+1] + network_g(\n",
    "        _cur_t_c_ask, _cur_X_c_ask, _cur_U_c_ask, _cur_Z_c_ask) * _dt_c_ask - \\\n",
    "        _cur_Z_c_ask * tf.sqrt(_dt_c_ask) * _dws[n]\n",
    "    _cur_Y_p_ask = _Ys_p_ask[n+1] + network_g(\n",
    "        _cur_t_p_ask, _cur_X_p_ask, _cur_U_p_ask, _cur_Z_p_ask) * _dt_p_ask - \\\n",
    "        _cur_Z_p_ask * tf.sqrt(_dt_p_ask) * _dws[n]\n",
    "    _Ys_c_ask[n] = _cur_Y_c_ask\n",
    "    _Ys_p_ask[n] = _cur_Y_p_ask\n",
    "    \n",
    "    _loss_UY_c_ask += tf.reduce_mean(tf.square(_cur_Y_c_ask - _cur_U_c_ask) / N)  # + tf.square(1/_cur_Y_c_ask - 1/_cur_U_c_ask)\n",
    "    _loss_UY_p_ask += tf.reduce_mean(tf.square(_cur_Y_p_ask - _cur_U_p_ask) / N)  # + tf.square(1/_cur_Y_p_ask - 1/_cur_U_p_ask)\n",
    "    \n",
    "    _grad_sigma_c_ask = tf.gradients(_cur_U_c_ask, _cur_X_c_ask)[0] * _sigma_c_ask[n]\n",
    "    _grad_sigma_p_ask = tf.gradients(_cur_U_p_ask, _cur_X_p_ask)[0] * _sigma_p_ask[n]\n",
    "    _loss_DYZ_c_ask += tf.reduce_mean(tf.square(_cur_Z_c_ask - _grad_sigma_c_ask) / N)  # + tf.square(1/_cur_Z_c_ask - 1/_grad_sigma_c_ask)\n",
    "    _loss_DYZ_p_ask += tf.reduce_mean(tf.square(_cur_Z_p_ask - _grad_sigma_p_ask) / N)  # + tf.square(1/_cur_Z_p_ask - 1/_grad_sigma_p_ask)\n",
    "\n",
    "# Pricing Loss: \n",
    "_true_Y0_c_ask = tf.placeholder(tf.float32, [None,1], name=\"ph_Y0_c_ask\")  # I x 1\n",
    "_true_Y0_p_ask = tf.placeholder(tf.float32, [None,1], name=\"ph_Y0_p_ask\")  # I x 1\n",
    "_Y0_c_ask = tf.reduce_mean(_Ys_c_ask[0], axis=1, keepdims=False)           # I x 1\n",
    "_Y0_p_ask = tf.reduce_mean(_Ys_p_ask[0], axis=1, keepdims=False)           # I x 1\n",
    "_Z0_c_ask = tf.reduce_mean(_Zs_c_ask[0], axis=1, keepdims=False)           # I x 1\n",
    "_Z0_p_ask = tf.reduce_mean(_Zs_p_ask[0], axis=1, keepdims=False)           # I x 1\n",
    "_U0_c_ask = tf.reduce_mean(_Us_c_ask[0], axis=1, keepdims=False)           # I x 1\n",
    "_U0_p_ask = tf.reduce_mean(_Us_p_ask[0], axis=1, keepdims=False)           # I x 1\n",
    "\n",
    "_mse_c_ask = tf.reduce_mean(tf.square(_Y0_c_ask - _true_Y0_c_ask))  # + tf.square(1/_Y0_c_ask - 1/_true_Y0_c_ask)\n",
    "_mse_p_ask = tf.reduce_mean(tf.square(_Y0_p_ask - _true_Y0_p_ask))  # + tf.square(1/_Y0_p_ask - 1/_true_Y0_p_ask)\n",
    "_mae_c_ask = tf.reduce_mean(tf.abs(_Y0_c_ask - _true_Y0_c_ask))\n",
    "_mae_p_ask = tf.reduce_mean(tf.abs(_Y0_p_ask - _true_Y0_p_ask))\n",
    "_mape_c_ask = tf.reduce_mean(tf.abs(_Y0_c_ask / _true_Y0_c_ask - 1))\n",
    "_mape_p_ask = tf.reduce_mean(tf.abs(_Y0_p_ask / _true_Y0_p_ask - 1))\n",
    "\n",
    "_loss_UY = (_loss_UY_c_ask + _loss_UY_p_ask) / 2\n",
    "_loss_DYZ = (_loss_DYZ_c_ask + _loss_DYZ_p_ask) / 2\n",
    "\n",
    "_mse = (_mse_c_ask + _mse_p_ask) / 2\n",
    "_mae = (_mae_c_ask + _mae_p_ask) / 2\n",
    "_mape = (_mape_c_ask + _mape_p_ask) / 2\n",
    "\n",
    "_loss = _mse + 1.0 * _loss_UY + 1.0 * _loss_DYZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Lock-C-ASK-NET-U/H-t/kernel:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-U/H-t/bias:0' shape=(50,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-U/H-X/kernel:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-U/H-X/bias:0' shape=(50,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-U/H-K/kernel:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-U/H-K/bias:0' shape=(50,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-U/H-T/kernel_1:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-U/H-T/bias_1:0' shape=(50,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-U/H2/kernel:0' shape=(200, 256) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-U/H2/bias:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-U/H3/kernel:0' shape=(256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-U/H3/bias:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-U/H4/kernel:0' shape=(256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-U/H4/bias:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-U/H5/kernel:0' shape=(256, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-U/H5/bias:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-U/U/kernel:0' shape=(128, 1) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-U/U/bias:0' shape=(1,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-U/H-t/kernel:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-U/H-t/bias:0' shape=(50,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-U/H-X/kernel:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-U/H-X/bias:0' shape=(50,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-U/H-K/kernel:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-U/H-K/bias:0' shape=(50,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-U/H-T/kernel_1:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-U/H-T/bias_1:0' shape=(50,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-U/H2/kernel:0' shape=(200, 256) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-U/H2/bias:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-U/H3/kernel:0' shape=(256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-U/H3/bias:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-U/H4/kernel:0' shape=(256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-U/H4/bias:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-U/H5/kernel:0' shape=(256, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-U/H5/bias:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-U/U/kernel:0' shape=(128, 1) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-U/U/bias:0' shape=(1,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-Z/H-t/kernel:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-Z/H-t/bias:0' shape=(50,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-Z/H-X/kernel:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-Z/H-X/bias:0' shape=(50,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-Z/H-K/kernel:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-Z/H-K/bias:0' shape=(50,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-Z/H-T/kernel_1:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-Z/H-T/bias_1:0' shape=(50,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-Z/H2/kernel:0' shape=(200, 256) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-Z/H2/bias:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-Z/H3/kernel:0' shape=(256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-Z/H3/bias:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-Z/H4/kernel:0' shape=(256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-Z/H4/bias:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-Z/H5/kernel:0' shape=(256, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-Z/H5/bias:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-Z/Z/kernel:0' shape=(128, 1) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-C-ASK-NET-Z/Z/bias:0' shape=(1,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-Z/H-t/kernel:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-Z/H-t/bias:0' shape=(50,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-Z/H-X/kernel:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-Z/H-X/bias:0' shape=(50,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-Z/H-K/kernel:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-Z/H-K/bias:0' shape=(50,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-Z/H-T/kernel_1:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-Z/H-T/bias_1:0' shape=(50,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-Z/H2/kernel:0' shape=(200, 256) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-Z/H2/bias:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-Z/H3/kernel:0' shape=(256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-Z/H3/bias:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-Z/H4/kernel:0' shape=(256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-Z/H4/bias:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-Z/H5/kernel:0' shape=(256, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-Z/H5/bias:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-Z/Z/kernel:0' shape=(128, 1) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-P-ASK-NET-Z/Z/bias:0' shape=(1,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-NET-g/H-t/kernel:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-NET-g/H-t/bias:0' shape=(50,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-NET-g/H-X/kernel:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-NET-g/H-X/bias:0' shape=(50,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-NET-g/H-Y/kernel:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-NET-g/H-Y/bias:0' shape=(50,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-NET-g/H-Z/kernel:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-NET-g/H-Z/bias:0' shape=(50,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-NET-g/H2/kernel:0' shape=(200, 256) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-NET-g/H2/bias:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-NET-g/H3/kernel:0' shape=(256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-NET-g/H3/bias:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-NET-g/H4/kernel:0' shape=(256, 256) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-NET-g/H4/bias:0' shape=(256,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-NET-g/H5/kernel:0' shape=(256, 128) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-NET-g/H5/bias:0' shape=(128,) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-NET-g/G/kernel:0' shape=(128, 1) dtype=float32_ref>\n",
      "<tf.Variable 'Lock-NET-g/G/bias:0' shape=(1,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "for variable in tf.trainable_variables():\n",
    "    print(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready...\n",
      "Training...\n",
      "sim_Y0_c_ask: 70.63745 sim_U0_c_ask: 1325.61 true_Y0_c_ask: 204.25 sim_Y0_p_ask: 15.892092 sim_U0_p_ask: 795.598 true_Y0_p_ask: 23.85 sim_Z0_c_ask: 1250.7948 sim_Z0_p_ask: 981.6931\n",
      "[Train] Epoch 0 Step 1, lr(0.004000): loss=315891.6562, mse=7331.0264, mae=66.9594, mape=0.7504, UY-loss=295841.2812, DYZ-loss=12719.3447\n",
      "[Valid] Epoch 0 Step 1, lr(0.004000): loss=4161028.2500, mse=809832.5625, mae=629.3422, mape=11.6410, UY-loss=2113054.0000, DYZ-loss=1238141.7500\n",
      "sim_Y0_c_ask: 46.646324 sim_U0_c_ask: 28.159567 true_Y0_c_ask: 25.6 sim_Y0_p_ask: 281.0143 sim_U0_p_ask: 524.06134 true_Y0_p_ask: 287.95 sim_Z0_c_ask: 135.97139 sim_Z0_p_ask: -314.60553\n",
      "[Train] Epoch 0 Step 51, lr(0.004000): loss=20819.1602, mse=1491.3645, mae=29.2953, mape=0.7533, UY-loss=9805.1074, DYZ-loss=9522.6895\n",
      "[Valid] Epoch 0 Step 51, lr(0.004000): loss=27111.9355, mse=992.1058, mae=22.7821, mape=0.6623, UY-loss=18766.4570, DYZ-loss=7353.3730\n",
      "sim_Y0_c_ask: 89.91788 sim_U0_c_ask: 52.523724 true_Y0_c_ask: 127.05 sim_Y0_p_ask: 285.07214 sim_U0_p_ask: 46.79136 true_Y0_p_ask: 322.35 sim_Z0_c_ask: 143.70557 sim_Z0_p_ask: -131.74411\n",
      "[Train] Epoch 0 Step 101, lr(0.004000): loss=9866.4746, mse=1331.4731, mae=28.2910, mape=0.5172, UY-loss=4590.6348, DYZ-loss=3944.3667\n",
      "[Valid] Epoch 0 Step 101, lr(0.004000): loss=9301.2959, mse=568.7094, mae=18.5716, mape=0.5954, UY-loss=5233.9233, DYZ-loss=3498.6631\n",
      "sim_Y0_c_ask: 1383.2161 sim_U0_c_ask: 1379.1167 true_Y0_c_ask: 1403.5 sim_Y0_p_ask: 24.448933 sim_U0_p_ask: 110.775185 true_Y0_p_ask: 35.55 sim_Z0_c_ask: 532.8477 sim_Z0_p_ask: -260.3748\n",
      "[Train] Epoch 0 Step 151, lr(0.004000): loss=7077.3691, mse=1205.7388, mae=27.5327, mape=0.2670, UY-loss=3984.0728, DYZ-loss=1887.5575\n",
      "[Valid] Epoch 0 Step 151, lr(0.004000): loss=8823.9912, mse=826.8207, mae=20.2975, mape=0.3891, UY-loss=5028.2539, DYZ-loss=2968.9167\n",
      "sim_Y0_c_ask: 412.1679 sim_U0_c_ask: 422.93216 true_Y0_c_ask: 462.65 sim_Y0_p_ask: 9.118349 sim_U0_p_ask: 42.149483 true_Y0_p_ask: 19.1 sim_Z0_c_ask: 531.63165 sim_Z0_p_ask: -33.13138\n",
      "[Train] Epoch 0 Step 201, lr(0.004000): loss=5405.6592, mse=1063.8528, mae=24.8297, mape=0.2759, UY-loss=3072.0437, DYZ-loss=1269.7629\n",
      "[Valid] Epoch 0 Step 201, lr(0.004000): loss=6443.5713, mse=512.6635, mae=17.4060, mape=0.3358, UY-loss=3668.4961, DYZ-loss=2262.4116\n",
      "sim_Y0_c_ask: 825.12976 sim_U0_c_ask: 793.71545 true_Y0_c_ask: 823.25 sim_Y0_p_ask: 22.331764 sim_U0_p_ask: 24.189161 true_Y0_p_ask: 63.15 sim_Z0_c_ask: 542.4591 sim_Z0_p_ask: -52.791786\n",
      "[Train] Epoch 0 Step 251, lr(0.004000): loss=5857.0801, mse=805.5402, mae=20.7234, mape=0.2516, UY-loss=3408.7100, DYZ-loss=1642.8300\n",
      "[Valid] Epoch 0 Step 251, lr(0.004000): loss=6035.0630, mse=342.3587, mae=13.9825, mape=0.3635, UY-loss=4196.5186, DYZ-loss=1496.1857\n",
      "sim_Y0_c_ask: 40.171906 sim_U0_c_ask: -0.6638396 true_Y0_c_ask: 29.05 sim_Y0_p_ask: 84.79301 sim_U0_p_ask: 37.7965 true_Y0_p_ask: 160.3 sim_Z0_c_ask: 14.143696 sim_Z0_p_ask: -46.0183\n",
      "[Train] Epoch 0 Step 301, lr(0.004000): loss=4145.7422, mse=831.3307, mae=21.8883, mape=0.2703, UY-loss=2660.3926, DYZ-loss=654.0193\n",
      "[Valid] Epoch 0 Step 301, lr(0.004000): loss=3445.9973, mse=307.6475, mae=13.6622, mape=0.3674, UY-loss=2645.5217, DYZ-loss=492.8281\n",
      "sim_Y0_c_ask: 148.14569 sim_U0_c_ask: 148.84343 true_Y0_c_ask: 159.95 sim_Y0_p_ask: 59.84712 sim_U0_p_ask: 17.804049 true_Y0_p_ask: 109.6 sim_Z0_c_ask: 433.8759 sim_Z0_p_ask: -97.33945\n",
      "[Train] Epoch 0 Step 351, lr(0.004000): loss=4784.9238, mse=1024.3903, mae=23.6746, mape=0.4321, UY-loss=2959.8074, DYZ-loss=800.7261\n",
      "[Valid] Epoch 0 Step 351, lr(0.004000): loss=6482.0664, mse=326.0969, mae=13.7815, mape=0.4536, UY-loss=3830.2583, DYZ-loss=2325.7112\n",
      "sim_Y0_c_ask: 119.580185 sim_U0_c_ask: 85.47666 true_Y0_c_ask: 140.45 sim_Y0_p_ask: 85.20019 sim_U0_p_ask: 39.89547 true_Y0_p_ask: 132.95 sim_Z0_c_ask: 256.04993 sim_Z0_p_ask: -38.729343\n",
      "[Train] Epoch 0 Step 401, lr(0.004000): loss=5266.4463, mse=945.2374, mae=23.1530, mape=0.3703, UY-loss=2983.6887, DYZ-loss=1337.5203\n",
      "[Valid] Epoch 0 Step 401, lr(0.004000): loss=4521.0361, mse=217.1983, mae=10.8936, mape=0.3307, UY-loss=3296.3677, DYZ-loss=1007.4701\n",
      "sim_Y0_c_ask: 301.9816 sim_U0_c_ask: 284.05856 true_Y0_c_ask: 328.3 sim_Y0_p_ask: 114.33747 sim_U0_p_ask: 184.61127 true_Y0_p_ask: 152.89999999999998 sim_Z0_c_ask: 518.157 sim_Z0_p_ask: -267.9527\n",
      "[Train] Epoch 0 Step 451, lr(0.004000): loss=6548.3872, mse=878.2493, mae=23.3843, mape=0.3018, UY-loss=3734.6421, DYZ-loss=1935.4956\n",
      "[Valid] Epoch 0 Step 451, lr(0.004000): loss=8354.6963, mse=309.9876, mae=13.2257, mape=0.4908, UY-loss=4064.7131, DYZ-loss=3979.9956\n",
      "sim_Y0_c_ask: 362.45978 sim_U0_c_ask: 293.96484 true_Y0_c_ask: 424.15 sim_Y0_p_ask: 141.01265 sim_U0_p_ask: 74.82001 true_Y0_p_ask: 195.8 sim_Z0_c_ask: 515.3312 sim_Z0_p_ask: -121.183014\n",
      "[Train] Epoch 0 Step 501, lr(0.004000): loss=4549.1313, mse=858.3608, mae=21.5784, mape=0.3299, UY-loss=2348.2827, DYZ-loss=1342.4879\n",
      "[Valid] Epoch 0 Step 501, lr(0.004000): loss=10636.0312, mse=413.8206, mae=14.9054, mape=0.5113, UY-loss=4753.8096, DYZ-loss=5468.4004\n",
      "sim_Y0_c_ask: 1095.0698 sim_U0_c_ask: 1145.6516 true_Y0_c_ask: 1099.5 sim_Y0_p_ask: 23.367455 sim_U0_p_ask: 13.699062 true_Y0_p_ask: 41.650000000000006 sim_Z0_c_ask: 570.7042 sim_Z0_p_ask: -11.528457\n",
      "[Train] Epoch 0 Step 551, lr(0.004000): loss=5773.9541, mse=1087.7831, mae=24.2786, mape=0.3597, UY-loss=2204.5728, DYZ-loss=2481.5979\n",
      "[Valid] Epoch 0 Step 551, lr(0.004000): loss=11041.5352, mse=200.0427, mae=10.7915, mape=0.6294, UY-loss=4133.3345, DYZ-loss=6708.1582\n",
      "sim_Y0_c_ask: 280.4347 sim_U0_c_ask: 149.61151 true_Y0_c_ask: 343.0 sim_Y0_p_ask: 51.87758 sim_U0_p_ask: 22.224176 true_Y0_p_ask: 68.25 sim_Z0_c_ask: 211.51064 sim_Z0_p_ask: -28.91616\n",
      "[Train] Epoch 1 Step 601, lr(0.004000): loss=3878.5566, mse=541.5925, mae=16.9051, mape=0.2141, UY-loss=2234.3091, DYZ-loss=1102.6550\n",
      "[Valid] Epoch 1 Step 601, lr(0.004000): loss=5596.6655, mse=239.9542, mae=11.4353, mape=0.2880, UY-loss=3114.1987, DYZ-loss=2242.5127\n",
      "sim_Y0_c_ask: 431.52954 sim_U0_c_ask: 429.92972 true_Y0_c_ask: 439.75 sim_Y0_p_ask: 90.07178 sim_U0_p_ask: 86.697655 true_Y0_p_ask: 133.75 sim_Z0_c_ask: 534.1122 sim_Z0_p_ask: -300.94238\n",
      "[Train] Epoch 1 Step 651, lr(0.004000): loss=3359.4380, mse=602.4893, mae=17.3006, mape=0.2566, UY-loss=2082.8015, DYZ-loss=674.1471\n",
      "[Valid] Epoch 1 Step 651, lr(0.004000): loss=3027.0818, mse=226.9132, mae=10.9723, mape=0.3582, UY-loss=2221.2256, DYZ-loss=578.9432\n",
      "sim_Y0_c_ask: 559.8865 sim_U0_c_ask: 579.6358 true_Y0_c_ask: 579.05 sim_Y0_p_ask: 68.94789 sim_U0_p_ask: 26.656538 true_Y0_p_ask: 90.55000000000001 sim_Z0_c_ask: 526.8852 sim_Z0_p_ask: -36.8963\n",
      "[Train] Epoch 1 Step 701, lr(0.004000): loss=4628.9062, mse=544.1227, mae=17.4153, mape=0.1744, UY-loss=2921.7793, DYZ-loss=1163.0042\n",
      "[Valid] Epoch 1 Step 701, lr(0.004000): loss=4806.6621, mse=458.1394, mae=14.6534, mape=0.4676, UY-loss=2999.1165, DYZ-loss=1349.4064\n",
      "sim_Y0_c_ask: 352.60355 sim_U0_c_ask: 367.7392 true_Y0_c_ask: 367.4 sim_Y0_p_ask: 9.431771 sim_U0_p_ask: -4.8203626 true_Y0_p_ask: 7.449999999999999 sim_Z0_c_ask: 494.60052 sim_Z0_p_ask: -21.792372\n",
      "[Train] Epoch 1 Step 751, lr(0.004000): loss=4646.4668, mse=459.4145, mae=15.0449, mape=0.2222, UY-loss=1768.0566, DYZ-loss=2418.9956\n",
      "[Valid] Epoch 1 Step 751, lr(0.004000): loss=7183.6489, mse=322.6029, mae=12.1258, mape=0.3726, UY-loss=3194.6816, DYZ-loss=3666.3643\n",
      "sim_Y0_c_ask: 575.453 sim_U0_c_ask: 506.23914 true_Y0_c_ask: 588.45 sim_Y0_p_ask: 44.13566 sim_U0_p_ask: 107.5724 true_Y0_p_ask: 55.55 sim_Z0_c_ask: 529.96954 sim_Z0_p_ask: -184.42125\n",
      "[Train] Epoch 1 Step 801, lr(0.004000): loss=2959.7529, mse=503.1933, mae=16.0284, mape=0.3657, UY-loss=1700.6055, DYZ-loss=755.9541\n",
      "[Valid] Epoch 1 Step 801, lr(0.004000): loss=3019.2717, mse=268.5713, mae=11.3111, mape=0.6898, UY-loss=2055.7808, DYZ-loss=694.9197\n",
      "sim_Y0_c_ask: 140.65298 sim_U0_c_ask: 59.292946 true_Y0_c_ask: 173.85000000000002 sim_Y0_p_ask: 425.41553 sim_U0_p_ask: 426.29224 true_Y0_p_ask: 425.15 sim_Z0_c_ask: 151.36235 sim_Z0_p_ask: -569.81067\n",
      "[Train] Epoch 1 Step 851, lr(0.004000): loss=4290.6392, mse=590.1147, mae=17.8811, mape=0.1875, UY-loss=2730.4321, DYZ-loss=970.0923\n",
      "[Valid] Epoch 1 Step 851, lr(0.004000): loss=7434.1079, mse=250.3197, mae=11.1785, mape=0.1946, UY-loss=3762.3604, DYZ-loss=3421.4280\n",
      "sim_Y0_c_ask: 21.02705 sim_U0_c_ask: -3.2080598 true_Y0_c_ask: 10.65 sim_Y0_p_ask: 344.44995 sim_U0_p_ask: 336.189 true_Y0_p_ask: 345.1 sim_Z0_c_ask: 12.448344 sim_Z0_p_ask: -477.6446\n",
      "[Train] Epoch 1 Step 901, lr(0.004000): loss=2591.4023, mse=346.5373, mae=13.7274, mape=0.2297, UY-loss=1618.3452, DYZ-loss=626.5198\n",
      "[Valid] Epoch 1 Step 901, lr(0.004000): loss=3666.0508, mse=393.4732, mae=15.7215, mape=0.4696, UY-loss=1986.0476, DYZ-loss=1286.5300\n",
      "sim_Y0_c_ask: 57.713203 sim_U0_c_ask: 37.08865 true_Y0_c_ask: 86.05000000000001 sim_Y0_p_ask: 236.43465 sim_U0_p_ask: 267.77655 true_Y0_p_ask: 266.75 sim_Z0_c_ask: 64.765854 sim_Z0_p_ask: -367.26227\n",
      "[Train] Epoch 1 Step 951, lr(0.004000): loss=5186.7783, mse=434.2587, mae=15.0945, mape=0.1439, UY-loss=2744.0781, DYZ-loss=2008.4414\n",
      "[Valid] Epoch 1 Step 951, lr(0.004000): loss=7729.9375, mse=208.9046, mae=10.1654, mape=0.2666, UY-loss=4332.6670, DYZ-loss=3188.3657\n",
      "sim_Y0_c_ask: 773.5489 sim_U0_c_ask: 739.0066 true_Y0_c_ask: 768.6 sim_Y0_p_ask: 154.90555 sim_U0_p_ask: 72.75947 true_Y0_p_ask: 216.05 sim_Z0_c_ask: 581.37146 sim_Z0_p_ask: -258.2848\n",
      "[Train] Epoch 1 Step 1001, lr(0.004000): loss=3323.5867, mse=587.0956, mae=18.2679, mape=0.2420, UY-loss=2214.2217, DYZ-loss=522.2693\n",
      "[Valid] Epoch 1 Step 1001, lr(0.004000): loss=5390.0469, mse=331.0658, mae=13.7735, mape=0.2923, UY-loss=2557.7637, DYZ-loss=2501.2173\n",
      "sim_Y0_c_ask: 1302.4917 sim_U0_c_ask: 1336.4926 true_Y0_c_ask: 1305.5 sim_Y0_p_ask: 1866.1218 sim_U0_p_ask: 1951.9872 true_Y0_p_ask: 1866.0 sim_Z0_c_ask: 536.66736 sim_Z0_p_ask: -582.52856\n",
      "[Train] Epoch 1 Step 1051, lr(0.004000): loss=3823.1199, mse=616.5822, mae=17.0925, mape=0.2750, UY-loss=1533.7227, DYZ-loss=1672.8149\n",
      "[Valid] Epoch 1 Step 1051, lr(0.004000): loss=2975.4248, mse=244.1798, mae=10.4769, mape=0.2401, UY-loss=1874.1971, DYZ-loss=857.0478\n",
      "sim_Y0_c_ask: 1125.1477 sim_U0_c_ask: 1151.4841 true_Y0_c_ask: 1115.0 sim_Y0_p_ask: 230.74173 sim_U0_p_ask: 219.00323 true_Y0_p_ask: 243.75 sim_Z0_c_ask: 555.0664 sim_Z0_p_ask: -28.403727\n",
      "[Train] Epoch 1 Step 1101, lr(0.004000): loss=2250.2168, mse=330.8861, mae=12.4982, mape=0.1636, UY-loss=1388.0889, DYZ-loss=531.2419\n",
      "[Valid] Epoch 1 Step 1101, lr(0.004000): loss=2646.0542, mse=250.0498, mae=11.1716, mape=0.5648, UY-loss=1429.7318, DYZ-loss=966.2726\n",
      "sim_Y0_c_ask: 1143.8901 sim_U0_c_ask: 1107.1088 true_Y0_c_ask: 1140.0 sim_Y0_p_ask: 11.313084 sim_U0_p_ask: 6.840303 true_Y0_p_ask: 23.6 sim_Z0_c_ask: 527.0291 sim_Z0_p_ask: -54.4388\n",
      "[Train] Epoch 1 Step 1151, lr(0.004000): loss=3694.9272, mse=361.4825, mae=14.3016, mape=0.1687, UY-loss=1935.7141, DYZ-loss=1397.7303\n",
      "[Valid] Epoch 1 Step 1151, lr(0.004000): loss=3322.8833, mse=195.4062, mae=9.9692, mape=0.3753, UY-loss=2096.7832, DYZ-loss=1030.6940\n",
      "sim_Y0_c_ask: 274.73254 sim_U0_c_ask: 201.22939 true_Y0_c_ask: 259.20000000000005 sim_Y0_p_ask: 893.0056 sim_U0_p_ask: 935.4717 true_Y0_p_ask: 894.85 sim_Z0_c_ask: 528.85236 sim_Z0_p_ask: -503.3849\n",
      "[Train] Epoch 2 Step 1201, lr(0.004000): loss=3456.2036, mse=322.4693, mae=13.2152, mape=0.1507, UY-loss=1900.9900, DYZ-loss=1232.7444\n",
      "[Valid] Epoch 2 Step 1201, lr(0.004000): loss=3223.9321, mse=282.0367, mae=13.3455, mape=0.2955, UY-loss=1947.8823, DYZ-loss=994.0133\n",
      "sim_Y0_c_ask: 25.76275 sim_U0_c_ask: 16.456926 true_Y0_c_ask: 14.6 sim_Y0_p_ask: 76.16791 sim_U0_p_ask: 66.11909 true_Y0_p_ask: 115.69999999999999 sim_Z0_c_ask: 10.718716 sim_Z0_p_ask: -31.575104\n",
      "[Train] Epoch 2 Step 1251, lr(0.004000): loss=9024.7012, mse=307.4799, mae=13.0373, mape=0.3749, UY-loss=3319.5859, DYZ-loss=5397.6357\n",
      "[Valid] Epoch 2 Step 1251, lr(0.004000): loss=5839.1621, mse=297.1453, mae=11.9777, mape=1.0820, UY-loss=3392.5513, DYZ-loss=2149.4653\n",
      "sim_Y0_c_ask: 6.4206166 sim_U0_c_ask: 6.2490816 true_Y0_c_ask: 3.2 sim_Y0_p_ask: 16.99323 sim_U0_p_ask: 40.45559 true_Y0_p_ask: 20.5 sim_Z0_c_ask: 22.645153 sim_Z0_p_ask: -98.87262\n",
      "[Train] Epoch 2 Step 1301, lr(0.004000): loss=3739.0229, mse=344.5579, mae=13.7247, mape=0.2565, UY-loss=1596.2024, DYZ-loss=1798.2628\n",
      "[Valid] Epoch 2 Step 1301, lr(0.004000): loss=3700.8770, mse=313.4356, mae=13.0498, mape=0.2761, UY-loss=2218.6377, DYZ-loss=1168.8037\n",
      "sim_Y0_c_ask: 1291.5417 sim_U0_c_ask: 1331.5948 true_Y0_c_ask: 1270.0 sim_Y0_p_ask: 237.3552 sim_U0_p_ask: 200.69638 true_Y0_p_ask: 288.9 sim_Z0_c_ask: 550.31824 sim_Z0_p_ask: -244.40065\n",
      "[Train] Epoch 2 Step 1351, lr(0.004000): loss=3215.2837, mse=481.2705, mae=15.6551, mape=0.1978, UY-loss=1552.5826, DYZ-loss=1181.4304\n",
      "[Valid] Epoch 2 Step 1351, lr(0.004000): loss=2386.4729, mse=416.0642, mae=16.2754, mape=0.3302, UY-loss=1521.9023, DYZ-loss=448.5064\n",
      "sim_Y0_c_ask: 4.287969 sim_U0_c_ask: 2.2901525 true_Y0_c_ask: 1.0 sim_Y0_p_ask: 183.73227 sim_U0_p_ask: 142.06107 true_Y0_p_ask: 175.1 sim_Z0_c_ask: 15.452332 sim_Z0_p_ask: -492.27298\n",
      "[Train] Epoch 2 Step 1401, lr(0.004000): loss=7339.0679, mse=287.7836, mae=12.8978, mape=0.2136, UY-loss=3369.6885, DYZ-loss=3681.5957\n",
      "[Valid] Epoch 2 Step 1401, lr(0.004000): loss=9713.3652, mse=381.3441, mae=14.9020, mape=0.3831, UY-loss=2872.0767, DYZ-loss=6459.9438\n",
      "sim_Y0_c_ask: 191.02774 sim_U0_c_ask: 138.3804 true_Y0_c_ask: 215.7 sim_Y0_p_ask: 16.41557 sim_U0_p_ask: 19.395721 true_Y0_p_ask: 25.0 sim_Z0_c_ask: 441.16568 sim_Z0_p_ask: -0.6720127\n",
      "[Train] Epoch 2 Step 1451, lr(0.004000): loss=7113.6865, mse=533.8252, mae=17.4975, mape=0.3365, UY-loss=2503.8928, DYZ-loss=4075.9688\n",
      "[Valid] Epoch 2 Step 1451, lr(0.004000): loss=6048.5586, mse=177.9690, mae=9.9754, mape=0.4447, UY-loss=3335.9133, DYZ-loss=2534.6763\n",
      "sim_Y0_c_ask: 3.9540737 sim_U0_c_ask: -7.7173886 true_Y0_c_ask: 1.275 sim_Y0_p_ask: 226.2034 sim_U0_p_ask: 240.77556 true_Y0_p_ask: 224.75 sim_Z0_c_ask: 7.6136937 sim_Z0_p_ask: -467.03702\n",
      "[Train] Epoch 2 Step 1501, lr(0.004000): loss=2207.4221, mse=328.9052, mae=12.9422, mape=0.1930, UY-loss=1176.2135, DYZ-loss=702.3035\n",
      "[Valid] Epoch 2 Step 1501, lr(0.004000): loss=2116.5891, mse=287.4216, mae=13.2227, mape=0.6713, UY-loss=1311.0920, DYZ-loss=518.0754\n",
      "sim_Y0_c_ask: 321.70697 sim_U0_c_ask: 258.764 true_Y0_c_ask: 334.7 sim_Y0_p_ask: 20.12047 sim_U0_p_ask: 6.7401466 true_Y0_p_ask: 25.85 sim_Z0_c_ask: 492.7011 sim_Z0_p_ask: -12.935368\n",
      "[Train] Epoch 2 Step 1551, lr(0.004000): loss=2229.4097, mse=296.0872, mae=12.5263, mape=0.1775, UY-loss=1306.4489, DYZ-loss=626.8737\n",
      "[Valid] Epoch 2 Step 1551, lr(0.004000): loss=2268.0576, mse=193.1978, mae=10.4740, mape=0.2285, UY-loss=1478.4294, DYZ-loss=596.4302\n",
      "sim_Y0_c_ask: 171.99802 sim_U0_c_ask: 182.22813 true_Y0_c_ask: 162.60000000000002 sim_Y0_p_ask: 25.16252 sim_U0_p_ask: 92.80404 true_Y0_p_ask: 22.950000000000003 sim_Z0_c_ask: 475.19333 sim_Z0_p_ask: -130.76587\n",
      "[Train] Epoch 2 Step 1601, lr(0.004000): loss=2243.0649, mse=348.0367, mae=13.3726, mape=0.2546, UY-loss=1320.6455, DYZ-loss=574.3828\n",
      "[Valid] Epoch 2 Step 1601, lr(0.004000): loss=3617.3320, mse=282.8606, mae=12.8197, mape=0.3912, UY-loss=1780.7163, DYZ-loss=1553.7551\n",
      "sim_Y0_c_ask: 407.29376 sim_U0_c_ask: 307.9606 true_Y0_c_ask: 430.79999999999995 sim_Y0_p_ask: 326.61435 sim_U0_p_ask: 281.218 true_Y0_p_ask: 351.54999999999995 sim_Z0_c_ask: 529.9729 sim_Z0_p_ask: -475.53625\n",
      "[Train] Epoch 2 Step 1651, lr(0.004000): loss=6424.7300, mse=307.5530, mae=13.8983, mape=0.1609, UY-loss=3008.1895, DYZ-loss=3108.9875\n",
      "[Valid] Epoch 2 Step 1651, lr(0.004000): loss=9125.4121, mse=207.5420, mae=10.9262, mape=0.4589, UY-loss=5133.4341, DYZ-loss=3784.4365\n",
      "sim_Y0_c_ask: 972.73584 sim_U0_c_ask: 1028.2548 true_Y0_c_ask: 987.95 sim_Y0_p_ask: 1354.7345 sim_U0_p_ask: 1406.7927 true_Y0_p_ask: 1364.5 sim_Z0_c_ask: 543.12665 sim_Z0_p_ask: -450.9961\n",
      "[Train] Epoch 2 Step 1701, lr(0.004000): loss=7515.7236, mse=436.3345, mae=15.4843, mape=0.1912, UY-loss=2770.8149, DYZ-loss=4308.5742\n",
      "[Valid] Epoch 2 Step 1701, lr(0.004000): loss=3355.0461, mse=344.4931, mae=13.8159, mape=0.3673, UY-loss=2048.5586, DYZ-loss=961.9943\n",
      "sim_Y0_c_ask: 1849.1045 sim_U0_c_ask: 1960.1134 true_Y0_c_ask: 1837.5 sim_Y0_p_ask: 238.73514 sim_U0_p_ask: 244.00903 true_Y0_p_ask: 239.45 sim_Z0_c_ask: 539.7154 sim_Z0_p_ask: -483.9118\n",
      "[Train] Epoch 2 Step 1751, lr(0.004000): loss=1736.0190, mse=253.0785, mae=11.4456, mape=0.2729, UY-loss=1017.6614, DYZ-loss=465.2790\n",
      "[Valid] Epoch 2 Step 1751, lr(0.004000): loss=2529.7021, mse=180.8578, mae=10.0707, mape=0.2431, UY-loss=1509.2764, DYZ-loss=839.5680\n",
      "sim_Y0_c_ask: 20.72303 sim_U0_c_ask: 13.496601 true_Y0_c_ask: 15.95 sim_Y0_p_ask: 373.36108 sim_U0_p_ask: 376.0085 true_Y0_p_ask: 361.29999999999995 sim_Z0_c_ask: 25.932793 sim_Z0_p_ask: -533.56995\n",
      "[Train] Epoch 3 Step 1801, lr(0.004000): loss=1649.4001, mse=239.2951, mae=11.7445, mape=0.1755, UY-loss=1054.4783, DYZ-loss=355.6267\n",
      "[Valid] Epoch 3 Step 1801, lr(0.004000): loss=2340.8833, mse=298.6084, mae=13.9612, mape=0.3177, UY-loss=1169.1566, DYZ-loss=873.1183\n",
      "sim_Y0_c_ask: 131.71976 sim_U0_c_ask: 167.01411 true_Y0_c_ask: 114.75 sim_Y0_p_ask: 17.916718 sim_U0_p_ask: 11.093127 true_Y0_p_ask: 19.35 sim_Z0_c_ask: 93.26537 sim_Z0_p_ask: -7.1023474\n",
      "[Train] Epoch 3 Step 1851, lr(0.004000): loss=8992.0488, mse=519.6789, mae=15.8069, mape=0.3396, UY-loss=6958.8364, DYZ-loss=1513.5338\n",
      "[Valid] Epoch 3 Step 1851, lr(0.004000): loss=56951.2930, mse=466.6886, mae=15.0067, mape=0.1909, UY-loss=34350.4531, DYZ-loss=22134.1523\n",
      "sim_Y0_c_ask: 54.7099 sim_U0_c_ask: 3.034515 true_Y0_c_ask: 61.5 sim_Y0_p_ask: 277.31384 sim_U0_p_ask: 161.51859 true_Y0_p_ask: 249.7 sim_Z0_c_ask: 85.84553 sim_Z0_p_ask: -379.2837\n",
      "[Train] Epoch 3 Step 1901, lr(0.004000): loss=13655.6846, mse=526.7341, mae=17.4949, mape=0.3929, UY-loss=7148.1846, DYZ-loss=5980.7656\n",
      "[Valid] Epoch 3 Step 1901, lr(0.004000): loss=20744.4805, mse=347.5760, mae=14.1321, mape=0.2945, UY-loss=15183.2490, DYZ-loss=5213.6543\n",
      "sim_Y0_c_ask: 100.88206 sim_U0_c_ask: 98.97454 true_Y0_c_ask: 139.6 sim_Y0_p_ask: 97.43331 sim_U0_p_ask: 13.541038 true_Y0_p_ask: 117.65 sim_Z0_c_ask: 307.70328 sim_Z0_p_ask: -81.50656\n",
      "[Train] Epoch 3 Step 1951, lr(0.004000): loss=7941.5459, mse=689.7252, mae=19.8730, mape=0.4454, UY-loss=3347.3794, DYZ-loss=3904.4417\n",
      "[Valid] Epoch 3 Step 1951, lr(0.004000): loss=4988.6484, mse=262.9029, mae=11.6252, mape=0.4801, UY-loss=2676.9568, DYZ-loss=2048.7891\n",
      "sim_Y0_c_ask: 1605.7078 sim_U0_c_ask: 1622.2186 true_Y0_c_ask: 1598.5 sim_Y0_p_ask: 12.183798 sim_U0_p_ask: 39.625416 true_Y0_p_ask: 13.899999999999999 sim_Z0_c_ask: 551.60126 sim_Z0_p_ask: -95.709785\n",
      "[Train] Epoch 3 Step 2001, lr(0.004000): loss=2161.5708, mse=336.1099, mae=12.7674, mape=0.3676, UY-loss=1193.0964, DYZ-loss=632.3646\n",
      "[Valid] Epoch 3 Step 2001, lr(0.004000): loss=2705.5999, mse=310.6995, mae=13.1030, mape=0.4313, UY-loss=1495.3027, DYZ-loss=899.5976\n",
      "sim_Y0_c_ask: 109.590775 sim_U0_c_ask: 97.95554 true_Y0_c_ask: 137.3 sim_Y0_p_ask: 343.03052 sim_U0_p_ask: 336.49713 true_Y0_p_ask: 325.55 sim_Z0_c_ask: 309.30563 sim_Z0_p_ask: -513.54535\n",
      "[Train] Epoch 3 Step 2051, lr(0.004000): loss=1813.5199, mse=351.3018, mae=13.3768, mape=0.1735, UY-loss=1136.7029, DYZ-loss=325.5151\n",
      "[Valid] Epoch 3 Step 2051, lr(0.004000): loss=1843.8195, mse=169.5556, mae=9.5858, mape=0.2530, UY-loss=1252.4137, DYZ-loss=421.8502\n",
      "sim_Y0_c_ask: 212.96509 sim_U0_c_ask: 158.95352 true_Y0_c_ask: 258.15 sim_Y0_p_ask: 29.677094 sim_U0_p_ask: 18.717697 true_Y0_p_ask: 30.05 sim_Z0_c_ask: 299.67575 sim_Z0_p_ask: -7.7005897\n",
      "[Train] Epoch 3 Step 2101, lr(0.004000): loss=1623.8217, mse=312.4004, mae=13.2051, mape=0.1854, UY-loss=1017.8981, DYZ-loss=293.5231\n",
      "[Valid] Epoch 3 Step 2101, lr(0.004000): loss=1658.3081, mse=296.3935, mae=13.6724, mape=0.3808, UY-loss=1053.5221, DYZ-loss=308.3925\n",
      "sim_Y0_c_ask: 255.37506 sim_U0_c_ask: 252.06082 true_Y0_c_ask: 258.5 sim_Y0_p_ask: 52.057625 sim_U0_p_ask: 97.27291 true_Y0_p_ask: 32.35 sim_Z0_c_ask: 515.36163 sim_Z0_p_ask: -0.20077546\n",
      "[Train] Epoch 3 Step 2151, lr(0.004000): loss=1555.8530, mse=336.9361, mae=12.7953, mape=0.1823, UY-loss=930.7882, DYZ-loss=288.1287\n",
      "[Valid] Epoch 3 Step 2151, lr(0.004000): loss=2313.2202, mse=316.2919, mae=14.3859, mape=0.3726, UY-loss=1380.7944, DYZ-loss=616.1338\n",
      "sim_Y0_c_ask: 19.268219 sim_U0_c_ask: 6.598433 true_Y0_c_ask: 7.15 sim_Y0_p_ask: 149.55254 sim_U0_p_ask: 107.16074 true_Y0_p_ask: 172.2 sim_Z0_c_ask: 5.1031094 sim_Z0_p_ask: -60.133183\n",
      "[Train] Epoch 3 Step 2201, lr(0.004000): loss=2261.6865, mse=475.0789, mae=15.1229, mape=0.3452, UY-loss=1333.3855, DYZ-loss=453.2221\n",
      "[Valid] Epoch 3 Step 2201, lr(0.004000): loss=2452.4253, mse=265.6699, mae=11.2028, mape=0.3412, UY-loss=1322.4802, DYZ-loss=864.2750\n",
      "sim_Y0_c_ask: 82.146576 sim_U0_c_ask: 68.91159 true_Y0_c_ask: 68.65 sim_Y0_p_ask: 83.23167 sim_U0_p_ask: 89.56141 true_Y0_p_ask: 102.8 sim_Z0_c_ask: 97.84666 sim_Z0_p_ask: -250.36807\n",
      "[Train] Epoch 3 Step 2251, lr(0.004000): loss=1979.3049, mse=302.8777, mae=12.5688, mape=0.1549, UY-loss=1150.0260, DYZ-loss=526.4013\n",
      "[Valid] Epoch 3 Step 2251, lr(0.004000): loss=2352.9204, mse=314.6513, mae=13.2640, mape=0.4305, UY-loss=1543.5656, DYZ-loss=494.7037\n",
      "sim_Y0_c_ask: 19.198883 sim_U0_c_ask: -3.84337 true_Y0_c_ask: 18.6 sim_Y0_p_ask: 97.45914 sim_U0_p_ask: 70.49141 true_Y0_p_ask: 117.30000000000001 sim_Z0_c_ask: 29.035313 sim_Z0_p_ask: -93.28401\n",
      "[Train] Epoch 3 Step 2301, lr(0.004000): loss=2122.2964, mse=389.7844, mae=14.4734, mape=0.2214, UY-loss=1096.8368, DYZ-loss=635.6753\n",
      "[Valid] Epoch 3 Step 2301, lr(0.004000): loss=2790.7520, mse=258.5256, mae=12.5605, mape=0.2244, UY-loss=1894.8357, DYZ-loss=637.3906\n",
      "sim_Y0_c_ask: 528.25 sim_U0_c_ask: 488.70792 true_Y0_c_ask: 534.4 sim_Y0_p_ask: 28.899776 sim_U0_p_ask: 39.114704 true_Y0_p_ask: 32.45 sim_Z0_c_ask: 558.23553 sim_Z0_p_ask: 2.96487\n",
      "[Train] Epoch 3 Step 2351, lr(0.004000): loss=1878.8495, mse=282.4288, mae=12.0295, mape=0.2778, UY-loss=961.7068, DYZ-loss=634.7139\n",
      "[Valid] Epoch 3 Step 2351, lr(0.004000): loss=2115.9492, mse=236.2977, mae=11.3717, mape=0.2798, UY-loss=1183.6101, DYZ-loss=696.0413\n",
      "sim_Y0_c_ask: 353.2182 sim_U0_c_ask: 318.42676 true_Y0_c_ask: 346.35 sim_Y0_p_ask: 52.456734 sim_U0_p_ask: 35.940407 true_Y0_p_ask: 66.95 sim_Z0_c_ask: 516.1213 sim_Z0_p_ask: -74.39029\n",
      "[Train] Epoch 4 Step 2401, lr(0.004000): loss=1789.2574, mse=224.9289, mae=11.6408, mape=0.3340, UY-loss=1147.7598, DYZ-loss=416.5687\n",
      "[Valid] Epoch 4 Step 2401, lr(0.004000): loss=2458.1147, mse=289.7617, mae=13.7419, mape=0.3559, UY-loss=1375.4695, DYZ-loss=792.8835\n",
      "sim_Y0_c_ask: 4.650788 sim_U0_c_ask: 5.2437887 true_Y0_c_ask: 7.35 sim_Y0_p_ask: 25.563982 sim_U0_p_ask: 20.807213 true_Y0_p_ask: 18.15 sim_Z0_c_ask: 6.6663246 sim_Z0_p_ask: -10.377873\n",
      "[Train] Epoch 4 Step 2451, lr(0.004000): loss=1715.7365, mse=289.7010, mae=12.5731, mape=0.1648, UY-loss=1010.7005, DYZ-loss=415.3350\n",
      "[Valid] Epoch 4 Step 2451, lr(0.004000): loss=2559.1553, mse=408.4003, mae=16.9513, mape=0.3347, UY-loss=1685.5854, DYZ-loss=465.1693\n",
      "sim_Y0_c_ask: 17.811634 sim_U0_c_ask: 4.707928 true_Y0_c_ask: 7.9 sim_Y0_p_ask: 385.372 sim_U0_p_ask: 364.50275 true_Y0_p_ask: 387.35 sim_Z0_c_ask: 46.288715 sim_Z0_p_ask: -532.0822\n",
      "[Train] Epoch 4 Step 2501, lr(0.004000): loss=1653.0896, mse=257.9097, mae=12.2070, mape=0.2643, UY-loss=1050.1317, DYZ-loss=345.0482\n",
      "[Valid] Epoch 4 Step 2501, lr(0.004000): loss=2350.4783, mse=243.2862, mae=12.4579, mape=0.2826, UY-loss=1306.8945, DYZ-loss=800.2976\n",
      "sim_Y0_c_ask: 578.9171 sim_U0_c_ask: 564.6975 true_Y0_c_ask: 569.55 sim_Y0_p_ask: 26.350061 sim_U0_p_ask: 11.255713 true_Y0_p_ask: 43.7 sim_Z0_c_ask: 592.61664 sim_Z0_p_ask: -17.822914\n",
      "[Train] Epoch 4 Step 2551, lr(0.004000): loss=1937.3868, mse=296.3748, mae=12.4907, mape=0.1830, UY-loss=886.7071, DYZ-loss=754.3049\n",
      "[Valid] Epoch 4 Step 2551, lr(0.004000): loss=2237.3567, mse=322.1918, mae=14.5789, mape=0.4881, UY-loss=1174.4070, DYZ-loss=740.7579\n",
      "sim_Y0_c_ask: 21.299376 sim_U0_c_ask: 23.643068 true_Y0_c_ask: 9.45 sim_Y0_p_ask: 184.68039 sim_U0_p_ask: 146.45251 true_Y0_p_ask: 191.5 sim_Z0_c_ask: 171.59396 sim_Z0_p_ask: -81.32917\n",
      "[Train] Epoch 4 Step 2601, lr(0.004000): loss=2083.7676, mse=346.7525, mae=14.3845, mape=0.1732, UY-loss=1100.2242, DYZ-loss=636.7908\n",
      "[Valid] Epoch 4 Step 2601, lr(0.004000): loss=2861.9019, mse=352.1671, mae=14.5463, mape=0.4791, UY-loss=1378.0171, DYZ-loss=1131.7178\n",
      "sim_Y0_c_ask: 666.5166 sim_U0_c_ask: 629.1369 true_Y0_c_ask: 660.0 sim_Y0_p_ask: 31.00293 sim_U0_p_ask: 16.38839 true_Y0_p_ask: 25.6 sim_Z0_c_ask: 542.08704 sim_Z0_p_ask: -13.972926\n",
      "[Train] Epoch 4 Step 2651, lr(0.004000): loss=2780.1714, mse=277.5783, mae=12.6130, mape=0.1921, UY-loss=1442.4482, DYZ-loss=1060.1448\n",
      "[Valid] Epoch 4 Step 2651, lr(0.004000): loss=3630.2148, mse=322.8798, mae=13.7474, mape=0.2706, UY-loss=2006.1569, DYZ-loss=1301.1781\n",
      "sim_Y0_c_ask: 33.72493 sim_U0_c_ask: 11.262061 true_Y0_c_ask: 32.849999999999994 sim_Y0_p_ask: 193.39313 sim_U0_p_ask: 155.06644 true_Y0_p_ask: 164.4 sim_Z0_c_ask: 35.417797 sim_Z0_p_ask: -191.3765\n",
      "[Train] Epoch 4 Step 2701, lr(0.004000): loss=2354.7046, mse=294.0956, mae=12.8156, mape=0.1961, UY-loss=1252.8430, DYZ-loss=807.7659\n",
      "[Valid] Epoch 4 Step 2701, lr(0.004000): loss=2933.0510, mse=801.6445, mae=21.1964, mape=0.3815, UY-loss=1429.2378, DYZ-loss=702.1688\n",
      "sim_Y0_c_ask: 177.78929 sim_U0_c_ask: 92.793045 true_Y0_c_ask: 107.55000000000001 sim_Y0_p_ask: 710.1855 sim_U0_p_ask: 700.2551 true_Y0_p_ask: 709.75 sim_Z0_c_ask: 40.85371 sim_Z0_p_ask: -531.57825\n",
      "[Train] Epoch 4 Step 2751, lr(0.004000): loss=1798.8367, mse=362.7258, mae=13.6957, mape=0.2134, UY-loss=926.7572, DYZ-loss=509.3536\n",
      "[Valid] Epoch 4 Step 2751, lr(0.004000): loss=2140.3713, mse=375.8304, mae=14.8231, mape=0.4610, UY-loss=1150.5835, DYZ-loss=613.9575\n",
      "sim_Y0_c_ask: 174.89758 sim_U0_c_ask: 116.121735 true_Y0_c_ask: 179.0 sim_Y0_p_ask: 181.15454 sim_U0_p_ask: 154.18358 true_Y0_p_ask: 210.4 sim_Z0_c_ask: 306.86548 sim_Z0_p_ask: -254.62717\n",
      "[Train] Epoch 4 Step 2801, lr(0.004000): loss=1699.3831, mse=353.7720, mae=13.8239, mape=0.1775, UY-loss=920.2352, DYZ-loss=425.3759\n",
      "[Valid] Epoch 4 Step 2801, lr(0.004000): loss=1903.3357, mse=208.9617, mae=11.2638, mape=0.2490, UY-loss=1157.9248, DYZ-loss=536.4492\n",
      "sim_Y0_c_ask: 1.013077 sim_U0_c_ask: 2.9259613 true_Y0_c_ask: 4.0 sim_Y0_p_ask: 5.5697765 sim_U0_p_ask: 0.0093250275 true_Y0_p_ask: 12.5 sim_Z0_c_ask: 6.6220126 sim_Z0_p_ask: -13.8897085\n",
      "[Train] Epoch 4 Step 2851, lr(0.004000): loss=2902.6243, mse=264.4954, mae=12.2059, mape=0.1752, UY-loss=1236.8008, DYZ-loss=1401.3281\n",
      "[Valid] Epoch 4 Step 2851, lr(0.004000): loss=3018.7346, mse=321.5667, mae=13.9757, mape=0.2549, UY-loss=1561.2078, DYZ-loss=1135.9602\n",
      "sim_Y0_c_ask: 404.98535 sim_U0_c_ask: 384.36893 true_Y0_c_ask: 415.0 sim_Y0_p_ask: 476.91327 sim_U0_p_ask: 506.59924 true_Y0_p_ask: 547.15 sim_Z0_c_ask: 553.7055 sim_Z0_p_ask: -254.83897\n",
      "[Train] Epoch 4 Step 2901, lr(0.004000): loss=8678.0781, mse=360.1714, mae=14.1816, mape=0.2062, UY-loss=5935.1816, DYZ-loss=2382.7256\n",
      "[Valid] Epoch 4 Step 2901, lr(0.004000): loss=11699.6592, mse=241.6518, mae=11.6406, mape=0.2784, UY-loss=10042.2764, DYZ-loss=1415.7311\n",
      "sim_Y0_c_ask: 499.91516 sim_U0_c_ask: 481.7447 true_Y0_c_ask: 543.55 sim_Y0_p_ask: 224.40921 sim_U0_p_ask: 178.69164 true_Y0_p_ask: 212.89999999999998 sim_Z0_c_ask: 511.5762 sim_Z0_p_ask: -46.27594\n",
      "[Train] Epoch 5 Step 2951, lr(0.004000): loss=2440.9468, mse=239.4590, mae=11.6278, mape=0.2226, UY-loss=1061.0624, DYZ-loss=1140.4254\n",
      "[Valid] Epoch 5 Step 2951, lr(0.004000): loss=2133.8276, mse=285.4633, mae=13.7383, mape=0.3339, UY-loss=1365.8699, DYZ-loss=482.4944\n",
      "sim_Y0_c_ask: 99.30252 sim_U0_c_ask: 141.97238 true_Y0_c_ask: 110.95 sim_Y0_p_ask: 38.92813 sim_U0_p_ask: 25.88667 true_Y0_p_ask: 47.849999999999994 sim_Z0_c_ask: 411.0658 sim_Z0_p_ask: -7.827292\n",
      "[Train] Epoch 5 Step 3001, lr(0.004000): loss=1562.8088, mse=291.3675, mae=12.7773, mape=0.2030, UY-loss=1020.0007, DYZ-loss=251.4407\n",
      "[Valid] Epoch 5 Step 3001, lr(0.004000): loss=1547.2441, mse=186.4763, mae=10.3747, mape=0.3282, UY-loss=1019.8818, DYZ-loss=340.8859\n",
      "sim_Y0_c_ask: 16.529888 sim_U0_c_ask: 19.774195 true_Y0_c_ask: 26.5 sim_Y0_p_ask: 89.559326 sim_U0_p_ask: 74.07292 true_Y0_p_ask: 98.35 sim_Z0_c_ask: 15.2561865 sim_Z0_p_ask: -37.285572\n",
      "[Train] Epoch 5 Step 3051, lr(0.004000): loss=2556.1199, mse=299.0059, mae=12.6647, mape=0.1573, UY-loss=1015.5663, DYZ-loss=1241.5477\n",
      "[Valid] Epoch 5 Step 3051, lr(0.004000): loss=1812.5538, mse=251.7402, mae=12.7378, mape=0.3686, UY-loss=1049.3096, DYZ-loss=511.5040\n",
      "sim_Y0_c_ask: 229.46112 sim_U0_c_ask: 189.09955 true_Y0_c_ask: 284.3 sim_Y0_p_ask: 34.825348 sim_U0_p_ask: 40.264355 true_Y0_p_ask: 40.2 sim_Z0_c_ask: 479.8446 sim_Z0_p_ask: -11.168335\n",
      "[Train] Epoch 5 Step 3101, lr(0.004000): loss=2729.5818, mse=350.2222, mae=13.5762, mape=0.1885, UY-loss=1605.7439, DYZ-loss=773.6157\n",
      "[Valid] Epoch 5 Step 3101, lr(0.004000): loss=5221.4116, mse=418.0284, mae=14.7430, mape=0.4728, UY-loss=1741.1133, DYZ-loss=3062.2700\n",
      "sim_Y0_c_ask: 1865.571 sim_U0_c_ask: 1926.2805 true_Y0_c_ask: 1859.0 sim_Y0_p_ask: 100.04703 sim_U0_p_ask: 68.016884 true_Y0_p_ask: 87.2 sim_Z0_c_ask: 583.8619 sim_Z0_p_ask: -27.086754\n",
      "[Train] Epoch 5 Step 3151, lr(0.004000): loss=2117.4248, mse=210.1555, mae=10.7266, mape=0.4587, UY-loss=1216.7657, DYZ-loss=690.5035\n",
      "[Valid] Epoch 5 Step 3151, lr(0.004000): loss=2783.6472, mse=388.7166, mae=15.5308, mape=0.4406, UY-loss=1394.8381, DYZ-loss=1000.0925\n",
      "sim_Y0_c_ask: 507.73517 sim_U0_c_ask: 496.5093 true_Y0_c_ask: 519.1 sim_Y0_p_ask: 1316.0393 sim_U0_p_ask: 1321.3617 true_Y0_p_ask: 1316.5 sim_Z0_c_ask: 554.1194 sim_Z0_p_ask: -515.4049\n",
      "[Train] Epoch 5 Step 3201, lr(0.004000): loss=1838.3643, mse=169.4228, mae=9.3088, mape=0.1772, UY-loss=1104.8635, DYZ-loss=564.0779\n",
      "[Valid] Epoch 5 Step 3201, lr(0.004000): loss=2888.9565, mse=248.3159, mae=12.0582, mape=0.3439, UY-loss=941.0319, DYZ-loss=1699.6088\n",
      "sim_Y0_c_ask: 963.5755 sim_U0_c_ask: 945.61206 true_Y0_c_ask: 947.8499999999999 sim_Y0_p_ask: 132.63206 sim_U0_p_ask: 85.70146 true_Y0_p_ask: 160.4 sim_Z0_c_ask: 621.7829 sim_Z0_p_ask: -171.42894\n",
      "[Train] Epoch 5 Step 3251, lr(0.004000): loss=3365.4417, mse=436.5526, mae=15.8380, mape=0.2544, UY-loss=1279.8522, DYZ-loss=1649.0369\n",
      "[Valid] Epoch 5 Step 3251, lr(0.004000): loss=5339.2383, mse=264.1760, mae=12.3848, mape=0.4271, UY-loss=1805.9646, DYZ-loss=3269.0979\n",
      "sim_Y0_c_ask: 811.0615 sim_U0_c_ask: 799.4485 true_Y0_c_ask: 807.6500000000001 sim_Y0_p_ask: 15.012407 sim_U0_p_ask: 22.638159 true_Y0_p_ask: 22.8 sim_Z0_c_ask: 543.4581 sim_Z0_p_ask: -18.22152\n",
      "[Train] Epoch 5 Step 3301, lr(0.004000): loss=3020.0322, mse=234.4668, mae=11.7036, mape=0.1879, UY-loss=1197.6725, DYZ-loss=1587.8929\n",
      "[Valid] Epoch 5 Step 3301, lr(0.004000): loss=1730.6730, mse=433.6250, mae=16.9584, mape=0.3921, UY-loss=1056.1453, DYZ-loss=240.9027\n",
      "sim_Y0_c_ask: 665.5824 sim_U0_c_ask: 678.76306 true_Y0_c_ask: 672.3499999999999 sim_Y0_p_ask: 14.624569 sim_U0_p_ask: 20.220991 true_Y0_p_ask: 20.3 sim_Z0_c_ask: 536.4679 sim_Z0_p_ask: -2.1627717\n",
      "[Train] Epoch 5 Step 3351, lr(0.004000): loss=3450.7639, mse=249.3326, mae=11.4880, mape=0.1497, UY-loss=1456.9358, DYZ-loss=1744.4955\n",
      "[Valid] Epoch 5 Step 3351, lr(0.004000): loss=4829.1895, mse=384.0301, mae=14.4673, mape=0.3546, UY-loss=1640.3794, DYZ-loss=2804.7798\n",
      "sim_Y0_c_ask: 868.14844 sim_U0_c_ask: 847.6799 true_Y0_c_ask: 860.45 sim_Y0_p_ask: 268.29028 sim_U0_p_ask: 214.09239 true_Y0_p_ask: 241.45 sim_Z0_c_ask: 537.83936 sim_Z0_p_ask: -475.33286\n",
      "[Train] Epoch 5 Step 3401, lr(0.004000): loss=2866.3647, mse=292.5892, mae=12.3809, mape=0.1910, UY-loss=1038.8187, DYZ-loss=1534.9567\n",
      "[Valid] Epoch 5 Step 3401, lr(0.004000): loss=2808.9883, mse=246.7546, mae=11.6773, mape=0.2408, UY-loss=1344.6156, DYZ-loss=1217.6180\n",
      "sim_Y0_c_ask: 0.7267077 sim_U0_c_ask: -18.316755 true_Y0_c_ask: 1.075 sim_Y0_p_ask: 647.1396 sim_U0_p_ask: 710.0622 true_Y0_p_ask: 675.8499999999999 sim_Z0_c_ask: 14.188379 sim_Z0_p_ask: -349.52148\n",
      "[Train] Epoch 5 Step 3451, lr(0.004000): loss=8677.3662, mse=334.3080, mae=13.8289, mape=0.2931, UY-loss=6258.3550, DYZ-loss=2084.7031\n",
      "[Valid] Epoch 5 Step 3451, lr(0.004000): loss=3719.3479, mse=284.3683, mae=12.7922, mape=0.2473, UY-loss=1698.7804, DYZ-loss=1736.1992\n",
      "sim_Y0_c_ask: -0.72105294 sim_U0_c_ask: 12.04707 true_Y0_c_ask: 5.800000000000001 sim_Y0_p_ask: 201.71814 sim_U0_p_ask: 194.80562 true_Y0_p_ask: 206.95 sim_Z0_c_ask: 9.131509 sim_Z0_p_ask: -89.05534\n",
      "[Train] Epoch 5 Step 3501, lr(0.004000): loss=2037.7471, mse=253.6252, mae=12.0875, mape=0.1744, UY-loss=1043.3171, DYZ-loss=740.8047\n",
      "[Valid] Epoch 5 Step 3501, lr(0.004000): loss=1942.5579, mse=180.6995, mae=9.6393, mape=0.2351, UY-loss=976.1016, DYZ-loss=785.7567\n",
      "sim_Y0_c_ask: 260.4537 sim_U0_c_ask: 237.53253 true_Y0_c_ask: 281.8 sim_Y0_p_ask: 8.799879 sim_U0_p_ask: 0.9618056 true_Y0_p_ask: 9.85 sim_Z0_c_ask: 484.95157 sim_Z0_p_ask: -16.191236\n",
      "[Train] Epoch 6 Step 3551, lr(0.004000): loss=1944.6659, mse=355.0100, mae=13.7405, mape=0.2246, UY-loss=849.3661, DYZ-loss=740.2898\n",
      "[Valid] Epoch 6 Step 3551, lr(0.004000): loss=1998.5186, mse=225.2828, mae=11.3730, mape=0.1754, UY-loss=1257.3882, DYZ-loss=515.8477\n",
      "sim_Y0_c_ask: 693.912 sim_U0_c_ask: 693.8806 true_Y0_c_ask: 694.4 sim_Y0_p_ask: 426.58353 sim_U0_p_ask: 436.22244 true_Y0_p_ask: 462.85 sim_Z0_c_ask: 553.8753 sim_Z0_p_ask: -252.92531\n",
      "[Train] Epoch 6 Step 3601, lr(0.004000): loss=1735.8958, mse=243.4136, mae=11.7684, mape=0.2587, UY-loss=1109.5088, DYZ-loss=382.9734\n",
      "[Valid] Epoch 6 Step 3601, lr(0.004000): loss=2085.5742, mse=281.5498, mae=13.6491, mape=0.3480, UY-loss=965.1612, DYZ-loss=838.8633\n",
      "sim_Y0_c_ask: 697.58997 sim_U0_c_ask: 699.7744 true_Y0_c_ask: 694.45 sim_Y0_p_ask: 233.38739 sim_U0_p_ask: 216.08807 true_Y0_p_ask: 260.70000000000005 sim_Z0_c_ask: 559.63525 sim_Z0_p_ask: -161.52917\n",
      "[Train] Epoch 6 Step 3651, lr(0.004000): loss=1898.2725, mse=343.1596, mae=13.7795, mape=0.1896, UY-loss=947.1765, DYZ-loss=607.9364\n",
      "[Valid] Epoch 6 Step 3651, lr(0.004000): loss=2117.4814, mse=217.1042, mae=11.6734, mape=0.3580, UY-loss=1035.1477, DYZ-loss=865.2296\n",
      "sim_Y0_c_ask: 383.38052 sim_U0_c_ask: 387.78937 true_Y0_c_ask: 402.95 sim_Y0_p_ask: 597.60986 sim_U0_p_ask: 578.68243 true_Y0_p_ask: 614.2 sim_Z0_c_ask: 542.888 sim_Z0_p_ask: -363.80978\n",
      "[Train] Epoch 6 Step 3701, lr(0.004000): loss=2903.0317, mse=296.2711, mae=12.3162, mape=0.1356, UY-loss=1117.4486, DYZ-loss=1489.3120\n",
      "[Valid] Epoch 6 Step 3701, lr(0.004000): loss=2222.2783, mse=213.6871, mae=11.7274, mape=0.7081, UY-loss=1353.9286, DYZ-loss=654.6627\n",
      "sim_Y0_c_ask: 528.40234 sim_U0_c_ask: 493.36118 true_Y0_c_ask: 523.75 sim_Y0_p_ask: 1444.4003 sim_U0_p_ask: 1430.3812 true_Y0_p_ask: 1473.0 sim_Z0_c_ask: 545.28143 sim_Z0_p_ask: -539.3581\n",
      "[Train] Epoch 6 Step 3751, lr(0.004000): loss=5108.6606, mse=335.1139, mae=13.1040, mape=0.1406, UY-loss=2206.2393, DYZ-loss=2567.3076\n",
      "[Valid] Epoch 6 Step 3751, lr(0.004000): loss=4956.4990, mse=222.2604, mae=11.0884, mape=0.2847, UY-loss=2672.4119, DYZ-loss=2061.8269\n",
      "sim_Y0_c_ask: 12.524479 sim_U0_c_ask: 15.720436 true_Y0_c_ask: 17.4 sim_Y0_p_ask: 16.296627 sim_U0_p_ask: 15.473973 true_Y0_p_ask: 11.35 sim_Z0_c_ask: 81.17983 sim_Z0_p_ask: -14.037283\n",
      "[Train] Epoch 6 Step 3801, lr(0.004000): loss=2353.2051, mse=245.6542, mae=11.4644, mape=0.1368, UY-loss=1216.7620, DYZ-loss=890.7891\n",
      "[Valid] Epoch 6 Step 3801, lr(0.004000): loss=6883.0952, mse=384.2097, mae=14.9157, mape=0.3362, UY-loss=2034.1047, DYZ-loss=4464.7808\n",
      "sim_Y0_c_ask: 30.834839 sim_U0_c_ask: 27.777382 true_Y0_c_ask: 44.1 sim_Y0_p_ask: 104.774086 sim_U0_p_ask: 62.827724 true_Y0_p_ask: 137.64999999999998 sim_Z0_c_ask: 49.659763 sim_Z0_p_ask: -104.55492\n",
      "[Train] Epoch 6 Step 3851, lr(0.004000): loss=1577.4127, mse=229.2188, mae=11.9022, mape=0.2222, UY-loss=863.9012, DYZ-loss=484.2928\n",
      "[Valid] Epoch 6 Step 3851, lr(0.004000): loss=1655.2373, mse=221.5035, mae=12.0909, mape=0.3029, UY-loss=942.2545, DYZ-loss=491.4792\n",
      "sim_Y0_c_ask: 3.5088484 sim_U0_c_ask: 15.428779 true_Y0_c_ask: 2.875 sim_Y0_p_ask: 226.38408 sim_U0_p_ask: 188.6175 true_Y0_p_ask: 241.95 sim_Z0_c_ask: 116.22965 sim_Z0_p_ask: -144.5155\n",
      "[Train] Epoch 6 Step 3901, lr(0.004000): loss=1726.6624, mse=216.6419, mae=10.7147, mape=0.1539, UY-loss=890.4720, DYZ-loss=619.5483\n",
      "[Valid] Epoch 6 Step 3901, lr(0.004000): loss=1848.5240, mse=216.9201, mae=11.6605, mape=0.1585, UY-loss=1060.7583, DYZ-loss=570.8456\n",
      "sim_Y0_c_ask: 875.5061 sim_U0_c_ask: 893.1271 true_Y0_c_ask: 868.7 sim_Y0_p_ask: 799.1451 sim_U0_p_ask: 811.2992 true_Y0_p_ask: 780.7 sim_Z0_c_ask: 522.52484 sim_Z0_p_ask: -424.74695\n",
      "[Train] Epoch 6 Step 3951, lr(0.004000): loss=4462.3770, mse=282.6298, mae=12.4702, mape=0.2433, UY-loss=1278.4210, DYZ-loss=2901.3259\n",
      "[Valid] Epoch 6 Step 3951, lr(0.004000): loss=3307.6694, mse=144.7408, mae=8.9437, mape=0.2513, UY-loss=1227.0111, DYZ-loss=1935.9175\n",
      "sim_Y0_c_ask: 160.74248 sim_U0_c_ask: 101.75988 true_Y0_c_ask: 162.7 sim_Y0_p_ask: 91.46701 sim_U0_p_ask: 67.25293 true_Y0_p_ask: 117.4 sim_Z0_c_ask: 401.4114 sim_Z0_p_ask: -76.7055\n",
      "[Train] Epoch 6 Step 4001, lr(0.004000): loss=1826.8237, mse=218.7018, mae=10.8776, mape=0.1705, UY-loss=802.8028, DYZ-loss=805.3190\n",
      "[Valid] Epoch 6 Step 4001, lr(0.004000): loss=2529.6089, mse=214.7444, mae=11.3126, mape=0.3261, UY-loss=1455.9263, DYZ-loss=858.9383\n",
      "sim_Y0_c_ask: 416.71048 sim_U0_c_ask: 366.5228 true_Y0_c_ask: 428.75 sim_Y0_p_ask: 412.1223 sim_U0_p_ask: 418.3598 true_Y0_p_ask: 419.5 sim_Z0_c_ask: 448.7344 sim_Z0_p_ask: -502.77832\n",
      "[Train] Epoch 6 Step 4051, lr(0.004000): loss=1270.5231, mse=223.2805, mae=11.0613, mape=0.1630, UY-loss=714.7596, DYZ-loss=332.4829\n",
      "[Valid] Epoch 6 Step 4051, lr(0.004000): loss=1491.2051, mse=229.9557, mae=11.8350, mape=0.2090, UY-loss=844.7122, DYZ-loss=416.5373\n",
      "sim_Y0_c_ask: 95.84123 sim_U0_c_ask: 81.61278 true_Y0_c_ask: 105.94999999999999 sim_Y0_p_ask: 54.713783 sim_U0_p_ask: 39.268852 true_Y0_p_ask: 50.75 sim_Z0_c_ask: 224.5754 sim_Z0_p_ask: -12.482\n",
      "[Train] Epoch 6 Step 4101, lr(0.004000): loss=2130.7783, mse=251.4830, mae=11.9518, mape=0.1790, UY-loss=1343.4636, DYZ-loss=535.8317\n",
      "[Valid] Epoch 6 Step 4101, lr(0.004000): loss=2614.9548, mse=419.2519, mae=16.4456, mape=0.3558, UY-loss=1020.0590, DYZ-loss=1175.6440\n",
      "sim_Y0_c_ask: 874.24133 sim_U0_c_ask: 865.1117 true_Y0_c_ask: 880.4 sim_Y0_p_ask: 184.55223 sim_U0_p_ask: 184.95255 true_Y0_p_ask: 174.25 sim_Z0_c_ask: 491.4311 sim_Z0_p_ask: -473.43884\n",
      "[Train] Epoch 7 Step 4151, lr(0.004000): loss=3122.7498, mse=228.1177, mae=11.2709, mape=0.1984, UY-loss=1098.4082, DYZ-loss=1796.2239\n",
      "[Valid] Epoch 7 Step 4151, lr(0.004000): loss=4212.2207, mse=320.9450, mae=14.3031, mape=0.3793, UY-loss=1648.4275, DYZ-loss=2242.8479\n",
      "sim_Y0_c_ask: 8.861642 sim_U0_c_ask: 67.07614 true_Y0_c_ask: 0.325 sim_Y0_p_ask: 61.576515 sim_U0_p_ask: 64.34131 true_Y0_p_ask: 101.35 sim_Z0_c_ask: 222.48265 sim_Z0_p_ask: -66.230415\n",
      "[Train] Epoch 7 Step 4201, lr(0.004000): loss=54313.1484, mse=1781.7261, mae=29.9226, mape=1.1478, UY-loss=50376.5469, DYZ-loss=2154.8770\n",
      "[Valid] Epoch 7 Step 4201, lr(0.004000): loss=101944.5547, mse=1191.6333, mae=25.3977, mape=1.5515, UY-loss=65358.3750, DYZ-loss=35394.5469\n",
      "sim_Y0_c_ask: 544.79224 sim_U0_c_ask: 530.4132 true_Y0_c_ask: 539.85 sim_Y0_p_ask: 43.839493 sim_U0_p_ask: 27.100033 true_Y0_p_ask: 42.55 sim_Z0_c_ask: 546.6054 sim_Z0_p_ask: -21.54895\n",
      "[Train] Epoch 7 Step 4251, lr(0.004000): loss=3790.3706, mse=608.4193, mae=18.7297, mape=0.8503, UY-loss=2233.4470, DYZ-loss=948.5043\n",
      "[Valid] Epoch 7 Step 4251, lr(0.004000): loss=4312.1875, mse=692.4115, mae=16.3591, mape=0.5812, UY-loss=2591.5300, DYZ-loss=1028.2463\n",
      "sim_Y0_c_ask: 97.74214 sim_U0_c_ask: 46.691303 true_Y0_c_ask: 160.95 sim_Y0_p_ask: 457.02112 sim_U0_p_ask: 477.5947 true_Y0_p_ask: 443.5 sim_Z0_c_ask: 254.32771 sim_Z0_p_ask: -477.33112\n",
      "[Train] Epoch 7 Step 4301, lr(0.004000): loss=2052.4648, mse=374.7139, mae=13.4847, mape=0.2535, UY-loss=1311.1720, DYZ-loss=366.5788\n",
      "[Valid] Epoch 7 Step 4301, lr(0.004000): loss=2143.3342, mse=183.9300, mae=10.3988, mape=0.3057, UY-loss=1366.7178, DYZ-loss=592.6866\n",
      "sim_Y0_c_ask: 993.13135 sim_U0_c_ask: 999.5194 true_Y0_c_ask: 999.65 sim_Y0_p_ask: 72.25806 sim_U0_p_ask: 56.805508 true_Y0_p_ask: 78.6 sim_Z0_c_ask: 554.2204 sim_Z0_p_ask: -65.31685\n",
      "[Train] Epoch 7 Step 4351, lr(0.004000): loss=1652.7987, mse=342.9674, mae=12.9792, mape=0.1868, UY-loss=1063.8024, DYZ-loss=246.0289\n",
      "[Valid] Epoch 7 Step 4351, lr(0.004000): loss=1858.3374, mse=255.2416, mae=10.8471, mape=0.2302, UY-loss=1293.8516, DYZ-loss=309.2443\n",
      "sim_Y0_c_ask: 83.64252 sim_U0_c_ask: 17.159592 true_Y0_c_ask: 188.9 sim_Y0_p_ask: 41.250458 sim_U0_p_ask: 22.103746 true_Y0_p_ask: 47.75 sim_Z0_c_ask: 124.1824 sim_Z0_p_ask: -20.743692\n",
      "[Train] Epoch 7 Step 4401, lr(0.004000): loss=1887.9485, mse=532.9814, mae=16.1887, mape=0.3972, UY-loss=1089.8696, DYZ-loss=265.0975\n",
      "[Valid] Epoch 7 Step 4401, lr(0.004000): loss=1776.9830, mse=219.9550, mae=10.9642, mape=0.2233, UY-loss=1266.0005, DYZ-loss=291.0276\n",
      "sim_Y0_c_ask: 568.5957 sim_U0_c_ask: 572.6557 true_Y0_c_ask: 577.85 sim_Y0_p_ask: 25.116407 sim_U0_p_ask: 19.182625 true_Y0_p_ask: 22.0 sim_Z0_c_ask: 566.99133 sim_Z0_p_ask: -8.9124\n",
      "[Train] Epoch 7 Step 4451, lr(0.004000): loss=6051.9966, mse=362.4577, mae=13.5521, mape=0.5748, UY-loss=4319.4111, DYZ-loss=1370.1279\n",
      "[Valid] Epoch 7 Step 4451, lr(0.004000): loss=6770.2461, mse=174.7264, mae=9.5859, mape=0.3653, UY-loss=3012.2754, DYZ-loss=3583.2441\n",
      "sim_Y0_c_ask: 953.1998 sim_U0_c_ask: 954.34515 true_Y0_c_ask: 957.6500000000001 sim_Y0_p_ask: 151.091 sim_U0_p_ask: 75.99334 true_Y0_p_ask: 170.14999999999998 sim_Z0_c_ask: 559.509 sim_Z0_p_ask: -176.65955\n",
      "[Train] Epoch 7 Step 4501, lr(0.004000): loss=4639.3818, mse=390.9405, mae=14.4848, mape=0.2205, UY-loss=2153.1909, DYZ-loss=2095.2505\n",
      "[Valid] Epoch 7 Step 4501, lr(0.004000): loss=3120.4644, mse=265.6739, mae=11.9028, mape=0.1649, UY-loss=1822.4785, DYZ-loss=1032.3121\n",
      "sim_Y0_c_ask: 221.87714 sim_U0_c_ask: 219.15442 true_Y0_c_ask: 227.7 sim_Y0_p_ask: 286.60413 sim_U0_p_ask: 258.41263 true_Y0_p_ask: 271.85 sim_Z0_c_ask: 483.16162 sim_Z0_p_ask: -321.783\n",
      "[Train] Epoch 7 Step 4551, lr(0.004000): loss=1287.1970, mse=215.1455, mae=11.3014, mape=0.3157, UY-loss=899.7924, DYZ-loss=172.2592\n",
      "[Valid] Epoch 7 Step 4551, lr(0.004000): loss=1627.8110, mse=335.1624, mae=14.0806, mape=0.3730, UY-loss=1080.0717, DYZ-loss=212.5769\n",
      "sim_Y0_c_ask: 575.92944 sim_U0_c_ask: 541.5863 true_Y0_c_ask: 566.95 sim_Y0_p_ask: 459.97443 sim_U0_p_ask: 448.9647 true_Y0_p_ask: 471.45 sim_Z0_c_ask: 580.39014 sim_Z0_p_ask: -425.8066\n",
      "[Train] Epoch 7 Step 4601, lr(0.004000): loss=1525.6960, mse=256.9843, mae=11.3992, mape=0.1298, UY-loss=932.5792, DYZ-loss=336.1325\n",
      "[Valid] Epoch 7 Step 4601, lr(0.004000): loss=1413.5935, mse=240.0715, mae=13.0046, mape=0.2629, UY-loss=999.0874, DYZ-loss=174.4345\n",
      "sim_Y0_c_ask: 481.84192 sim_U0_c_ask: 473.21942 true_Y0_c_ask: 502.4 sim_Y0_p_ask: 31.224596 sim_U0_p_ask: 22.771059 true_Y0_p_ask: 24.6 sim_Z0_c_ask: 537.7292 sim_Z0_p_ask: -55.50853\n",
      "[Train] Epoch 7 Step 4651, lr(0.004000): loss=1563.2931, mse=296.8360, mae=12.1592, mape=0.2977, UY-loss=805.7770, DYZ-loss=460.6801\n",
      "[Valid] Epoch 7 Step 4651, lr(0.004000): loss=1512.1356, mse=234.2709, mae=11.9347, mape=0.3609, UY-loss=973.9257, DYZ-loss=303.9391\n",
      "sim_Y0_c_ask: 8.3852215 sim_U0_c_ask: 1.9569031 true_Y0_c_ask: 12.1 sim_Y0_p_ask: 28.397793 sim_U0_p_ask: 20.279999 true_Y0_p_ask: 23.85 sim_Z0_c_ask: 12.309358 sim_Z0_p_ask: -9.627403\n",
      "[Train] Epoch 7 Step 4701, lr(0.004000): loss=1154.5902, mse=227.1336, mae=11.1467, mape=0.1890, UY-loss=739.0471, DYZ-loss=188.4095\n",
      "[Valid] Epoch 7 Step 4701, lr(0.004000): loss=1705.6621, mse=452.3912, mae=17.6823, mape=0.3847, UY-loss=1012.4883, DYZ-loss=240.7827\n",
      "sim_Y0_c_ask: 255.85904 sim_U0_c_ask: 212.96373 true_Y0_c_ask: 299.35 sim_Y0_p_ask: 509.78235 sim_U0_p_ask: 522.8537 true_Y0_p_ask: 529.55 sim_Z0_c_ask: 312.95477 sim_Z0_p_ask: -376.16684\n",
      "[Train] Epoch 8 Step 4751, lr(0.004000): loss=1256.0708, mse=251.8008, mae=11.6790, mape=0.1737, UY-loss=784.0385, DYZ-loss=220.2315\n",
      "[Valid] Epoch 8 Step 4751, lr(0.004000): loss=1344.0391, mse=240.4139, mae=12.7559, mape=0.2754, UY-loss=805.7209, DYZ-loss=297.9041\n",
      "sim_Y0_c_ask: 309.5124 sim_U0_c_ask: 257.20233 true_Y0_c_ask: 322.25 sim_Y0_p_ask: 52.285835 sim_U0_p_ask: 29.686825 true_Y0_p_ask: 43.599999999999994 sim_Z0_c_ask: 404.42743 sim_Z0_p_ask: -9.639675\n",
      "[Train] Epoch 8 Step 4801, lr(0.004000): loss=2142.2783, mse=368.4002, mae=14.1309, mape=0.1927, UY-loss=965.7179, DYZ-loss=808.1602\n",
      "[Valid] Epoch 8 Step 4801, lr(0.004000): loss=2821.9634, mse=301.3974, mae=12.6236, mape=0.2164, UY-loss=1781.2126, DYZ-loss=739.3531\n",
      "sim_Y0_c_ask: 820.3553 sim_U0_c_ask: 839.2283 true_Y0_c_ask: 812.35 sim_Y0_p_ask: 250.51773 sim_U0_p_ask: 239.97963 true_Y0_p_ask: 259.95000000000005 sim_Z0_c_ask: 554.10944 sim_Z0_p_ask: -290.29337\n",
      "[Train] Epoch 8 Step 4851, lr(0.004000): loss=1307.4424, mse=254.3162, mae=11.5889, mape=0.2877, UY-loss=765.6133, DYZ-loss=287.5129\n",
      "[Valid] Epoch 8 Step 4851, lr(0.004000): loss=1840.1160, mse=205.0004, mae=11.6751, mape=0.4834, UY-loss=1138.0627, DYZ-loss=497.0527\n",
      "sim_Y0_c_ask: 1392.3055 sim_U0_c_ask: 1434.5405 true_Y0_c_ask: 1384.0 sim_Y0_p_ask: 67.1391 sim_U0_p_ask: 49.40811 true_Y0_p_ask: 69.15 sim_Z0_c_ask: 553.53705 sim_Z0_p_ask: -68.72325\n",
      "[Train] Epoch 8 Step 4901, lr(0.004000): loss=1240.9486, mse=281.7785, mae=12.3833, mape=0.1672, UY-loss=717.3459, DYZ-loss=241.8242\n",
      "[Valid] Epoch 8 Step 4901, lr(0.004000): loss=1574.7893, mse=383.3120, mae=16.3953, mape=0.3255, UY-loss=880.4790, DYZ-loss=310.9983\n",
      "sim_Y0_c_ask: 82.09757 sim_U0_c_ask: 39.59212 true_Y0_c_ask: 60.35 sim_Y0_p_ask: 77.97059 sim_U0_p_ask: 64.74045 true_Y0_p_ask: 65.45 sim_Z0_c_ask: 156.9661 sim_Z0_p_ask: -48.4414\n",
      "[Train] Epoch 8 Step 4951, lr(0.004000): loss=1407.4487, mse=225.9984, mae=10.7106, mape=0.2379, UY-loss=812.4508, DYZ-loss=368.9995\n",
      "[Valid] Epoch 8 Step 4951, lr(0.004000): loss=1506.1484, mse=331.3563, mae=15.2976, mape=0.2997, UY-loss=851.1091, DYZ-loss=323.6832\n",
      "sim_Y0_c_ask: 335.68927 sim_U0_c_ask: 339.15384 true_Y0_c_ask: 333.35 sim_Y0_p_ask: 126.49769 sim_U0_p_ask: 117.06578 true_Y0_p_ask: 142.55 sim_Z0_c_ask: 547.0871 sim_Z0_p_ask: -133.44849\n",
      "[Train] Epoch 8 Step 5001, lr(0.004000): loss=1241.1034, mse=231.1878, mae=11.0269, mape=0.1791, UY-loss=738.9526, DYZ-loss=270.9630\n",
      "[Valid] Epoch 8 Step 5001, lr(0.004000): loss=1416.0854, mse=243.7463, mae=12.0177, mape=0.1719, UY-loss=837.5034, DYZ-loss=334.8356\n",
      "sim_Y0_c_ask: 183.07266 sim_U0_c_ask: 114.263794 true_Y0_c_ask: 187.15 sim_Y0_p_ask: 413.50623 sim_U0_p_ask: 395.39093 true_Y0_p_ask: 416.25 sim_Z0_c_ask: 230.65369 sim_Z0_p_ask: -249.9074\n",
      "[Train] Epoch 8 Step 5051, lr(0.000400): loss=969.6058, mse=187.8982, mae=9.7707, mape=0.1438, UY-loss=592.5226, DYZ-loss=189.1850\n",
      "[Valid] Epoch 8 Step 5051, lr(0.000400): loss=1477.2301, mse=331.5117, mae=13.9391, mape=0.2916, UY-loss=917.2975, DYZ-loss=228.4211\n",
      "sim_Y0_c_ask: 332.80035 sim_U0_c_ask: 308.38464 true_Y0_c_ask: 337.04999999999995 sim_Y0_p_ask: 76.35271 sim_U0_p_ask: 67.57174 true_Y0_p_ask: 86.1 sim_Z0_c_ask: 349.43225 sim_Z0_p_ask: -34.283222\n",
      "[Train] Epoch 8 Step 5101, lr(0.000400): loss=1164.4934, mse=209.7923, mae=11.0516, mape=0.1215, UY-loss=743.2188, DYZ-loss=211.4824\n",
      "[Valid] Epoch 8 Step 5101, lr(0.000400): loss=1119.7212, mse=265.4796, mae=13.0070, mape=0.2178, UY-loss=671.5144, DYZ-loss=182.7272\n",
      "sim_Y0_c_ask: 1.6456753 sim_U0_c_ask: -1.4081284 true_Y0_c_ask: 5.6 sim_Y0_p_ask: 1740.7661 sim_U0_p_ask: 1741.056 true_Y0_p_ask: 1758.0 sim_Z0_c_ask: 11.163357 sim_Z0_p_ask: -522.18823\n",
      "[Train] Epoch 8 Step 5151, lr(0.000400): loss=997.3795, mse=214.5749, mae=10.5563, mape=0.1774, UY-loss=599.2209, DYZ-loss=183.5837\n",
      "[Valid] Epoch 8 Step 5151, lr(0.000400): loss=1467.8398, mse=282.7229, mae=13.5812, mape=0.3558, UY-loss=954.6217, DYZ-loss=230.4952\n",
      "sim_Y0_c_ask: 62.259632 sim_U0_c_ask: 38.43887 true_Y0_c_ask: 85.0 sim_Y0_p_ask: 107.580666 sim_U0_p_ask: 89.63082 true_Y0_p_ask: 91.4 sim_Z0_c_ask: 154.0675 sim_Z0_p_ask: -95.73362\n",
      "[Train] Epoch 8 Step 5201, lr(0.000400): loss=1037.2310, mse=209.2274, mae=10.6006, mape=0.2804, UY-loss=619.8984, DYZ-loss=208.1052\n",
      "[Valid] Epoch 8 Step 5201, lr(0.000400): loss=1447.8937, mse=373.8173, mae=15.1147, mape=0.3462, UY-loss=855.1632, DYZ-loss=218.9132\n",
      "sim_Y0_c_ask: 18.575815 sim_U0_c_ask: 17.982212 true_Y0_c_ask: 24.799999999999997 sim_Y0_p_ask: 339.25418 sim_U0_p_ask: 325.62228 true_Y0_p_ask: 350.95 sim_Z0_c_ask: 4.663811 sim_Z0_p_ask: -253.04901\n",
      "[Train] Epoch 8 Step 5251, lr(0.000400): loss=1169.8992, mse=231.1592, mae=11.5888, mape=0.1688, UY-loss=749.0122, DYZ-loss=189.7278\n",
      "[Valid] Epoch 8 Step 5251, lr(0.000400): loss=1264.3428, mse=264.2369, mae=13.3166, mape=0.4035, UY-loss=794.8446, DYZ-loss=205.2612\n",
      "sim_Y0_c_ask: 683.5968 sim_U0_c_ask: 682.9813 true_Y0_c_ask: 673.45 sim_Y0_p_ask: 577.36865 sim_U0_p_ask: 579.97296 true_Y0_p_ask: 572.2 sim_Z0_c_ask: 581.63556 sim_Z0_p_ask: -541.0929\n",
      "[Train] Epoch 8 Step 5301, lr(0.000400): loss=1049.3759, mse=248.6256, mae=11.0898, mape=0.1585, UY-loss=612.3553, DYZ-loss=188.3951\n",
      "[Valid] Epoch 8 Step 5301, lr(0.000400): loss=1243.2592, mse=262.1122, mae=13.0858, mape=0.3124, UY-loss=775.4598, DYZ-loss=205.6871\n",
      "sim_Y0_c_ask: 812.673 sim_U0_c_ask: 815.7827 true_Y0_c_ask: 804.05 sim_Y0_p_ask: 160.58253 sim_U0_p_ask: 139.35318 true_Y0_p_ask: 160.6 sim_Z0_c_ask: 560.1177 sim_Z0_p_ask: -150.24713\n",
      "[Train] Epoch 9 Step 5351, lr(0.000400): loss=1201.2196, mse=252.4537, mae=11.9445, mape=0.1398, UY-loss=758.5958, DYZ-loss=190.1701\n",
      "[Valid] Epoch 9 Step 5351, lr(0.000400): loss=1198.1831, mse=303.8595, mae=14.0418, mape=0.2897, UY-loss=710.9703, DYZ-loss=183.3533\n",
      "sim_Y0_c_ask: 606.81586 sim_U0_c_ask: 600.3326 true_Y0_c_ask: 593.3 sim_Y0_p_ask: 84.380356 sim_U0_p_ask: 75.617516 true_Y0_p_ask: 107.4 sim_Z0_c_ask: 592.9043 sim_Z0_p_ask: -222.2897\n",
      "[Train] Epoch 9 Step 5401, lr(0.000400): loss=1047.3386, mse=174.2249, mae=10.0434, mape=0.1745, UY-loss=700.2045, DYZ-loss=172.9092\n",
      "[Valid] Epoch 9 Step 5401, lr(0.000400): loss=1340.2261, mse=298.9530, mae=14.0778, mape=0.2653, UY-loss=853.6199, DYZ-loss=187.6532\n",
      "sim_Y0_c_ask: 787.75696 sim_U0_c_ask: 789.86365 true_Y0_c_ask: 781.7 sim_Y0_p_ask: 269.98224 sim_U0_p_ask: 266.01816 true_Y0_p_ask: 249.35 sim_Z0_c_ask: 576.2553 sim_Z0_p_ask: -359.59375\n",
      "[Train] Epoch 9 Step 5451, lr(0.000400): loss=1101.6514, mse=202.3024, mae=10.8323, mape=0.1273, UY-loss=709.6677, DYZ-loss=189.6813\n",
      "[Valid] Epoch 9 Step 5451, lr(0.000400): loss=1407.3518, mse=312.6018, mae=14.1027, mape=0.2636, UY-loss=871.5246, DYZ-loss=223.2253\n",
      "sim_Y0_c_ask: 289.0427 sim_U0_c_ask: 252.57245 true_Y0_c_ask: 303.65 sim_Y0_p_ask: 645.56976 sim_U0_p_ask: 659.9254 true_Y0_p_ask: 641.55 sim_Z0_c_ask: 391.25598 sim_Z0_p_ask: -459.53558\n",
      "[Train] Epoch 9 Step 5501, lr(0.000400): loss=980.1288, mse=182.2396, mae=10.0067, mape=0.4120, UY-loss=626.8849, DYZ-loss=171.0043\n",
      "[Valid] Epoch 9 Step 5501, lr(0.000400): loss=1246.5743, mse=287.6224, mae=13.3147, mape=0.3021, UY-loss=775.4971, DYZ-loss=183.4549\n",
      "sim_Y0_c_ask: 77.71623 sim_U0_c_ask: 52.26827 true_Y0_c_ask: 76.4 sim_Y0_p_ask: 202.15979 sim_U0_p_ask: 198.43375 true_Y0_p_ask: 228.8 sim_Z0_c_ask: 132.31699 sim_Z0_p_ask: -224.85666\n",
      "[Train] Epoch 9 Step 5551, lr(0.000400): loss=1040.7821, mse=224.7005, mae=10.7168, mape=0.2171, UY-loss=639.0308, DYZ-loss=177.0508\n",
      "[Valid] Epoch 9 Step 5551, lr(0.000400): loss=1235.1108, mse=303.8525, mae=14.3264, mape=0.3945, UY-loss=744.6073, DYZ-loss=186.6511\n",
      "sim_Y0_c_ask: 959.4134 sim_U0_c_ask: 970.0823 true_Y0_c_ask: 969.2 sim_Y0_p_ask: 50.875343 sim_U0_p_ask: 47.115532 true_Y0_p_ask: 50.85 sim_Z0_c_ask: 513.6643 sim_Z0_p_ask: -14.407749\n",
      "[Train] Epoch 9 Step 5601, lr(0.000400): loss=1050.3544, mse=187.6082, mae=9.8486, mape=0.1839, UY-loss=687.2366, DYZ-loss=175.5096\n",
      "[Valid] Epoch 9 Step 5601, lr(0.000400): loss=1243.4951, mse=291.2243, mae=13.3260, mape=0.2262, UY-loss=753.0612, DYZ-loss=199.2096\n",
      "sim_Y0_c_ask: 11.070719 sim_U0_c_ask: 33.620327 true_Y0_c_ask: 6.15 sim_Y0_p_ask: 187.80373 sim_U0_p_ask: 167.05844 true_Y0_p_ask: 177.45 sim_Z0_c_ask: 216.34326 sim_Z0_p_ask: -128.60811\n",
      "[Train] Epoch 9 Step 5651, lr(0.000400): loss=1071.0167, mse=184.3445, mae=10.3136, mape=0.2703, UY-loss=708.4553, DYZ-loss=178.2169\n",
      "[Valid] Epoch 9 Step 5651, lr(0.000400): loss=1233.4169, mse=264.4347, mae=13.0775, mape=0.4542, UY-loss=759.4589, DYZ-loss=209.5233\n",
      "sim_Y0_c_ask: 45.63645 sim_U0_c_ask: 19.655134 true_Y0_c_ask: 53.05 sim_Y0_p_ask: 659.9369 sim_U0_p_ask: 664.6322 true_Y0_p_ask: 662.45 sim_Z0_c_ask: 45.691372 sim_Z0_p_ask: -407.67673\n",
      "[Train] Epoch 9 Step 5701, lr(0.000400): loss=1054.7865, mse=205.1182, mae=10.6805, mape=0.1552, UY-loss=665.4425, DYZ-loss=184.2258\n",
      "[Valid] Epoch 9 Step 5701, lr(0.000400): loss=1166.8906, mse=280.1343, mae=13.3832, mape=0.2292, UY-loss=704.3727, DYZ-loss=182.3836\n",
      "sim_Y0_c_ask: 180.22574 sim_U0_c_ask: 141.44514 true_Y0_c_ask: 171.55 sim_Y0_p_ask: 233.81718 sim_U0_p_ask: 203.49167 true_Y0_p_ask: 233.35 sim_Z0_c_ask: 415.38745 sim_Z0_p_ask: -118.5018\n",
      "[Train] Epoch 9 Step 5751, lr(0.000400): loss=947.6898, mse=190.6783, mae=10.5203, mape=0.1883, UY-loss=590.4115, DYZ-loss=166.6000\n",
      "[Valid] Epoch 9 Step 5751, lr(0.000400): loss=1194.2798, mse=263.8511, mae=13.6006, mape=0.4758, UY-loss=722.4174, DYZ-loss=208.0113\n",
      "sim_Y0_c_ask: 77.38396 sim_U0_c_ask: 67.13587 true_Y0_c_ask: 83.85 sim_Y0_p_ask: 373.54645 sim_U0_p_ask: 382.7388 true_Y0_p_ask: 394.45 sim_Z0_c_ask: 12.716277 sim_Z0_p_ask: -447.9613\n",
      "[Train] Epoch 9 Step 5801, lr(0.000400): loss=1054.2893, mse=241.0796, mae=11.9290, mape=0.3604, UY-loss=636.8849, DYZ-loss=176.3246\n",
      "[Valid] Epoch 9 Step 5801, lr(0.000400): loss=1414.1079, mse=365.2224, mae=14.7116, mape=0.3681, UY-loss=856.7254, DYZ-loss=192.1601\n",
      "sim_Y0_c_ask: 119.38438 sim_U0_c_ask: 78.215195 true_Y0_c_ask: 131.5 sim_Y0_p_ask: 569.5519 sim_U0_p_ask: 573.8502 true_Y0_p_ask: 544.3 sim_Z0_c_ask: 93.05558 sim_Z0_p_ask: -501.26996\n",
      "[Train] Epoch 9 Step 5851, lr(0.000400): loss=1088.7728, mse=232.6511, mae=11.2778, mape=0.1257, UY-loss=681.1118, DYZ-loss=175.0099\n",
      "[Valid] Epoch 9 Step 5851, lr(0.000400): loss=1299.0100, mse=353.9825, mae=14.4567, mape=0.3540, UY-loss=752.3586, DYZ-loss=192.6688\n",
      "sim_Y0_c_ask: 316.46112 sim_U0_c_ask: 289.74506 true_Y0_c_ask: 304.1 sim_Y0_p_ask: 27.369297 sim_U0_p_ask: 24.51437 true_Y0_p_ask: 24.5 sim_Z0_c_ask: 513.52826 sim_Z0_p_ask: -26.56772\n",
      "[Train] Epoch 10 Step 5901, lr(0.000400): loss=1014.3171, mse=205.0977, mae=10.5321, mape=0.1909, UY-loss=630.0796, DYZ-loss=179.1398\n",
      "[Valid] Epoch 10 Step 5901, lr(0.000400): loss=1265.5353, mse=348.1016, mae=14.5309, mape=0.2819, UY-loss=754.0818, DYZ-loss=163.3518\n",
      "sim_Y0_c_ask: 3.2560678 sim_U0_c_ask: 3.1947567 true_Y0_c_ask: 1.975 sim_Y0_p_ask: 21.484077 sim_U0_p_ask: 20.865925 true_Y0_p_ask: 36.85 sim_Z0_c_ask: 5.28968 sim_Z0_p_ask: -19.961477\n",
      "[Train] Epoch 10 Step 5951, lr(0.000400): loss=969.3542, mse=227.8407, mae=10.5623, mape=0.1528, UY-loss=596.5894, DYZ-loss=144.9242\n",
      "[Valid] Epoch 10 Step 5951, lr(0.000400): loss=1098.1355, mse=289.9404, mae=13.8564, mape=0.2975, UY-loss=646.9611, DYZ-loss=161.2339\n",
      "sim_Y0_c_ask: 998.17017 sim_U0_c_ask: 998.1569 true_Y0_c_ask: 995.9 sim_Y0_p_ask: 70.53404 sim_U0_p_ask: 61.327488 true_Y0_p_ask: 54.8 sim_Z0_c_ask: 557.164 sim_Z0_p_ask: -72.0031\n",
      "[Train] Epoch 10 Step 6001, lr(0.000400): loss=907.4965, mse=195.0277, mae=10.5579, mape=0.1363, UY-loss=569.1609, DYZ-loss=143.3079\n",
      "[Valid] Epoch 10 Step 6001, lr(0.000400): loss=1164.3062, mse=287.8554, mae=12.8336, mape=0.3015, UY-loss=720.3876, DYZ-loss=156.0631\n",
      "sim_Y0_c_ask: 815.5763 sim_U0_c_ask: 819.9189 true_Y0_c_ask: 826.8499999999999 sim_Y0_p_ask: 199.857 sim_U0_p_ask: 179.42815 true_Y0_p_ask: 195.9 sim_Z0_c_ask: 493.14136 sim_Z0_p_ask: -245.85518\n",
      "[Train] Epoch 10 Step 6051, lr(0.000400): loss=898.6205, mse=205.1365, mae=10.3368, mape=0.1383, UY-loss=548.2581, DYZ-loss=145.2258\n",
      "[Valid] Epoch 10 Step 6051, lr(0.000400): loss=1174.0040, mse=304.6806, mae=13.3247, mape=0.3061, UY-loss=704.0968, DYZ-loss=165.2266\n",
      "sim_Y0_c_ask: 4.443139 sim_U0_c_ask: 0.5792178 true_Y0_c_ask: 2.175 sim_Y0_p_ask: 119.60326 sim_U0_p_ask: 104.96989 true_Y0_p_ask: 97.65 sim_Z0_c_ask: 12.965986 sim_Z0_p_ask: -118.861946\n",
      "[Train] Epoch 10 Step 6101, lr(0.000400): loss=873.4438, mse=211.5392, mae=10.6456, mape=0.2247, UY-loss=533.0887, DYZ-loss=128.8159\n",
      "[Valid] Epoch 10 Step 6101, lr(0.000400): loss=1242.1559, mse=345.1108, mae=14.9890, mape=0.3716, UY-loss=723.0524, DYZ-loss=173.9928\n",
      "sim_Y0_c_ask: 348.57416 sim_U0_c_ask: 320.27026 true_Y0_c_ask: 324.25 sim_Y0_p_ask: 108.37324 sim_U0_p_ask: 85.8794 true_Y0_p_ask: 95.85 sim_Z0_c_ask: 537.07916 sim_Z0_p_ask: -88.841194\n",
      "[Train] Epoch 10 Step 6151, lr(0.000400): loss=825.9488, mse=208.9222, mae=10.6070, mape=0.1665, UY-loss=483.6900, DYZ-loss=133.3365\n",
      "[Valid] Epoch 10 Step 6151, lr(0.000400): loss=1073.7963, mse=299.1467, mae=13.6384, mape=0.3320, UY-loss=624.7152, DYZ-loss=149.9344\n",
      "sim_Y0_c_ask: 729.7592 sim_U0_c_ask: 728.78796 true_Y0_c_ask: 718.25 sim_Y0_p_ask: 643.085 sim_U0_p_ask: 654.2705 true_Y0_p_ask: 644.6500000000001 sim_Z0_c_ask: 591.6121 sim_Z0_p_ask: -525.63043\n",
      "[Train] Epoch 10 Step 6201, lr(0.000400): loss=786.7646, mse=208.3996, mae=10.6485, mape=0.1328, UY-loss=452.4185, DYZ-loss=125.9466\n",
      "[Valid] Epoch 10 Step 6201, lr(0.000400): loss=924.3970, mse=271.0724, mae=13.2632, mape=0.1798, UY-loss=526.6268, DYZ-loss=126.6978\n",
      "sim_Y0_c_ask: 577.6367 sim_U0_c_ask: 567.6869 true_Y0_c_ask: 597.55 sim_Y0_p_ask: 29.705215 sim_U0_p_ask: 26.700237 true_Y0_p_ask: 33.2 sim_Z0_c_ask: 495.15344 sim_Z0_p_ask: -28.344687\n",
      "[Train] Epoch 10 Step 6251, lr(0.000400): loss=864.2816, mse=178.1880, mae=9.9441, mape=0.1491, UY-loss=554.7869, DYZ-loss=131.3066\n",
      "[Valid] Epoch 10 Step 6251, lr(0.000400): loss=1233.0369, mse=333.7592, mae=14.9379, mape=0.3729, UY-loss=755.7670, DYZ-loss=143.5106\n",
      "sim_Y0_c_ask: 10.057248 sim_U0_c_ask: 18.999763 true_Y0_c_ask: 5.25 sim_Y0_p_ask: 292.17352 sim_U0_p_ask: 296.84805 true_Y0_p_ask: 305.2 sim_Z0_c_ask: 8.146775 sim_Z0_p_ask: -459.34415\n",
      "[Train] Epoch 10 Step 6301, lr(0.000400): loss=969.6366, mse=223.2713, mae=11.0576, mape=0.1385, UY-loss=614.3516, DYZ-loss=132.0137\n",
      "[Valid] Epoch 10 Step 6301, lr(0.000400): loss=1085.7455, mse=294.5225, mae=13.7288, mape=0.2897, UY-loss=640.8149, DYZ-loss=150.4081\n",
      "sim_Y0_c_ask: 549.4984 sim_U0_c_ask: 540.1042 true_Y0_c_ask: 545.8 sim_Y0_p_ask: 16.069462 sim_U0_p_ask: 16.355263 true_Y0_p_ask: 18.6 sim_Z0_c_ask: 451.0189 sim_Z0_p_ask: -5.178882\n",
      "[Train] Epoch 10 Step 6351, lr(0.000400): loss=816.0518, mse=161.7795, mae=9.3673, mape=0.1687, UY-loss=526.7931, DYZ-loss=127.4792\n",
      "[Valid] Epoch 10 Step 6351, lr(0.000400): loss=1124.1876, mse=293.4031, mae=13.8408, mape=0.2235, UY-loss=668.8431, DYZ-loss=161.9414\n",
      "sim_Y0_c_ask: 731.9551 sim_U0_c_ask: 737.67694 true_Y0_c_ask: 730.25 sim_Y0_p_ask: 394.09363 sim_U0_p_ask: 397.7134 true_Y0_p_ask: 393.25 sim_Z0_c_ask: 569.7624 sim_Z0_p_ask: -555.7202\n",
      "[Train] Epoch 10 Step 6401, lr(0.000400): loss=949.1957, mse=208.8107, mae=10.2217, mape=0.1915, UY-loss=598.2755, DYZ-loss=142.1095\n",
      "[Valid] Epoch 10 Step 6401, lr(0.000400): loss=984.1282, mse=251.3063, mae=12.2684, mape=0.1937, UY-loss=584.8397, DYZ-loss=147.9823\n",
      "sim_Y0_c_ask: 216.20198 sim_U0_c_ask: 179.04472 true_Y0_c_ask: 198.05 sim_Y0_p_ask: 49.221 sim_U0_p_ask: 40.86868 true_Y0_p_ask: 48.55 sim_Z0_c_ask: 441.83643 sim_Z0_p_ask: -34.50362\n",
      "[Train] Epoch 10 Step 6451, lr(0.000400): loss=737.4487, mse=188.7764, mae=9.6467, mape=0.1699, UY-loss=423.4900, DYZ-loss=125.1823\n",
      "[Valid] Epoch 10 Step 6451, lr(0.000400): loss=1091.4215, mse=321.0523, mae=13.5890, mape=0.3366, UY-loss=605.2503, DYZ-loss=165.1189\n",
      "sim_Y0_c_ask: 442.75525 sim_U0_c_ask: 443.37204 true_Y0_c_ask: 444.05 sim_Y0_p_ask: 47.00641 sim_U0_p_ask: 42.518364 true_Y0_p_ask: 69.44999999999999 sim_Z0_c_ask: 535.38477 sim_Z0_p_ask: -65.16769\n",
      "[Train] Epoch 11 Step 6501, lr(0.000400): loss=846.7692, mse=217.7725, mae=10.4568, mape=0.1803, UY-loss=498.7603, DYZ-loss=130.2364\n",
      "[Valid] Epoch 11 Step 6501, lr(0.000400): loss=1126.7563, mse=294.1750, mae=13.4162, mape=0.1886, UY-loss=686.2296, DYZ-loss=146.3517\n",
      "sim_Y0_c_ask: 1004.0216 sim_U0_c_ask: 1030.9668 true_Y0_c_ask: 1010.7 sim_Y0_p_ask: 895.84216 sim_U0_p_ask: 899.1253 true_Y0_p_ask: 890.0 sim_Z0_c_ask: 486.8483 sim_Z0_p_ask: -542.705\n",
      "[Train] Epoch 11 Step 6551, lr(0.000400): loss=716.8674, mse=172.2891, mae=9.7434, mape=0.1660, UY-loss=423.7121, DYZ-loss=120.8662\n",
      "[Valid] Epoch 11 Step 6551, lr(0.000400): loss=1192.3162, mse=362.5223, mae=14.4542, mape=0.2198, UY-loss=679.9059, DYZ-loss=149.8880\n",
      "sim_Y0_c_ask: 27.587547 sim_U0_c_ask: 27.32788 true_Y0_c_ask: 20.6 sim_Y0_p_ask: 77.64589 sim_U0_p_ask: 64.34011 true_Y0_p_ask: 77.45 sim_Z0_c_ask: 24.89402 sim_Z0_p_ask: -61.88782\n",
      "[Train] Epoch 11 Step 6601, lr(0.000400): loss=948.2571, mse=204.9486, mae=10.7377, mape=0.1577, UY-loss=596.8949, DYZ-loss=146.4135\n",
      "[Valid] Epoch 11 Step 6601, lr(0.000400): loss=978.4537, mse=302.4862, mae=13.4721, mape=0.2551, UY-loss=549.4429, DYZ-loss=126.5245\n",
      "sim_Y0_c_ask: 361.0728 sim_U0_c_ask: 351.18857 true_Y0_c_ask: 407.35 sim_Y0_p_ask: 801.7039 sim_U0_p_ask: 810.32324 true_Y0_p_ask: 801.5 sim_Z0_c_ask: 456.63885 sim_Z0_p_ask: -551.80066\n",
      "[Train] Epoch 11 Step 6651, lr(0.000400): loss=776.7181, mse=165.7199, mae=9.1495, mape=0.1317, UY-loss=489.3398, DYZ-loss=121.6585\n",
      "[Valid] Epoch 11 Step 6651, lr(0.000400): loss=1163.9882, mse=335.1051, mae=13.9688, mape=0.2920, UY-loss=663.9330, DYZ-loss=164.9500\n",
      "sim_Y0_c_ask: 792.02075 sim_U0_c_ask: 823.11426 true_Y0_c_ask: 812.5 sim_Y0_p_ask: 14.135918 sim_U0_p_ask: 15.895358 true_Y0_p_ask: 19.0 sim_Z0_c_ask: 463.71542 sim_Z0_p_ask: -4.447897\n",
      "[Train] Epoch 11 Step 6701, lr(0.000400): loss=802.4811, mse=214.2330, mae=10.5882, mape=0.2455, UY-loss=473.6486, DYZ-loss=114.5996\n",
      "[Valid] Epoch 11 Step 6701, lr(0.000400): loss=1068.3848, mse=322.5413, mae=14.1427, mape=0.2395, UY-loss=612.2574, DYZ-loss=133.5861\n",
      "sim_Y0_c_ask: 18.77192 sim_U0_c_ask: 15.26581 true_Y0_c_ask: 12.399999999999999 sim_Y0_p_ask: 616.7356 sim_U0_p_ask: 637.72107 true_Y0_p_ask: 624.55 sim_Z0_c_ask: 26.014332 sim_Z0_p_ask: -296.74866\n",
      "[Train] Epoch 11 Step 6751, lr(0.000400): loss=835.2717, mse=172.7037, mae=9.8050, mape=0.1077, UY-loss=538.0060, DYZ-loss=124.5620\n",
      "[Valid] Epoch 11 Step 6751, lr(0.000400): loss=916.4515, mse=273.5146, mae=12.7698, mape=0.2323, UY-loss=514.2748, DYZ-loss=128.6620\n",
      "sim_Y0_c_ask: 72.23166 sim_U0_c_ask: 56.368088 true_Y0_c_ask: 59.0 sim_Y0_p_ask: 321.5614 sim_U0_p_ask: 319.77988 true_Y0_p_ask: 310.95 sim_Z0_c_ask: 129.96938 sim_Z0_p_ask: -467.4011\n",
      "[Train] Epoch 11 Step 6801, lr(0.000400): loss=717.8620, mse=218.7782, mae=10.7514, mape=0.1276, UY-loss=391.1349, DYZ-loss=107.9489\n",
      "[Valid] Epoch 11 Step 6801, lr(0.000400): loss=964.7080, mse=300.1689, mae=13.9385, mape=0.2512, UY-loss=536.0042, DYZ-loss=128.5349\n",
      "sim_Y0_c_ask: 1457.8425 sim_U0_c_ask: 1455.8954 true_Y0_c_ask: 1457.5 sim_Y0_p_ask: 64.936516 sim_U0_p_ask: 52.7849 true_Y0_p_ask: 79.25 sim_Z0_c_ask: 535.9756 sim_Z0_p_ask: -69.50607\n",
      "[Train] Epoch 11 Step 6851, lr(0.000400): loss=833.9257, mse=163.5323, mae=9.6703, mape=0.1440, UY-loss=554.5717, DYZ-loss=115.8217\n",
      "[Valid] Epoch 11 Step 6851, lr(0.000400): loss=850.8649, mse=240.0893, mae=12.1937, mape=0.1976, UY-loss=489.3271, DYZ-loss=121.4484\n",
      "sim_Y0_c_ask: 0.60876745 sim_U0_c_ask: 0.77111566 true_Y0_c_ask: 0.65 sim_Y0_p_ask: 79.27779 sim_U0_p_ask: 69.095764 true_Y0_p_ask: 82.65 sim_Z0_c_ask: 0.8753406 sim_Z0_p_ask: -62.66403\n",
      "[Train] Epoch 11 Step 6901, lr(0.000400): loss=750.7092, mse=199.0830, mae=10.3874, mape=0.1114, UY-loss=439.8771, DYZ-loss=111.7491\n",
      "[Valid] Epoch 11 Step 6901, lr(0.000400): loss=1103.1125, mse=330.0350, mae=14.0835, mape=0.2216, UY-loss=639.6770, DYZ-loss=133.4005\n",
      "sim_Y0_c_ask: 67.34606 sim_U0_c_ask: 61.60993 true_Y0_c_ask: 88.5 sim_Y0_p_ask: 195.26213 sim_U0_p_ask: 179.70285 true_Y0_p_ask: 203.0 sim_Z0_c_ask: 150.5891 sim_Z0_p_ask: -123.71477\n",
      "[Train] Epoch 11 Step 6951, lr(0.000400): loss=753.1044, mse=163.4115, mae=9.4990, mape=0.1114, UY-loss=472.0648, DYZ-loss=117.6280\n",
      "[Valid] Epoch 11 Step 6951, lr(0.000400): loss=940.2210, mse=285.4020, mae=13.9238, mape=0.2396, UY-loss=524.3699, DYZ-loss=130.4492\n",
      "sim_Y0_c_ask: 497.39725 sim_U0_c_ask: 475.06116 true_Y0_c_ask: 477.0 sim_Y0_p_ask: 28.05708 sim_U0_p_ask: 30.948786 true_Y0_p_ask: 34.3 sim_Z0_c_ask: 498.53806 sim_Z0_p_ask: -23.020363\n",
      "[Train] Epoch 11 Step 7001, lr(0.000400): loss=824.8932, mse=183.4263, mae=9.9512, mape=0.1233, UY-loss=514.3785, DYZ-loss=127.0884\n",
      "[Valid] Epoch 11 Step 7001, lr(0.000400): loss=998.6852, mse=287.3434, mae=13.7979, mape=0.3563, UY-loss=542.7963, DYZ-loss=168.5455\n",
      "sim_Y0_c_ask: 1630.7559 sim_U0_c_ask: 1665.3164 true_Y0_c_ask: 1621.5 sim_Y0_p_ask: 362.32352 sim_U0_p_ask: 364.75012 true_Y0_p_ask: 348.65 sim_Z0_c_ask: 487.45813 sim_Z0_p_ask: -409.9093\n",
      "[Train] Epoch 11 Step 7051, lr(0.000400): loss=895.6676, mse=247.6424, mae=10.8766, mape=0.1061, UY-loss=508.9731, DYZ-loss=139.0521\n",
      "[Valid] Epoch 11 Step 7051, lr(0.000400): loss=1052.3052, mse=351.1418, mae=14.2576, mape=0.2149, UY-loss=564.9174, DYZ-loss=136.2461\n",
      "sim_Y0_c_ask: -0.07609391 sim_U0_c_ask: 3.1992772 true_Y0_c_ask: 0.22499999999999998 sim_Y0_p_ask: 265.84027 sim_U0_p_ask: 266.46338 true_Y0_p_ask: 265.15 sim_Z0_c_ask: 19.921152 sim_Z0_p_ask: -480.2423\n",
      "[Train] Epoch 12 Step 7101, lr(0.000400): loss=761.4647, mse=174.3337, mae=9.6962, mape=0.1382, UY-loss=456.8224, DYZ-loss=130.3087\n",
      "[Valid] Epoch 12 Step 7101, lr(0.000400): loss=993.6716, mse=248.9592, mae=12.6722, mape=0.3240, UY-loss=579.5892, DYZ-loss=165.1231\n",
      "sim_Y0_c_ask: 390.25443 sim_U0_c_ask: 369.18484 true_Y0_c_ask: 389.0 sim_Y0_p_ask: 189.43141 sim_U0_p_ask: 188.46913 true_Y0_p_ask: 235.3 sim_Z0_c_ask: 364.10287 sim_Z0_p_ask: -124.99985\n",
      "[Train] Epoch 12 Step 7151, lr(0.000400): loss=1013.9384, mse=244.3325, mae=11.3581, mape=0.2002, UY-loss=557.0922, DYZ-loss=212.5137\n",
      "[Valid] Epoch 12 Step 7151, lr(0.000400): loss=1141.7045, mse=333.2049, mae=15.1396, mape=0.5042, UY-loss=570.9302, DYZ-loss=237.5694\n",
      "sim_Y0_c_ask: -1.8355836 sim_U0_c_ask: 0.63379055 true_Y0_c_ask: 0.025 sim_Y0_p_ask: 31.780863 sim_U0_p_ask: 29.324306 true_Y0_p_ask: 24.2 sim_Z0_c_ask: 21.676844 sim_Z0_p_ask: -20.912144\n",
      "[Train] Epoch 12 Step 7201, lr(0.000400): loss=719.7891, mse=168.3164, mae=9.5580, mape=0.3929, UY-loss=432.4884, DYZ-loss=118.9843\n",
      "[Valid] Epoch 12 Step 7201, lr(0.000400): loss=927.7021, mse=272.7037, mae=13.7560, mape=0.3422, UY-loss=518.7744, DYZ-loss=136.2241\n",
      "sim_Y0_c_ask: 572.4073 sim_U0_c_ask: 561.53894 true_Y0_c_ask: 588.0999999999999 sim_Y0_p_ask: 111.14552 sim_U0_p_ask: 97.43624 true_Y0_p_ask: 93.95 sim_Z0_c_ask: 455.67694 sim_Z0_p_ask: -119.81738\n",
      "[Train] Epoch 12 Step 7251, lr(0.000400): loss=809.2298, mse=206.9684, mae=10.8054, mape=0.1681, UY-loss=480.5238, DYZ-loss=121.7375\n",
      "[Valid] Epoch 12 Step 7251, lr(0.000400): loss=1133.1473, mse=399.0678, mae=15.6896, mape=0.2850, UY-loss=595.9194, DYZ-loss=138.1601\n",
      "sim_Y0_c_ask: 106.74069 sim_U0_c_ask: 95.27896 true_Y0_c_ask: 112.05000000000001 sim_Y0_p_ask: 286.55127 sim_U0_p_ask: 296.1315 true_Y0_p_ask: 315.70000000000005 sim_Z0_c_ask: 262.00607 sim_Z0_p_ask: -327.8649\n",
      "[Train] Epoch 12 Step 7301, lr(0.000400): loss=814.9321, mse=212.0451, mae=10.3551, mape=0.1556, UY-loss=473.3052, DYZ-loss=129.5819\n",
      "[Valid] Epoch 12 Step 7301, lr(0.000400): loss=970.4868, mse=273.6845, mae=13.0989, mape=0.2722, UY-loss=540.8932, DYZ-loss=155.9091\n",
      "sim_Y0_c_ask: 141.25943 sim_U0_c_ask: 128.20398 true_Y0_c_ask: 164.9 sim_Y0_p_ask: 35.072704 sim_U0_p_ask: 30.450066 true_Y0_p_ask: 41.0 sim_Z0_c_ask: 364.9429 sim_Z0_p_ask: -24.498442\n",
      "[Train] Epoch 12 Step 7351, lr(0.000400): loss=935.7665, mse=225.6752, mae=11.1266, mape=0.2202, UY-loss=547.1743, DYZ-loss=162.9171\n",
      "[Valid] Epoch 12 Step 7351, lr(0.000400): loss=951.2627, mse=252.4944, mae=12.9454, mape=0.2981, UY-loss=524.5350, DYZ-loss=174.2332\n",
      "sim_Y0_c_ask: 934.6144 sim_U0_c_ask: 937.0192 true_Y0_c_ask: 941.75 sim_Y0_p_ask: 330.93402 sim_U0_p_ask: 333.68488 true_Y0_p_ask: 334.3 sim_Z0_c_ask: 512.1616 sim_Z0_p_ask: -371.0902\n",
      "[Train] Epoch 12 Step 7401, lr(0.000400): loss=798.1284, mse=195.3314, mae=10.2147, mape=0.1238, UY-loss=465.8539, DYZ-loss=136.9431\n",
      "[Valid] Epoch 12 Step 7401, lr(0.000400): loss=1135.0271, mse=337.8815, mae=14.6487, mape=0.2726, UY-loss=612.7617, DYZ-loss=184.3840\n",
      "sim_Y0_c_ask: 487.3268 sim_U0_c_ask: 496.29846 true_Y0_c_ask: 520.55 sim_Y0_p_ask: 1812.1814 sim_U0_p_ask: 1815.0286 true_Y0_p_ask: 1807.0 sim_Z0_c_ask: 462.90088 sim_Z0_p_ask: -558.62115\n",
      "[Train] Epoch 12 Step 7451, lr(0.000400): loss=766.3043, mse=200.0151, mae=9.9989, mape=0.1217, UY-loss=425.9539, DYZ-loss=140.3353\n",
      "[Valid] Epoch 12 Step 7451, lr(0.000400): loss=992.7841, mse=267.0054, mae=13.0316, mape=0.2567, UY-loss=564.6965, DYZ-loss=161.0821\n",
      "sim_Y0_c_ask: 672.4398 sim_U0_c_ask: 665.72974 true_Y0_c_ask: 667.15 sim_Y0_p_ask: 52.39788 sim_U0_p_ask: 39.165104 true_Y0_p_ask: 58.05 sim_Z0_c_ask: 524.5693 sim_Z0_p_ask: -52.876366\n",
      "[Train] Epoch 12 Step 7501, lr(0.000400): loss=858.6845, mse=218.6800, mae=11.2645, mape=0.1244, UY-loss=469.0263, DYZ-loss=170.9782\n",
      "[Valid] Epoch 12 Step 7501, lr(0.000400): loss=1375.8448, mse=437.7388, mae=17.6487, mape=0.3012, UY-loss=713.7903, DYZ-loss=224.3157\n",
      "sim_Y0_c_ask: 1199.9028 sim_U0_c_ask: 1204.3306 true_Y0_c_ask: 1205.5 sim_Y0_p_ask: 15.849325 sim_U0_p_ask: 15.546689 true_Y0_p_ask: 18.35 sim_Z0_c_ask: 541.26697 sim_Z0_p_ask: -2.7984045\n",
      "[Train] Epoch 12 Step 7551, lr(0.000400): loss=930.0414, mse=221.4137, mae=10.6386, mape=0.1424, UY-loss=532.6579, DYZ-loss=175.9698\n",
      "[Valid] Epoch 12 Step 7551, lr(0.000400): loss=1078.4395, mse=219.7618, mae=11.8268, mape=0.2178, UY-loss=643.4969, DYZ-loss=215.1808\n",
      "sim_Y0_c_ask: 598.28296 sim_U0_c_ask: 593.0462 true_Y0_c_ask: 590.05 sim_Y0_p_ask: 45.24633 sim_U0_p_ask: 48.90509 true_Y0_p_ask: 44.8 sim_Z0_c_ask: 508.68826 sim_Z0_p_ask: -53.35226\n",
      "[Train] Epoch 12 Step 7601, lr(0.000400): loss=721.8754, mse=188.6052, mae=10.1292, mape=0.1258, UY-loss=393.8503, DYZ-loss=139.4198\n",
      "[Valid] Epoch 12 Step 7601, lr(0.000400): loss=1042.4144, mse=294.5606, mae=13.2163, mape=0.2199, UY-loss=599.7274, DYZ-loss=148.1265\n",
      "sim_Y0_c_ask: 273.60388 sim_U0_c_ask: 272.4573 true_Y0_c_ask: 297.85 sim_Y0_p_ask: 263.98798 sim_U0_p_ask: 263.34534 true_Y0_p_ask: 247.6 sim_Z0_c_ask: 484.2995 sim_Z0_p_ask: -410.90994\n",
      "[Train] Epoch 12 Step 7651, lr(0.000400): loss=698.0003, mse=172.4456, mae=9.4027, mape=0.1264, UY-loss=402.8511, DYZ-loss=122.7035\n",
      "[Valid] Epoch 12 Step 7651, lr(0.000400): loss=1032.2618, mse=334.1182, mae=15.2680, mape=0.2343, UY-loss=532.8375, DYZ-loss=165.3062\n",
      "sim_Y0_c_ask: 203.0413 sim_U0_c_ask: 151.63173 true_Y0_c_ask: 169.45 sim_Y0_p_ask: 37.12386 sim_U0_p_ask: 32.010727 true_Y0_p_ask: 42.900000000000006 sim_Z0_c_ask: 249.71472 sim_Z0_p_ask: -35.924118\n",
      "[Train] Epoch 13 Step 7701, lr(0.000400): loss=729.8767, mse=202.3820, mae=10.3676, mape=0.1586, UY-loss=404.5369, DYZ-loss=122.9579\n",
      "[Valid] Epoch 13 Step 7701, lr(0.000400): loss=1000.5330, mse=328.0565, mae=14.8691, mape=0.2903, UY-loss=532.1446, DYZ-loss=140.3319\n",
      "sim_Y0_c_ask: 403.1953 sim_U0_c_ask: 393.7097 true_Y0_c_ask: 382.85 sim_Y0_p_ask: 16.843843 sim_U0_p_ask: 16.307474 true_Y0_p_ask: 21.9 sim_Z0_c_ask: 502.40494 sim_Z0_p_ask: -10.446998\n",
      "[Train] Epoch 13 Step 7751, lr(0.000400): loss=857.1472, mse=196.8642, mae=10.3772, mape=0.0956, UY-loss=493.4154, DYZ-loss=166.8676\n",
      "[Valid] Epoch 13 Step 7751, lr(0.000400): loss=1043.8575, mse=277.1577, mae=13.6318, mape=0.2131, UY-loss=609.0465, DYZ-loss=157.6533\n",
      "sim_Y0_c_ask: 301.6817 sim_U0_c_ask: 307.93335 true_Y0_c_ask: 326.65 sim_Y0_p_ask: 60.129517 sim_U0_p_ask: 51.990665 true_Y0_p_ask: 59.5 sim_Z0_c_ask: 510.14142 sim_Z0_p_ask: -23.904924\n",
      "[Train] Epoch 13 Step 7801, lr(0.000400): loss=771.6630, mse=199.9441, mae=9.8585, mape=0.1323, UY-loss=416.9821, DYZ-loss=154.7368\n",
      "[Valid] Epoch 13 Step 7801, lr(0.000400): loss=929.8577, mse=270.1817, mae=13.3861, mape=0.3644, UY-loss=512.4455, DYZ-loss=147.2304\n",
      "sim_Y0_c_ask: 571.55396 sim_U0_c_ask: 572.0241 true_Y0_c_ask: 566.8 sim_Y0_p_ask: 13.908918 sim_U0_p_ask: 12.737167 true_Y0_p_ask: 12.399999999999999 sim_Z0_c_ask: 550.2072 sim_Z0_p_ask: -7.22776\n",
      "[Train] Epoch 13 Step 7851, lr(0.000400): loss=756.3722, mse=216.7683, mae=10.9522, mape=0.1377, UY-loss=408.2291, DYZ-loss=131.3748\n",
      "[Valid] Epoch 13 Step 7851, lr(0.000400): loss=1133.1155, mse=395.2082, mae=15.8082, mape=0.2308, UY-loss=581.7874, DYZ-loss=156.1200\n",
      "sim_Y0_c_ask: 168.30936 sim_U0_c_ask: 152.04399 true_Y0_c_ask: 173.45 sim_Y0_p_ask: 329.78958 sim_U0_p_ask: 342.48486 true_Y0_p_ask: 352.5 sim_Z0_c_ask: 421.22296 sim_Z0_p_ask: -455.03802\n",
      "[Train] Epoch 13 Step 7901, lr(0.000400): loss=842.2729, mse=226.7202, mae=10.7589, mape=0.1396, UY-loss=477.1210, DYZ-loss=138.4317\n",
      "[Valid] Epoch 13 Step 7901, lr(0.000400): loss=882.3884, mse=265.5361, mae=12.5520, mape=0.2116, UY-loss=472.5174, DYZ-loss=144.3350\n",
      "sim_Y0_c_ask: 610.90955 sim_U0_c_ask: 616.1306 true_Y0_c_ask: 626.95 sim_Y0_p_ask: 184.5753 sim_U0_p_ask: 190.69865 true_Y0_p_ask: 211.3 sim_Z0_c_ask: 496.43698 sim_Z0_p_ask: -109.23127\n",
      "[Train] Epoch 13 Step 7951, lr(0.000400): loss=770.6552, mse=198.8329, mae=10.5517, mape=0.1073, UY-loss=442.6391, DYZ-loss=129.1831\n",
      "[Valid] Epoch 13 Step 7951, lr(0.000400): loss=1057.0480, mse=293.8328, mae=13.5474, mape=0.2170, UY-loss=595.1273, DYZ-loss=168.0878\n",
      "sim_Y0_c_ask: 42.888878 sim_U0_c_ask: 36.869495 true_Y0_c_ask: 53.3 sim_Y0_p_ask: 293.81018 sim_U0_p_ask: 299.9222 true_Y0_p_ask: 293.8 sim_Z0_c_ask: 186.56987 sim_Z0_p_ask: -300.3206\n",
      "[Train] Epoch 13 Step 8001, lr(0.000400): loss=955.3123, mse=200.3635, mae=10.6113, mape=0.1770, UY-loss=569.3370, DYZ-loss=185.6117\n",
      "[Valid] Epoch 13 Step 8001, lr(0.000400): loss=951.1177, mse=309.7459, mae=14.2318, mape=0.2518, UY-loss=502.0342, DYZ-loss=139.3376\n",
      "sim_Y0_c_ask: 981.4112 sim_U0_c_ask: 981.83185 true_Y0_c_ask: 985.2 sim_Y0_p_ask: 71.01747 sim_U0_p_ask: 53.761272 true_Y0_p_ask: 80.6 sim_Z0_c_ask: 540.0844 sim_Z0_p_ask: -101.45276\n",
      "[Train] Epoch 13 Step 8051, lr(0.000400): loss=999.0667, mse=219.4781, mae=11.0288, mape=0.1064, UY-loss=601.2173, DYZ-loss=178.3713\n",
      "[Valid] Epoch 13 Step 8051, lr(0.000400): loss=1142.7937, mse=331.0898, mae=14.4722, mape=0.2024, UY-loss=633.8732, DYZ-loss=177.8307\n",
      "sim_Y0_c_ask: 602.3793 sim_U0_c_ask: 597.03033 true_Y0_c_ask: 595.9000000000001 sim_Y0_p_ask: 564.886 sim_U0_p_ask: 561.9817 true_Y0_p_ask: 566.2 sim_Z0_c_ask: 512.58655 sim_Z0_p_ask: -589.9903\n",
      "[Train] Epoch 13 Step 8101, lr(0.000400): loss=913.8285, mse=162.1767, mae=9.0970, mape=0.1331, UY-loss=572.9374, DYZ-loss=178.7144\n",
      "[Valid] Epoch 13 Step 8101, lr(0.000400): loss=1185.7833, mse=350.0250, mae=15.3417, mape=0.2399, UY-loss=682.8083, DYZ-loss=152.9500\n",
      "sim_Y0_c_ask: 110.139496 sim_U0_c_ask: 109.21501 true_Y0_c_ask: 112.05 sim_Y0_p_ask: 44.104485 sim_U0_p_ask: 31.159397 true_Y0_p_ask: 48.35 sim_Z0_c_ask: 381.5747 sim_Z0_p_ask: -17.57337\n",
      "[Train] Epoch 13 Step 8151, lr(0.000400): loss=862.8167, mse=193.4350, mae=10.3092, mape=0.1662, UY-loss=503.7670, DYZ-loss=165.6146\n",
      "[Valid] Epoch 13 Step 8151, lr(0.000400): loss=1159.7615, mse=249.5381, mae=13.0491, mape=0.3420, UY-loss=609.7224, DYZ-loss=300.5011\n",
      "sim_Y0_c_ask: 38.340836 sim_U0_c_ask: 41.270782 true_Y0_c_ask: 44.85 sim_Y0_p_ask: 563.646 sim_U0_p_ask: 571.2965 true_Y0_p_ask: 580.75 sim_Z0_c_ask: 132.25359 sim_Z0_p_ask: -502.78784\n",
      "[Train] Epoch 13 Step 8201, lr(0.000400): loss=844.7601, mse=226.6860, mae=11.1734, mape=0.1800, UY-loss=455.3481, DYZ-loss=162.7260\n",
      "[Valid] Epoch 13 Step 8201, lr(0.000400): loss=1162.6322, mse=312.5374, mae=14.2770, mape=0.2355, UY-loss=649.4619, DYZ-loss=200.6328\n",
      "sim_Y0_c_ask: 100.93834 sim_U0_c_ask: 102.048294 true_Y0_c_ask: 130.39999999999998 sim_Y0_p_ask: 134.7197 sim_U0_p_ask: 130.71065 true_Y0_p_ask: 159.85 sim_Z0_c_ask: 238.10133 sim_Z0_p_ask: -202.55014\n",
      "[Train] Epoch 13 Step 8251, lr(0.000400): loss=860.2947, mse=217.0439, mae=10.8950, mape=0.1498, UY-loss=498.9173, DYZ-loss=144.3335\n",
      "[Valid] Epoch 13 Step 8251, lr(0.000400): loss=1085.8484, mse=314.2188, mae=13.7658, mape=0.2224, UY-loss=623.7815, DYZ-loss=147.8480\n",
      "sim_Y0_c_ask: 218.12006 sim_U0_c_ask: 209.28963 true_Y0_c_ask: 223.35000000000002 sim_Y0_p_ask: 65.23566 sim_U0_p_ask: 56.872032 true_Y0_p_ask: 79.0 sim_Z0_c_ask: 483.58002 sim_Z0_p_ask: -31.833662\n",
      "[Train] Epoch 14 Step 8301, lr(0.000400): loss=703.6282, mse=212.2988, mae=10.6907, mape=0.1084, UY-loss=380.0110, DYZ-loss=111.3184\n",
      "[Valid] Epoch 14 Step 8301, lr(0.000400): loss=955.9915, mse=302.1334, mae=13.8352, mape=0.2118, UY-loss=524.1682, DYZ-loss=129.6900\n",
      "sim_Y0_c_ask: 921.3594 sim_U0_c_ask: 919.36646 true_Y0_c_ask: 919.6500000000001 sim_Y0_p_ask: 247.58093 sim_U0_p_ask: 255.54767 true_Y0_p_ask: 247.60000000000002 sim_Z0_c_ask: 534.837 sim_Z0_p_ask: -428.2463\n",
      "[Train] Epoch 14 Step 8351, lr(0.000400): loss=777.7584, mse=182.3021, mae=9.7194, mape=0.1080, UY-loss=480.0671, DYZ-loss=115.3891\n",
      "[Valid] Epoch 14 Step 8351, lr(0.000400): loss=943.5004, mse=352.0806, mae=15.5070, mape=0.2652, UY-loss=467.2827, DYZ-loss=124.1371\n",
      "sim_Y0_c_ask: 1076.7017 sim_U0_c_ask: 1080.0688 true_Y0_c_ask: 1075.5 sim_Y0_p_ask: 68.91627 sim_U0_p_ask: 57.638084 true_Y0_p_ask: 65.2 sim_Z0_c_ask: 551.7847 sim_Z0_p_ask: -122.98504\n",
      "[Train] Epoch 14 Step 8401, lr(0.000400): loss=941.4088, mse=182.4764, mae=10.0887, mape=0.1044, UY-loss=594.3580, DYZ-loss=164.5744\n",
      "[Valid] Epoch 14 Step 8401, lr(0.000400): loss=807.1454, mse=242.9177, mae=12.2382, mape=0.2107, UY-loss=419.2714, DYZ-loss=144.9563\n",
      "sim_Y0_c_ask: 815.3686 sim_U0_c_ask: 819.36255 true_Y0_c_ask: 846.95 sim_Y0_p_ask: 418.68423 sim_U0_p_ask: 417.40067 true_Y0_p_ask: 432.6 sim_Z0_c_ask: 482.4212 sim_Z0_p_ask: -512.58997\n",
      "[Train] Epoch 14 Step 8451, lr(0.000400): loss=850.6279, mse=256.4044, mae=11.9906, mape=0.1291, UY-loss=458.7859, DYZ-loss=135.4376\n",
      "[Valid] Epoch 14 Step 8451, lr(0.000400): loss=982.9972, mse=338.5341, mae=14.5870, mape=0.2711, UY-loss=512.9515, DYZ-loss=131.5116\n",
      "sim_Y0_c_ask: 1265.4342 sim_U0_c_ask: 1254.2316 true_Y0_c_ask: 1260.5 sim_Y0_p_ask: 64.60506 sim_U0_p_ask: 50.06941 true_Y0_p_ask: 64.4 sim_Z0_c_ask: 579.70337 sim_Z0_p_ask: -96.32864\n",
      "[Train] Epoch 14 Step 8501, lr(0.000400): loss=737.2443, mse=209.8907, mae=10.4028, mape=0.1010, UY-loss=411.6807, DYZ-loss=115.6729\n",
      "[Valid] Epoch 14 Step 8501, lr(0.000400): loss=962.4908, mse=288.6631, mae=13.7052, mape=0.2222, UY-loss=518.2026, DYZ-loss=155.6251\n",
      "sim_Y0_c_ask: 1030.49 sim_U0_c_ask: 1036.955 true_Y0_c_ask: 1025.0 sim_Y0_p_ask: 131.46571 sim_U0_p_ask: 135.1627 true_Y0_p_ask: 114.45 sim_Z0_c_ask: 582.03644 sim_Z0_p_ask: -139.07935\n",
      "[Train] Epoch 14 Step 8551, lr(0.000400): loss=820.7571, mse=215.1812, mae=10.6486, mape=0.1382, UY-loss=478.1333, DYZ-loss=127.4425\n",
      "[Valid] Epoch 14 Step 8551, lr(0.000400): loss=1140.5100, mse=320.6614, mae=14.7784, mape=0.2310, UY-loss=655.5518, DYZ-loss=164.2969\n",
      "sim_Y0_c_ask: 649.25543 sim_U0_c_ask: 644.48364 true_Y0_c_ask: 639.4 sim_Y0_p_ask: 212.40002 sim_U0_p_ask: 201.18333 true_Y0_p_ask: 210.1 sim_Z0_c_ask: 545.1008 sim_Z0_p_ask: -237.57454\n",
      "[Train] Epoch 14 Step 8601, lr(0.000400): loss=844.3715, mse=190.7055, mae=10.1781, mape=0.1939, UY-loss=475.0105, DYZ-loss=178.6555\n",
      "[Valid] Epoch 14 Step 8601, lr(0.000400): loss=1149.9382, mse=300.1444, mae=13.3345, mape=0.2177, UY-loss=651.3741, DYZ-loss=198.4197\n",
      "sim_Y0_c_ask: 1338.1208 sim_U0_c_ask: 1328.3988 true_Y0_c_ask: 1332.5 sim_Y0_p_ask: 1546.7338 sim_U0_p_ask: 1549.0115 true_Y0_p_ask: 1560.5 sim_Z0_c_ask: 559.3052 sim_Z0_p_ask: -500.86298\n",
      "[Train] Epoch 14 Step 8651, lr(0.000400): loss=1123.6805, mse=234.7244, mae=10.9651, mape=0.1514, UY-loss=557.2973, DYZ-loss=331.6588\n",
      "[Valid] Epoch 14 Step 8651, lr(0.000400): loss=1172.0692, mse=255.5155, mae=12.4424, mape=0.1952, UY-loss=578.0749, DYZ-loss=338.4787\n",
      "sim_Y0_c_ask: 45.877228 sim_U0_c_ask: 48.267735 true_Y0_c_ask: 53.9 sim_Y0_p_ask: 98.41385 sim_U0_p_ask: 103.294876 true_Y0_p_ask: 110.9 sim_Z0_c_ask: 150.76894 sim_Z0_p_ask: -109.10016\n",
      "[Train] Epoch 14 Step 8701, lr(0.000400): loss=1170.8181, mse=247.9572, mae=11.7561, mape=0.1665, UY-loss=651.3713, DYZ-loss=271.4897\n",
      "[Valid] Epoch 14 Step 8701, lr(0.000400): loss=1391.5018, mse=265.4297, mae=12.7959, mape=0.2130, UY-loss=769.0303, DYZ-loss=357.0419\n",
      "sim_Y0_c_ask: 272.11853 sim_U0_c_ask: 267.33148 true_Y0_c_ask: 294.8 sim_Y0_p_ask: 114.54678 sim_U0_p_ask: 90.23685 true_Y0_p_ask: 138.1 sim_Z0_c_ask: 440.90906 sim_Z0_p_ask: -291.92685\n",
      "[Train] Epoch 14 Step 8751, lr(0.000400): loss=1534.0493, mse=225.7034, mae=10.7039, mape=0.1102, UY-loss=731.1829, DYZ-loss=577.1630\n",
      "[Valid] Epoch 14 Step 8751, lr(0.000400): loss=1330.1418, mse=206.3208, mae=11.2427, mape=0.2021, UY-loss=625.1904, DYZ-loss=498.6306\n",
      "sim_Y0_c_ask: -1.3698609 sim_U0_c_ask: -3.0215197 true_Y0_c_ask: 3.2750000000000004 sim_Y0_p_ask: 155.26099 sim_U0_p_ask: 168.46896 true_Y0_p_ask: 189.05 sim_Z0_c_ask: 5.528981 sim_Z0_p_ask: -150.4391\n",
      "[Train] Epoch 14 Step 8801, lr(0.000400): loss=1238.3584, mse=223.8980, mae=11.0969, mape=0.1377, UY-loss=592.9669, DYZ-loss=421.4934\n",
      "[Valid] Epoch 14 Step 8801, lr(0.000400): loss=1492.3750, mse=294.4898, mae=13.0364, mape=0.2044, UY-loss=750.2711, DYZ-loss=447.6141\n",
      "sim_Y0_c_ask: 431.2442 sim_U0_c_ask: 436.37527 true_Y0_c_ask: 426.65 sim_Y0_p_ask: 122.909996 sim_U0_p_ask: 114.674736 true_Y0_p_ask: 122.55000000000001 sim_Z0_c_ask: 551.53094 sim_Z0_p_ask: -85.680885\n",
      "[Train] Epoch 15 Step 8851, lr(0.000400): loss=999.6047, mse=207.0836, mae=10.3856, mape=0.1607, UY-loss=569.4130, DYZ-loss=223.1081\n",
      "[Valid] Epoch 15 Step 8851, lr(0.000400): loss=1197.3762, mse=350.8686, mae=15.1416, mape=0.2333, UY-loss=649.3369, DYZ-loss=197.1707\n",
      "sim_Y0_c_ask: 49.499043 sim_U0_c_ask: 46.270992 true_Y0_c_ask: 37.3 sim_Y0_p_ask: 64.58658 sim_U0_p_ask: 51.29429 true_Y0_p_ask: 95.7 sim_Z0_c_ask: 115.341034 sim_Z0_p_ask: -111.14517\n",
      "[Train] Epoch 15 Step 8901, lr(0.000400): loss=881.6855, mse=201.0890, mae=10.7241, mape=0.2291, UY-loss=539.2000, DYZ-loss=141.3966\n",
      "[Valid] Epoch 15 Step 8901, lr(0.000400): loss=1091.4047, mse=331.9785, mae=14.6017, mape=0.3675, UY-loss=535.8105, DYZ-loss=223.6156\n",
      "sim_Y0_c_ask: 386.97052 sim_U0_c_ask: 386.56146 true_Y0_c_ask: 408.45000000000005 sim_Y0_p_ask: 191.99005 sim_U0_p_ask: 181.43767 true_Y0_p_ask: 213.55 sim_Z0_c_ask: 475.5485 sim_Z0_p_ask: -454.1973\n",
      "[Train] Epoch 15 Step 8951, lr(0.000400): loss=672.2265, mse=146.1046, mae=9.0515, mape=0.3291, UY-loss=406.3314, DYZ-loss=119.7906\n",
      "[Valid] Epoch 15 Step 8951, lr(0.000400): loss=1096.7314, mse=340.9584, mae=14.8598, mape=0.2054, UY-loss=604.8076, DYZ-loss=150.9654\n",
      "sim_Y0_c_ask: 1173.1729 sim_U0_c_ask: 1169.8914 true_Y0_c_ask: 1165.5 sim_Y0_p_ask: 14.405955 sim_U0_p_ask: 12.16061 true_Y0_p_ask: 16.3 sim_Z0_c_ask: 567.81964 sim_Z0_p_ask: -14.097915\n",
      "[Train] Epoch 15 Step 9001, lr(0.000400): loss=715.1085, mse=158.9584, mae=9.2069, mape=0.1095, UY-loss=425.1169, DYZ-loss=131.0332\n",
      "[Valid] Epoch 15 Step 9001, lr(0.000400): loss=880.8501, mse=306.7109, mae=13.9776, mape=0.2847, UY-loss=451.9995, DYZ-loss=122.1396\n",
      "sim_Y0_c_ask: 247.48547 sim_U0_c_ask: 244.69868 true_Y0_c_ask: 270.55 sim_Y0_p_ask: 24.199825 sim_U0_p_ask: 21.836842 true_Y0_p_ask: 20.15 sim_Z0_c_ask: 489.75867 sim_Z0_p_ask: -11.956074\n",
      "[Train] Epoch 15 Step 9051, lr(0.000400): loss=851.7286, mse=215.6843, mae=10.8922, mape=0.1258, UY-loss=507.6577, DYZ-loss=128.3866\n",
      "[Valid] Epoch 15 Step 9051, lr(0.000400): loss=959.5773, mse=305.4271, mae=13.9723, mape=0.2144, UY-loss=522.9589, DYZ-loss=131.1913\n",
      "sim_Y0_c_ask: 288.23523 sim_U0_c_ask: 288.95142 true_Y0_c_ask: 276.75 sim_Y0_p_ask: 1576.3201 sim_U0_p_ask: 1552.0035 true_Y0_p_ask: 1586.0 sim_Z0_c_ask: 567.1761 sim_Z0_p_ask: -513.14624\n",
      "[Train] Epoch 15 Step 9101, lr(0.000400): loss=752.7549, mse=197.0375, mae=10.5353, mape=0.1364, UY-loss=419.7372, DYZ-loss=135.9801\n",
      "[Valid] Epoch 15 Step 9101, lr(0.000400): loss=1161.8766, mse=405.2296, mae=16.0420, mape=0.2078, UY-loss=583.3470, DYZ-loss=173.3000\n",
      "sim_Y0_c_ask: 217.6221 sim_U0_c_ask: 205.51479 true_Y0_c_ask: 203.35 sim_Y0_p_ask: 69.51803 sim_U0_p_ask: 60.211643 true_Y0_p_ask: 79.5 sim_Z0_c_ask: 418.56732 sim_Z0_p_ask: -61.351055\n",
      "[Train] Epoch 15 Step 9151, lr(0.000400): loss=770.5514, mse=222.0261, mae=10.8728, mape=0.1457, UY-loss=422.6910, DYZ-loss=125.8342\n",
      "[Valid] Epoch 15 Step 9151, lr(0.000400): loss=825.7814, mse=289.8696, mae=13.7833, mape=0.3033, UY-loss=412.2850, DYZ-loss=123.6268\n",
      "sim_Y0_c_ask: 117.74811 sim_U0_c_ask: 101.20778 true_Y0_c_ask: 87.69999999999999 sim_Y0_p_ask: 1683.8898 sim_U0_p_ask: 1690.9808 true_Y0_p_ask: 1679.5 sim_Z0_c_ask: 281.30817 sim_Z0_p_ask: -603.14307\n",
      "[Train] Epoch 15 Step 9201, lr(0.000400): loss=928.7309, mse=238.3527, mae=10.9283, mape=0.1025, UY-loss=512.7706, DYZ-loss=177.6076\n",
      "[Valid] Epoch 15 Step 9201, lr(0.000400): loss=987.9733, mse=285.6885, mae=13.0329, mape=0.2610, UY-loss=560.1074, DYZ-loss=142.1775\n",
      "sim_Y0_c_ask: 219.24333 sim_U0_c_ask: 201.65341 true_Y0_c_ask: 213.5 sim_Y0_p_ask: 40.365227 sim_U0_p_ask: 35.600876 true_Y0_p_ask: 33.7 sim_Z0_c_ask: 392.35312 sim_Z0_p_ask: -14.674532\n",
      "[Train] Epoch 15 Step 9251, lr(0.000400): loss=682.9321, mse=186.6372, mae=10.0437, mape=0.1229, UY-loss=384.3953, DYZ-loss=111.8995\n",
      "[Valid] Epoch 15 Step 9251, lr(0.000400): loss=1213.9496, mse=455.4055, mae=17.4787, mape=0.3251, UY-loss=575.3918, DYZ-loss=183.1522\n",
      "sim_Y0_c_ask: 165.85251 sim_U0_c_ask: 151.57289 true_Y0_c_ask: 147.9 sim_Y0_p_ask: 11.332883 sim_U0_p_ask: 10.688479 true_Y0_p_ask: 6.4 sim_Z0_c_ask: 346.92462 sim_Z0_p_ask: -12.817923\n",
      "[Train] Epoch 15 Step 9301, lr(0.000400): loss=644.1490, mse=162.5816, mae=9.5358, mape=0.1159, UY-loss=374.1935, DYZ-loss=107.3740\n",
      "[Valid] Epoch 15 Step 9301, lr(0.000400): loss=1005.9045, mse=327.7645, mae=14.0357, mape=0.2366, UY-loss=526.7295, DYZ-loss=151.4106\n",
      "sim_Y0_c_ask: 749.6792 sim_U0_c_ask: 758.4404 true_Y0_c_ask: 751.2 sim_Y0_p_ask: 63.805363 sim_U0_p_ask: 57.43824 true_Y0_p_ask: 72.6 sim_Z0_c_ask: 530.1022 sim_Z0_p_ask: -64.62646\n",
      "[Train] Epoch 15 Step 9351, lr(0.000400): loss=703.5824, mse=154.1075, mae=9.1653, mape=0.1071, UY-loss=432.4491, DYZ-loss=117.0258\n",
      "[Valid] Epoch 15 Step 9351, lr(0.000400): loss=1018.4653, mse=297.3062, mae=13.5756, mape=0.1908, UY-loss=570.2286, DYZ-loss=150.9305\n",
      "sim_Y0_c_ask: 290.36847 sim_U0_c_ask: 275.6604 true_Y0_c_ask: 278.35 sim_Y0_p_ask: 144.91565 sim_U0_p_ask: 133.96951 true_Y0_p_ask: 120.5 sim_Z0_c_ask: 476.81876 sim_Z0_p_ask: -272.9842\n",
      "[Train] Epoch 15 Step 9401, lr(0.000400): loss=674.6478, mse=192.3895, mae=10.4309, mape=0.1217, UY-loss=379.0038, DYZ-loss=103.2544\n",
      "[Valid] Epoch 15 Step 9401, lr(0.000400): loss=1030.3627, mse=308.5361, mae=13.7530, mape=0.2343, UY-loss=596.9873, DYZ-loss=124.8392\n",
      "sim_Y0_c_ask: 3.1068277 sim_U0_c_ask: 5.1076455 true_Y0_c_ask: 4.65 sim_Y0_p_ask: 32.150196 sim_U0_p_ask: 28.12544 true_Y0_p_ask: 47.25 sim_Z0_c_ask: 5.407404 sim_Z0_p_ask: -24.319815\n",
      "[Train] Epoch 16 Step 9451, lr(0.000400): loss=830.9009, mse=202.7190, mae=10.1336, mape=0.1174, UY-loss=498.1703, DYZ-loss=130.0115\n",
      "[Valid] Epoch 16 Step 9451, lr(0.000400): loss=854.6906, mse=251.0243, mae=12.4502, mape=0.2600, UY-loss=436.5758, DYZ-loss=167.0905\n",
      "sim_Y0_c_ask: 729.1458 sim_U0_c_ask: 729.8713 true_Y0_c_ask: 720.5 sim_Y0_p_ask: 225.08224 sim_U0_p_ask: 232.81088 true_Y0_p_ask: 212.2 sim_Z0_c_ask: 454.4964 sim_Z0_p_ask: -286.60333\n",
      "[Train] Epoch 16 Step 9501, lr(0.000400): loss=862.9564, mse=221.7294, mae=10.8376, mape=0.1524, UY-loss=497.8214, DYZ-loss=143.4055\n",
      "[Valid] Epoch 16 Step 9501, lr(0.000400): loss=1007.9701, mse=281.9028, mae=13.7903, mape=0.1970, UY-loss=566.2948, DYZ-loss=159.7726\n",
      "sim_Y0_c_ask: 464.5016 sim_U0_c_ask: 455.4467 true_Y0_c_ask: 441.75 sim_Y0_p_ask: 54.172874 sim_U0_p_ask: 51.510098 true_Y0_p_ask: 75.55 sim_Z0_c_ask: 489.06754 sim_Z0_p_ask: -133.66759\n",
      "[Train] Epoch 16 Step 9551, lr(0.000400): loss=789.5267, mse=190.0018, mae=10.4066, mape=0.1329, UY-loss=453.9282, DYZ-loss=145.5968\n",
      "[Valid] Epoch 16 Step 9551, lr(0.000400): loss=879.4952, mse=267.0084, mae=12.9965, mape=0.2493, UY-loss=475.9041, DYZ-loss=136.5827\n",
      "sim_Y0_c_ask: 138.37454 sim_U0_c_ask: 134.23878 true_Y0_c_ask: 140.05 sim_Y0_p_ask: 1667.1968 sim_U0_p_ask: 1666.798 true_Y0_p_ask: 1671.5 sim_Z0_c_ask: 434.7623 sim_Z0_p_ask: -542.2469\n",
      "[Train] Epoch 16 Step 9601, lr(0.000400): loss=824.7152, mse=219.1172, mae=10.4010, mape=0.1011, UY-loss=473.1675, DYZ-loss=132.4305\n",
      "[Valid] Epoch 16 Step 9601, lr(0.000400): loss=978.8616, mse=258.7141, mae=12.4086, mape=0.2115, UY-loss=551.5781, DYZ-loss=168.5693\n",
      "sim_Y0_c_ask: 602.213 sim_U0_c_ask: 604.123 true_Y0_c_ask: 605.7 sim_Y0_p_ask: 314.38754 sim_U0_p_ask: 323.6501 true_Y0_p_ask: 296.2 sim_Z0_c_ask: 542.92975 sim_Z0_p_ask: -352.47208\n",
      "[Train] Epoch 16 Step 9651, lr(0.000400): loss=667.7912, mse=189.1234, mae=10.7685, mape=0.2045, UY-loss=358.8500, DYZ-loss=119.8178\n",
      "[Valid] Epoch 16 Step 9651, lr(0.000400): loss=1077.7855, mse=336.0748, mae=14.7632, mape=0.2760, UY-loss=563.9750, DYZ-loss=177.7358\n",
      "sim_Y0_c_ask: 868.28906 sim_U0_c_ask: 871.52484 true_Y0_c_ask: 870.3499999999999 sim_Y0_p_ask: 554.1478 sim_U0_p_ask: 554.7502 true_Y0_p_ask: 559.9 sim_Z0_c_ask: 540.75146 sim_Z0_p_ask: -493.6835\n",
      "[Train] Epoch 16 Step 9701, lr(0.000400): loss=742.8510, mse=198.2430, mae=10.6044, mape=0.1165, UY-loss=405.5154, DYZ-loss=139.0925\n",
      "[Valid] Epoch 16 Step 9701, lr(0.000400): loss=893.7744, mse=302.4400, mae=13.6329, mape=0.2268, UY-loss=460.0470, DYZ-loss=131.2874\n",
      "sim_Y0_c_ask: 1081.8431 sim_U0_c_ask: 1077.9769 true_Y0_c_ask: 1087.5 sim_Y0_p_ask: 38.163597 sim_U0_p_ask: 27.833467 true_Y0_p_ask: 28.0 sim_Z0_c_ask: 542.06995 sim_Z0_p_ask: -8.319245\n",
      "[Train] Epoch 16 Step 9751, lr(0.000400): loss=733.2225, mse=203.5950, mae=10.2853, mape=0.1129, UY-loss=381.5307, DYZ-loss=148.0967\n",
      "[Valid] Epoch 16 Step 9751, lr(0.000400): loss=1113.3849, mse=425.8450, mae=16.7181, mape=0.2911, UY-loss=527.7317, DYZ-loss=159.8081\n",
      "sim_Y0_c_ask: 0.4898757 sim_U0_c_ask: -6.8571243 true_Y0_c_ask: 0.7250000000000001 sim_Y0_p_ask: 79.69273 sim_U0_p_ask: 64.5208 true_Y0_p_ask: 69.19999999999999 sim_Z0_c_ask: 1.2703135 sim_Z0_p_ask: -63.991966\n",
      "[Train] Epoch 16 Step 9801, lr(0.000400): loss=825.4135, mse=190.4877, mae=10.3571, mape=0.1514, UY-loss=487.5359, DYZ-loss=147.3898\n",
      "[Valid] Epoch 16 Step 9801, lr(0.000400): loss=1073.4712, mse=375.7281, mae=15.6213, mape=0.3669, UY-loss=550.3978, DYZ-loss=147.3454\n",
      "sim_Y0_c_ask: 889.3893 sim_U0_c_ask: 888.83514 true_Y0_c_ask: 882.45 sim_Y0_p_ask: 55.981483 sim_U0_p_ask: 50.086285 true_Y0_p_ask: 58.25 sim_Z0_c_ask: 558.603 sim_Z0_p_ask: -72.40244\n",
      "[Train] Epoch 16 Step 9851, lr(0.000400): loss=653.7739, mse=174.1550, mae=9.3489, mape=0.2001, UY-loss=349.8348, DYZ-loss=129.7842\n",
      "[Valid] Epoch 16 Step 9851, lr(0.000400): loss=1029.2908, mse=399.2706, mae=16.3633, mape=0.2436, UY-loss=473.5360, DYZ-loss=156.4841\n",
      "sim_Y0_c_ask: 43.345703 sim_U0_c_ask: 39.836357 true_Y0_c_ask: 47.8 sim_Y0_p_ask: 310.67822 sim_U0_p_ask: 311.23203 true_Y0_p_ask: 313.6 sim_Z0_c_ask: 306.52563 sim_Z0_p_ask: -233.41353\n",
      "[Train] Epoch 16 Step 9901, lr(0.000400): loss=696.3113, mse=167.7075, mae=9.8408, mape=0.1326, UY-loss=397.4435, DYZ-loss=131.1603\n",
      "[Valid] Epoch 16 Step 9901, lr(0.000400): loss=1125.5638, mse=405.7380, mae=16.3073, mape=0.2396, UY-loss=562.6420, DYZ-loss=157.1839\n",
      "sim_Y0_c_ask: 1110.2424 sim_U0_c_ask: 1089.2417 true_Y0_c_ask: 1111.5 sim_Y0_p_ask: 679.4292 sim_U0_p_ask: 673.0835 true_Y0_p_ask: 687.75 sim_Z0_c_ask: 526.4759 sim_Z0_p_ask: -466.91852\n",
      "[Train] Epoch 16 Step 9951, lr(0.000400): loss=893.8548, mse=255.0943, mae=11.7611, mape=0.1562, UY-loss=499.1838, DYZ-loss=139.5767\n",
      "[Valid] Epoch 16 Step 9951, lr(0.000400): loss=1318.1417, mse=369.3229, mae=14.5703, mape=0.2302, UY-loss=705.9449, DYZ-loss=242.8739\n",
      "sim_Y0_c_ask: 906.5785 sim_U0_c_ask: 903.5094 true_Y0_c_ask: 910.4 sim_Y0_p_ask: 121.09897 sim_U0_p_ask: 122.5807 true_Y0_p_ask: 133.4 sim_Z0_c_ask: 530.5351 sim_Z0_p_ask: -108.673775\n",
      "[Train] Epoch 16 Step 10001, lr(0.000400): loss=837.9467, mse=213.5887, mae=10.4639, mape=0.1225, UY-loss=474.0610, DYZ-loss=150.2971\n",
      "[Valid] Epoch 16 Step 10001, lr(0.000400): loss=910.1302, mse=198.2629, mae=10.9835, mape=0.1350, UY-loss=521.4843, DYZ-loss=190.3831\n",
      "sim_Y0_c_ask: 27.804775 sim_U0_c_ask: 16.775686 true_Y0_c_ask: 22.25 sim_Y0_p_ask: 24.697685 sim_U0_p_ask: 22.178568 true_Y0_p_ask: 19.25 sim_Z0_c_ask: 74.21405 sim_Z0_p_ask: -6.5984206\n",
      "[Train] Epoch 17 Step 10051, lr(0.000040): loss=821.6842, mse=214.1409, mae=10.6915, mape=0.1557, UY-loss=501.2642, DYZ-loss=106.2791\n",
      "[Valid] Epoch 17 Step 10051, lr(0.000040): loss=954.4949, mse=334.0102, mae=15.3109, mape=0.2116, UY-loss=501.3919, DYZ-loss=119.0927\n",
      "sim_Y0_c_ask: 120.84374 sim_U0_c_ask: 119.038536 true_Y0_c_ask: 137.1 sim_Y0_p_ask: 554.4617 sim_U0_p_ask: 557.6703 true_Y0_p_ask: 557.8 sim_Z0_c_ask: 341.38968 sim_Z0_p_ask: -537.7967\n",
      "[Train] Epoch 17 Step 10101, lr(0.000040): loss=739.0410, mse=193.2112, mae=10.4870, mape=0.1453, UY-loss=438.6614, DYZ-loss=107.1683\n",
      "[Valid] Epoch 17 Step 10101, lr(0.000040): loss=997.2005, mse=344.9168, mae=15.1138, mape=0.2541, UY-loss=525.8831, DYZ-loss=126.4007\n",
      "sim_Y0_c_ask: 28.810371 sim_U0_c_ask: 23.324821 true_Y0_c_ask: 30.1 sim_Y0_p_ask: 31.816 sim_U0_p_ask: 29.486917 true_Y0_p_ask: 29.9 sim_Z0_c_ask: 108.949554 sim_Z0_p_ask: -22.619131\n",
      "[Train] Epoch 17 Step 10151, lr(0.000040): loss=696.4388, mse=163.0427, mae=9.6440, mape=0.1169, UY-loss=431.9701, DYZ-loss=101.4261\n",
      "[Valid] Epoch 17 Step 10151, lr(0.000040): loss=795.8892, mse=272.2541, mae=13.1778, mape=0.2522, UY-loss=409.0865, DYZ-loss=114.5486\n",
      "sim_Y0_c_ask: 531.2858 sim_U0_c_ask: 513.55334 true_Y0_c_ask: 532.25 sim_Y0_p_ask: 74.20758 sim_U0_p_ask: 62.282043 true_Y0_p_ask: 65.6 sim_Z0_c_ask: 451.42358 sim_Z0_p_ask: -66.22626\n",
      "[Train] Epoch 17 Step 10201, lr(0.000040): loss=649.1733, mse=171.4550, mae=9.3922, mape=0.1176, UY-loss=380.1693, DYZ-loss=97.5490\n",
      "[Valid] Epoch 17 Step 10201, lr(0.000040): loss=844.9438, mse=308.4137, mae=14.4450, mape=0.2588, UY-loss=421.0778, DYZ-loss=115.4523\n",
      "sim_Y0_c_ask: 845.5449 sim_U0_c_ask: 846.0269 true_Y0_c_ask: 845.05 sim_Y0_p_ask: 70.883316 sim_U0_p_ask: 67.057396 true_Y0_p_ask: 78.15 sim_Z0_c_ask: 539.6414 sim_Z0_p_ask: -58.185722\n",
      "[Train] Epoch 17 Step 10251, lr(0.000040): loss=646.3629, mse=173.9646, mae=9.3206, mape=0.2265, UY-loss=370.6433, DYZ-loss=101.7550\n",
      "[Valid] Epoch 17 Step 10251, lr(0.000040): loss=899.3389, mse=318.0265, mae=14.4113, mape=0.2183, UY-loss=465.2724, DYZ-loss=116.0399\n",
      "sim_Y0_c_ask: 634.99664 sim_U0_c_ask: 629.2718 true_Y0_c_ask: 642.0 sim_Y0_p_ask: 46.81613 sim_U0_p_ask: 43.498978 true_Y0_p_ask: 48.35 sim_Z0_c_ask: 423.29617 sim_Z0_p_ask: -59.43521\n",
      "[Train] Epoch 17 Step 10301, lr(0.000040): loss=649.9816, mse=162.7188, mae=9.1904, mape=0.1412, UY-loss=387.8564, DYZ-loss=99.4064\n",
      "[Valid] Epoch 17 Step 10301, lr(0.000040): loss=891.5016, mse=280.4497, mae=13.8258, mape=0.2213, UY-loss=495.8886, DYZ-loss=115.1632\n",
      "sim_Y0_c_ask: 41.89189 sim_U0_c_ask: 41.201298 true_Y0_c_ask: 41.15 sim_Y0_p_ask: 169.29544 sim_U0_p_ask: 158.94194 true_Y0_p_ask: 138.85 sim_Z0_c_ask: 152.81133 sim_Z0_p_ask: -282.06506\n",
      "[Train] Epoch 17 Step 10351, lr(0.000040): loss=715.5575, mse=166.6386, mae=9.2862, mape=0.1456, UY-loss=444.2432, DYZ-loss=104.6758\n",
      "[Valid] Epoch 17 Step 10351, lr(0.000040): loss=952.1228, mse=278.9055, mae=13.3087, mape=0.2963, UY-loss=546.9856, DYZ-loss=126.2318\n",
      "sim_Y0_c_ask: 197.5811 sim_U0_c_ask: 201.0567 true_Y0_c_ask: 205.64999999999998 sim_Y0_p_ask: 122.33359 sim_U0_p_ask: 119.22921 true_Y0_p_ask: 117.35 sim_Z0_c_ask: 400.965 sim_Z0_p_ask: -122.04722\n",
      "[Train] Epoch 17 Step 10401, lr(0.000040): loss=684.1910, mse=185.9104, mae=9.7467, mape=0.1127, UY-loss=396.3783, DYZ-loss=101.9023\n",
      "[Valid] Epoch 17 Step 10401, lr(0.000040): loss=779.9448, mse=279.4226, mae=13.6803, mape=0.2187, UY-loss=388.6890, DYZ-loss=111.8331\n",
      "sim_Y0_c_ask: 657.3053 sim_U0_c_ask: 659.47833 true_Y0_c_ask: 664.5999999999999 sim_Y0_p_ask: 270.58087 sim_U0_p_ask: 270.24982 true_Y0_p_ask: 266.75 sim_Z0_c_ask: 532.3508 sim_Z0_p_ask: -372.96814\n",
      "[Train] Epoch 17 Step 10451, lr(0.000040): loss=652.9421, mse=171.8003, mae=9.6130, mape=0.1204, UY-loss=377.8702, DYZ-loss=103.2717\n",
      "[Valid] Epoch 17 Step 10451, lr(0.000040): loss=838.7002, mse=301.0900, mae=14.1009, mape=0.2492, UY-loss=424.2388, DYZ-loss=113.3714\n",
      "sim_Y0_c_ask: 733.4204 sim_U0_c_ask: 742.00366 true_Y0_c_ask: 742.0999999999999 sim_Y0_p_ask: 153.81615 sim_U0_p_ask: 151.45544 true_Y0_p_ask: 187.8 sim_Z0_c_ask: 512.6865 sim_Z0_p_ask: -309.13235\n",
      "[Train] Epoch 17 Step 10501, lr(0.000040): loss=818.8331, mse=265.6049, mae=12.1947, mape=0.1618, UY-loss=439.1608, DYZ-loss=114.0675\n",
      "[Valid] Epoch 17 Step 10501, lr(0.000040): loss=846.1334, mse=309.1257, mae=14.5316, mape=0.2410, UY-loss=417.0410, DYZ-loss=119.9668\n",
      "sim_Y0_c_ask: 799.79626 sim_U0_c_ask: 800.25037 true_Y0_c_ask: 793.0 sim_Y0_p_ask: 56.05083 sim_U0_p_ask: 45.504086 true_Y0_p_ask: 64.25 sim_Z0_c_ask: 565.63055 sim_Z0_p_ask: -27.14436\n",
      "[Train] Epoch 17 Step 10551, lr(0.000040): loss=768.1954, mse=197.8078, mae=10.4986, mape=0.1206, UY-loss=463.1246, DYZ-loss=107.2630\n",
      "[Valid] Epoch 17 Step 10551, lr(0.000040): loss=997.5252, mse=324.1505, mae=14.6564, mape=0.2114, UY-loss=547.0137, DYZ-loss=126.3610\n",
      "sim_Y0_c_ask: 192.93858 sim_U0_c_ask: 194.40286 true_Y0_c_ask: 175.05 sim_Y0_p_ask: 56.368896 sim_U0_p_ask: 49.705044 true_Y0_p_ask: 49.05 sim_Z0_c_ask: 298.648 sim_Z0_p_ask: -51.668743\n",
      "[Train] Epoch 17 Step 10601, lr(0.000040): loss=704.2910, mse=175.4160, mae=9.6713, mape=0.1682, UY-loss=424.4651, DYZ-loss=104.4100\n",
      "[Valid] Epoch 17 Step 10601, lr(0.000040): loss=890.4869, mse=316.5183, mae=14.4639, mape=0.1940, UY-loss=452.7104, DYZ-loss=121.2582\n",
      "sim_Y0_c_ask: 390.61578 sim_U0_c_ask: 387.4865 true_Y0_c_ask: 368.79999999999995 sim_Y0_p_ask: 439.284 sim_U0_p_ask: 444.83328 true_Y0_p_ask: 452.65 sim_Z0_c_ask: 493.6747 sim_Z0_p_ask: -303.04926\n",
      "[Train] Epoch 18 Step 10651, lr(0.000040): loss=668.5193, mse=164.2725, mae=9.4156, mape=0.1311, UY-loss=407.4699, DYZ-loss=96.7768\n",
      "[Valid] Epoch 18 Step 10651, lr(0.000040): loss=864.6741, mse=275.7230, mae=13.1984, mape=0.2554, UY-loss=476.5380, DYZ-loss=112.4131\n",
      "sim_Y0_c_ask: 642.27405 sim_U0_c_ask: 643.18085 true_Y0_c_ask: 641.5999999999999 sim_Y0_p_ask: 625.2437 sim_U0_p_ask: 636.91156 true_Y0_p_ask: 641.0 sim_Z0_c_ask: 541.67584 sim_Z0_p_ask: -308.36633\n",
      "[Train] Epoch 18 Step 10701, lr(0.000040): loss=749.7811, mse=194.9229, mae=9.8919, mape=0.1943, UY-loss=450.6956, DYZ-loss=104.1626\n",
      "[Valid] Epoch 18 Step 10701, lr(0.000040): loss=943.2980, mse=340.9478, mae=15.0009, mape=0.2112, UY-loss=483.0725, DYZ-loss=119.2777\n",
      "sim_Y0_c_ask: 0.36705798 sim_U0_c_ask: -0.7381274 true_Y0_c_ask: 0.125 sim_Y0_p_ask: 482.7284 sim_U0_p_ask: 486.35596 true_Y0_p_ask: 489.1 sim_Z0_c_ask: 2.9421072 sim_Z0_p_ask: -512.90857\n",
      "[Train] Epoch 18 Step 10751, lr(0.000040): loss=734.5962, mse=196.8187, mae=10.0127, mape=0.1085, UY-loss=429.5092, DYZ-loss=108.2683\n",
      "[Valid] Epoch 18 Step 10751, lr(0.000040): loss=968.1541, mse=317.0562, mae=14.7439, mape=0.2469, UY-loss=522.6083, DYZ-loss=128.4895\n",
      "sim_Y0_c_ask: 304.74988 sim_U0_c_ask: 297.7719 true_Y0_c_ask: 288.54999999999995 sim_Y0_p_ask: 46.845306 sim_U0_p_ask: 42.892273 true_Y0_p_ask: 51.400000000000006 sim_Z0_c_ask: 472.87692 sim_Z0_p_ask: -20.230692\n",
      "[Train] Epoch 18 Step 10801, lr(0.000040): loss=741.2060, mse=196.4198, mae=10.3330, mape=0.1088, UY-loss=438.7945, DYZ-loss=105.9917\n",
      "[Valid] Epoch 18 Step 10801, lr(0.000040): loss=926.8286, mse=306.1100, mae=14.0786, mape=0.2409, UY-loss=489.9586, DYZ-loss=130.7600\n",
      "sim_Y0_c_ask: 302.1902 sim_U0_c_ask: 294.13394 true_Y0_c_ask: 281.9 sim_Y0_p_ask: 27.541376 sim_U0_p_ask: 26.363075 true_Y0_p_ask: 25.549999999999997 sim_Z0_c_ask: 454.76117 sim_Z0_p_ask: -24.832706\n",
      "[Train] Epoch 18 Step 10851, lr(0.000040): loss=681.1587, mse=171.1502, mae=9.6158, mape=0.1221, UY-loss=399.0066, DYZ-loss=111.0019\n",
      "[Valid] Epoch 18 Step 10851, lr(0.000040): loss=1061.0369, mse=348.9953, mae=14.9045, mape=0.2491, UY-loss=577.5073, DYZ-loss=134.5343\n",
      "sim_Y0_c_ask: 144.3978 sim_U0_c_ask: 135.53894 true_Y0_c_ask: 146.65 sim_Y0_p_ask: 14.358715 sim_U0_p_ask: 13.54385 true_Y0_p_ask: 13.7 sim_Z0_c_ask: 415.83148 sim_Z0_p_ask: -13.516672\n",
      "[Train] Epoch 18 Step 10901, lr(0.000040): loss=718.8582, mse=189.5821, mae=10.3372, mape=0.1275, UY-loss=421.8278, DYZ-loss=107.4484\n",
      "[Valid] Epoch 18 Step 10901, lr(0.000040): loss=880.7135, mse=259.5974, mae=13.1311, mape=0.1979, UY-loss=504.2195, DYZ-loss=116.8967\n",
      "sim_Y0_c_ask: 618.13135 sim_U0_c_ask: 619.4241 true_Y0_c_ask: 619.55 sim_Y0_p_ask: 14.4643 sim_U0_p_ask: 15.1346035 true_Y0_p_ask: 17.6 sim_Z0_c_ask: 528.66077 sim_Z0_p_ask: -7.586353\n",
      "[Train] Epoch 18 Step 10951, lr(0.000040): loss=730.1391, mse=184.7643, mae=10.2178, mape=0.1046, UY-loss=440.4648, DYZ-loss=104.9100\n",
      "[Valid] Epoch 18 Step 10951, lr(0.000040): loss=957.3745, mse=309.7046, mae=13.6318, mape=0.2180, UY-loss=524.4408, DYZ-loss=123.2291\n",
      "sim_Y0_c_ask: 175.73773 sim_U0_c_ask: 168.81325 true_Y0_c_ask: 147.6 sim_Y0_p_ask: 414.10303 sim_U0_p_ask: 417.36816 true_Y0_p_ask: 406.25 sim_Z0_c_ask: 275.05103 sim_Z0_p_ask: -271.30643\n",
      "[Train] Epoch 18 Step 11001, lr(0.000040): loss=604.4911, mse=150.3831, mae=9.1920, mape=0.1340, UY-loss=362.8867, DYZ-loss=91.2214\n",
      "[Valid] Epoch 18 Step 11001, lr(0.000040): loss=968.0889, mse=327.9534, mae=14.7830, mape=0.2585, UY-loss=512.5276, DYZ-loss=127.6078\n",
      "sim_Y0_c_ask: 106.49991 sim_U0_c_ask: 96.24551 true_Y0_c_ask: 76.25 sim_Y0_p_ask: 525.66455 sim_U0_p_ask: 528.01306 true_Y0_p_ask: 522.5999999999999 sim_Z0_c_ask: 261.88028 sim_Z0_p_ask: -531.854\n",
      "[Train] Epoch 18 Step 11051, lr(0.000040): loss=651.9999, mse=158.9287, mae=9.1412, mape=0.1308, UY-loss=392.2977, DYZ-loss=100.7735\n",
      "[Valid] Epoch 18 Step 11051, lr(0.000040): loss=961.6057, mse=337.5803, mae=14.7740, mape=0.2361, UY-loss=500.8276, DYZ-loss=123.1977\n",
      "sim_Y0_c_ask: 160.63715 sim_U0_c_ask: 153.8279 true_Y0_c_ask: 187.35 sim_Y0_p_ask: 38.79277 sim_U0_p_ask: 34.76009 true_Y0_p_ask: 30.65 sim_Z0_c_ask: 458.67368 sim_Z0_p_ask: -34.329426\n",
      "[Train] Epoch 18 Step 11101, lr(0.000040): loss=639.5786, mse=179.6994, mae=9.8696, mape=0.1127, UY-loss=361.1508, DYZ-loss=98.7284\n",
      "[Valid] Epoch 18 Step 11101, lr(0.000040): loss=789.8918, mse=253.6170, mae=12.7695, mape=0.2280, UY-loss=424.8714, DYZ-loss=111.4035\n",
      "sim_Y0_c_ask: 1.3468223 sim_U0_c_ask: -0.040452704 true_Y0_c_ask: 3.4000000000000004 sim_Y0_p_ask: 77.211975 sim_U0_p_ask: 72.34745 true_Y0_p_ask: 114.19999999999999 sim_Z0_c_ask: 7.553953 sim_Z0_p_ask: -85.65433\n",
      "[Train] Epoch 18 Step 11151, lr(0.000040): loss=709.6846, mse=205.1915, mae=10.8493, mape=0.1206, UY-loss=392.6489, DYZ-loss=111.8441\n",
      "[Valid] Epoch 18 Step 11151, lr(0.000040): loss=699.6434, mse=245.4482, mae=12.9681, mape=0.2431, UY-loss=344.0708, DYZ-loss=110.1244\n",
      "sim_Y0_c_ask: 140.66528 sim_U0_c_ask: 140.69061 true_Y0_c_ask: 174.25 sim_Y0_p_ask: 62.025154 sim_U0_p_ask: 62.717266 true_Y0_p_ask: 44.25 sim_Z0_c_ask: 308.22308 sim_Z0_p_ask: -105.22738\n",
      "[Train] Epoch 18 Step 11201, lr(0.000040): loss=771.4289, mse=205.8092, mae=10.6634, mape=0.1116, UY-loss=458.8668, DYZ-loss=106.7529\n",
      "[Valid] Epoch 18 Step 11201, lr(0.000040): loss=841.7299, mse=283.7055, mae=13.5761, mape=0.3150, UY-loss=442.8763, DYZ-loss=115.1480\n",
      "sim_Y0_c_ask: 469.88956 sim_U0_c_ask: 467.93588 true_Y0_c_ask: 453.05 sim_Y0_p_ask: 31.269178 sim_U0_p_ask: 32.45712 true_Y0_p_ask: 29.5 sim_Z0_c_ask: 528.1543 sim_Z0_p_ask: -29.045755\n",
      "[Train] Epoch 19 Step 11251, lr(0.000040): loss=663.9915, mse=171.3136, mae=9.6187, mape=0.1188, UY-loss=389.2966, DYZ-loss=103.3813\n",
      "[Valid] Epoch 19 Step 11251, lr(0.000040): loss=874.6559, mse=277.3243, mae=13.3182, mape=0.2169, UY-loss=472.2911, DYZ-loss=125.0405\n",
      "sim_Y0_c_ask: 800.7174 sim_U0_c_ask: 799.87415 true_Y0_c_ask: 793.0 sim_Y0_p_ask: 98.97582 sim_U0_p_ask: 88.50164 true_Y0_p_ask: 81.2 sim_Z0_c_ask: 566.51117 sim_Z0_p_ask: -91.00629\n",
      "[Train] Epoch 19 Step 11301, lr(0.000040): loss=702.5017, mse=199.5242, mae=10.5821, mape=0.1708, UY-loss=399.2094, DYZ-loss=103.7681\n",
      "[Valid] Epoch 19 Step 11301, lr(0.000040): loss=923.5774, mse=338.0240, mae=14.8856, mape=0.2209, UY-loss=464.4753, DYZ-loss=121.0781\n",
      "sim_Y0_c_ask: 77.45436 sim_U0_c_ask: 89.15517 true_Y0_c_ask: 75.55 sim_Y0_p_ask: 792.6305 sim_U0_p_ask: 804.62054 true_Y0_p_ask: 772.8 sim_Z0_c_ask: 142.45981 sim_Z0_p_ask: -353.29608\n",
      "[Train] Epoch 19 Step 11351, lr(0.000040): loss=708.2777, mse=170.8251, mae=9.6167, mape=0.1617, UY-loss=431.4717, DYZ-loss=105.9810\n",
      "[Valid] Epoch 19 Step 11351, lr(0.000040): loss=1003.1401, mse=388.0594, mae=15.6658, mape=0.2528, UY-loss=488.1990, DYZ-loss=126.8816\n",
      "sim_Y0_c_ask: 683.3544 sim_U0_c_ask: 693.3629 true_Y0_c_ask: 708.5 sim_Y0_p_ask: 16.80608 sim_U0_p_ask: 16.65772 true_Y0_p_ask: 17.65 sim_Z0_c_ask: 436.0126 sim_Z0_p_ask: -7.671256\n",
      "[Train] Epoch 19 Step 11401, lr(0.000040): loss=699.2635, mse=185.8771, mae=10.0969, mape=0.1343, UY-loss=409.2379, DYZ-loss=104.1485\n",
      "[Valid] Epoch 19 Step 11401, lr(0.000040): loss=832.4964, mse=301.7897, mae=13.6673, mape=0.2498, UY-loss=411.6533, DYZ-loss=119.0534\n",
      "sim_Y0_c_ask: 123.856155 sim_U0_c_ask: 113.95502 true_Y0_c_ask: 100.69999999999999 sim_Y0_p_ask: 185.03557 sim_U0_p_ask: 181.55618 true_Y0_p_ask: 158.55 sim_Z0_c_ask: 280.61725 sim_Z0_p_ask: -303.16394\n",
      "[Train] Epoch 19 Step 11451, lr(0.000040): loss=722.0212, mse=170.1078, mae=9.4610, mape=0.1166, UY-loss=439.5198, DYZ-loss=112.3935\n",
      "[Valid] Epoch 19 Step 11451, lr(0.000040): loss=781.9471, mse=293.8962, mae=14.2670, mape=0.3061, UY-loss=372.0282, DYZ-loss=116.0228\n",
      "sim_Y0_c_ask: 329.5828 sim_U0_c_ask: 334.02036 true_Y0_c_ask: 335.65 sim_Y0_p_ask: 328.75275 sim_U0_p_ask: 353.94547 true_Y0_p_ask: 337.25 sim_Z0_c_ask: 499.58942 sim_Z0_p_ask: -177.29582\n",
      "[Train] Epoch 19 Step 11501, lr(0.000040): loss=684.3406, mse=169.2330, mae=9.8095, mape=0.1148, UY-loss=410.7402, DYZ-loss=104.3674\n",
      "[Valid] Epoch 19 Step 11501, lr(0.000040): loss=863.7979, mse=330.1153, mae=14.1991, mape=0.2432, UY-loss=421.5750, DYZ-loss=112.1076\n",
      "sim_Y0_c_ask: 179.2916 sim_U0_c_ask: 207.61148 true_Y0_c_ask: 224.15 sim_Y0_p_ask: 390.38272 sim_U0_p_ask: 402.12314 true_Y0_p_ask: 376.20000000000005 sim_Z0_c_ask: 270.1884 sim_Z0_p_ask: -191.37044\n",
      "[Train] Epoch 19 Step 11551, lr(0.000040): loss=705.9990, mse=143.9845, mae=8.8599, mape=0.1132, UY-loss=459.9828, DYZ-loss=102.0317\n",
      "[Valid] Epoch 19 Step 11551, lr(0.000040): loss=990.7515, mse=320.0120, mae=14.7800, mape=0.2230, UY-loss=537.4384, DYZ-loss=133.3012\n",
      "sim_Y0_c_ask: 1182.903 sim_U0_c_ask: 1192.0199 true_Y0_c_ask: 1189.0 sim_Y0_p_ask: 90.52075 sim_U0_p_ask: 88.65419 true_Y0_p_ask: 108.0 sim_Z0_c_ask: 502.8257 sim_Z0_p_ask: -86.012436\n",
      "[Train] Epoch 19 Step 11601, lr(0.000040): loss=632.7570, mse=156.7521, mae=9.1087, mape=0.1635, UY-loss=375.4708, DYZ-loss=100.5340\n",
      "[Valid] Epoch 19 Step 11601, lr(0.000040): loss=856.7309, mse=298.6187, mae=13.7740, mape=0.2206, UY-loss=445.1628, DYZ-loss=112.9493\n",
      "sim_Y0_c_ask: 780.23474 sim_U0_c_ask: 784.54236 true_Y0_c_ask: 776.4 sim_Y0_p_ask: 32.745384 sim_U0_p_ask: 31.59005 true_Y0_p_ask: 52.1 sim_Z0_c_ask: 547.3763 sim_Z0_p_ask: -32.132\n",
      "[Train] Epoch 19 Step 11651, lr(0.000040): loss=735.4542, mse=179.3840, mae=10.1456, mape=0.1288, UY-loss=448.7745, DYZ-loss=107.2957\n",
      "[Valid] Epoch 19 Step 11651, lr(0.000040): loss=888.5119, mse=286.5042, mae=13.4572, mape=0.2088, UY-loss=482.6990, DYZ-loss=119.3087\n",
      "sim_Y0_c_ask: 9.797152 sim_U0_c_ask: 10.194397 true_Y0_c_ask: 6.5 sim_Y0_p_ask: 200.75513 sim_U0_p_ask: 202.4765 true_Y0_p_ask: 179.3 sim_Z0_c_ask: 46.916904 sim_Z0_p_ask: -241.85068\n",
      "[Train] Epoch 19 Step 11701, lr(0.000040): loss=720.1538, mse=219.7410, mae=10.9284, mape=0.1379, UY-loss=389.1286, DYZ-loss=111.2842\n",
      "[Valid] Epoch 19 Step 11701, lr(0.000040): loss=777.7062, mse=257.2780, mae=12.7070, mape=0.2519, UY-loss=413.2913, DYZ-loss=107.1369\n",
      "sim_Y0_c_ask: 72.6221 sim_U0_c_ask: 63.645424 true_Y0_c_ask: 80.0 sim_Y0_p_ask: 1712.6201 sim_U0_p_ask: 1709.983 true_Y0_p_ask: 1713.0 sim_Z0_c_ask: 259.06906 sim_Z0_p_ask: -582.124\n",
      "[Train] Epoch 19 Step 11751, lr(0.000040): loss=616.6616, mse=170.5558, mae=9.3698, mape=0.1102, UY-loss=344.3000, DYZ-loss=101.8058\n",
      "[Valid] Epoch 19 Step 11751, lr(0.000040): loss=897.0674, mse=314.9540, mae=13.9500, mape=0.2849, UY-loss=458.2956, DYZ-loss=123.8178\n",
      "sim_Y0_c_ask: 878.89606 sim_U0_c_ask: 869.9304 true_Y0_c_ask: 870.1500000000001 sim_Y0_p_ask: 234.35965 sim_U0_p_ask: 237.03545 true_Y0_p_ask: 274.25 sim_Z0_c_ask: 526.1831 sim_Z0_p_ask: -257.75946\n",
      "[Train] Epoch 20 Step 11801, lr(0.000040): loss=731.7117, mse=198.3692, mae=10.3112, mape=0.1512, UY-loss=424.0980, DYZ-loss=109.2445\n",
      "[Valid] Epoch 20 Step 11801, lr(0.000040): loss=1006.1855, mse=365.2847, mae=15.5199, mape=0.2639, UY-loss=507.3538, DYZ-loss=133.5470\n",
      "sim_Y0_c_ask: 724.18555 sim_U0_c_ask: 724.13464 true_Y0_c_ask: 717.55 sim_Y0_p_ask: 30.507563 sim_U0_p_ask: 28.384405 true_Y0_p_ask: 28.35 sim_Z0_c_ask: 565.4604 sim_Z0_p_ask: -9.790057\n",
      "[Train] Epoch 20 Step 11851, lr(0.000040): loss=696.9449, mse=183.4808, mae=9.9638, mape=0.1659, UY-loss=410.1641, DYZ-loss=103.3000\n",
      "[Valid] Epoch 20 Step 11851, lr(0.000040): loss=887.7731, mse=329.5404, mae=14.3118, mape=0.2042, UY-loss=440.9165, DYZ-loss=117.3162\n",
      "sim_Y0_c_ask: 1375.4124 sim_U0_c_ask: 1375.4507 true_Y0_c_ask: 1366.5 sim_Y0_p_ask: 65.77669 sim_U0_p_ask: 55.226704 true_Y0_p_ask: 73.15 sim_Z0_c_ask: 581.9736 sim_Z0_p_ask: -57.613773\n",
      "[Train] Epoch 20 Step 11901, lr(0.000040): loss=805.3215, mse=200.8745, mae=10.2531, mape=0.1018, UY-loss=482.5620, DYZ-loss=121.8849\n",
      "[Valid] Epoch 20 Step 11901, lr(0.000040): loss=861.0287, mse=277.8060, mae=13.7406, mape=0.2235, UY-loss=443.8868, DYZ-loss=139.3360\n",
      "sim_Y0_c_ask: 16.224888 sim_U0_c_ask: 10.764574 true_Y0_c_ask: 15.100000000000001 sim_Y0_p_ask: 38.467384 sim_U0_p_ask: 33.01411 true_Y0_p_ask: 43.599999999999994 sim_Z0_c_ask: 29.74834 sim_Z0_p_ask: -26.747086\n",
      "[Train] Epoch 20 Step 11951, lr(0.000040): loss=702.3151, mse=191.6653, mae=10.0895, mape=0.1296, UY-loss=401.5087, DYZ-loss=109.1410\n",
      "[Valid] Epoch 20 Step 11951, lr(0.000040): loss=882.0712, mse=314.4065, mae=14.7151, mape=0.1817, UY-loss=443.3076, DYZ-loss=124.3571\n",
      "sim_Y0_c_ask: 382.9679 sim_U0_c_ask: 384.74496 true_Y0_c_ask: 394.85 sim_Y0_p_ask: 436.97543 sim_U0_p_ask: 434.07773 true_Y0_p_ask: 448.6 sim_Z0_c_ask: 441.89728 sim_Z0_p_ask: -547.9374\n",
      "[Train] Epoch 20 Step 12001, lr(0.000040): loss=673.9327, mse=165.5228, mae=10.0063, mape=0.1408, UY-loss=396.4534, DYZ-loss=111.9565\n",
      "[Valid] Epoch 20 Step 12001, lr(0.000040): loss=945.0137, mse=297.2010, mae=13.8231, mape=0.2112, UY-loss=521.6789, DYZ-loss=126.1339\n",
      "sim_Y0_c_ask: 606.52625 sim_U0_c_ask: 606.76556 true_Y0_c_ask: 625.95 sim_Y0_p_ask: 77.40571 sim_U0_p_ask: 67.74617 true_Y0_p_ask: 71.2 sim_Z0_c_ask: 474.9875 sim_Z0_p_ask: -55.6332\n",
      "[Train] Epoch 20 Step 12051, lr(0.000040): loss=687.0315, mse=213.0758, mae=10.7334, mape=0.1506, UY-loss=360.3786, DYZ-loss=113.5771\n",
      "[Valid] Epoch 20 Step 12051, lr(0.000040): loss=847.4539, mse=280.3398, mae=13.4191, mape=0.2469, UY-loss=435.0814, DYZ-loss=132.0327\n",
      "sim_Y0_c_ask: 59.538345 sim_U0_c_ask: 59.509644 true_Y0_c_ask: 47.55 sim_Y0_p_ask: 25.223429 sim_U0_p_ask: 32.320835 true_Y0_p_ask: 25.950000000000003 sim_Z0_c_ask: 198.82597 sim_Z0_p_ask: -5.556392\n",
      "[Train] Epoch 20 Step 12101, lr(0.000040): loss=723.9924, mse=190.2792, mae=9.9503, mape=0.1077, UY-loss=422.4229, DYZ-loss=111.2903\n",
      "[Valid] Epoch 20 Step 12101, lr(0.000040): loss=972.2344, mse=369.1132, mae=15.3709, mape=0.3013, UY-loss=474.3038, DYZ-loss=128.8174\n",
      "sim_Y0_c_ask: 11.022002 sim_U0_c_ask: 5.024648 true_Y0_c_ask: 8.65 sim_Y0_p_ask: 33.079247 sim_U0_p_ask: 27.580172 true_Y0_p_ask: 29.75 sim_Z0_c_ask: 35.964973 sim_Z0_p_ask: -27.430832\n",
      "[Train] Epoch 20 Step 12151, lr(0.000040): loss=792.4324, mse=228.8360, mae=10.9619, mape=0.1412, UY-loss=447.2351, DYZ-loss=116.3613\n",
      "[Valid] Epoch 20 Step 12151, lr(0.000040): loss=899.7485, mse=343.4966, mae=15.0756, mape=0.2387, UY-loss=427.4201, DYZ-loss=128.8319\n",
      "sim_Y0_c_ask: 795.0869 sim_U0_c_ask: 800.57104 true_Y0_c_ask: 792.15 sim_Y0_p_ask: 28.74311 sim_U0_p_ask: 26.433096 true_Y0_p_ask: 26.5 sim_Z0_c_ask: 545.9843 sim_Z0_p_ask: -24.529781\n",
      "[Train] Epoch 20 Step 12201, lr(0.000040): loss=669.5193, mse=146.0198, mae=8.6405, mape=0.1305, UY-loss=405.2569, DYZ-loss=118.2426\n",
      "[Valid] Epoch 20 Step 12201, lr(0.000040): loss=877.8591, mse=273.6802, mae=13.4388, mape=0.1925, UY-loss=460.8900, DYZ-loss=143.2888\n",
      "sim_Y0_c_ask: 4.3485446 sim_U0_c_ask: 1.7937943 true_Y0_c_ask: 6.0 sim_Y0_p_ask: 237.25507 sim_U0_p_ask: 233.90205 true_Y0_p_ask: 235.25 sim_Z0_c_ask: 17.674732 sim_Z0_p_ask: -146.82661\n",
      "[Train] Epoch 20 Step 12251, lr(0.000040): loss=698.6869, mse=173.4343, mae=9.3933, mape=0.4142, UY-loss=412.7870, DYZ-loss=112.4656\n",
      "[Valid] Epoch 20 Step 12251, lr(0.000040): loss=990.4755, mse=344.0507, mae=14.8200, mape=0.2338, UY-loss=512.0800, DYZ-loss=134.3448\n",
      "sim_Y0_c_ask: 81.89084 sim_U0_c_ask: 86.56046 true_Y0_c_ask: 91.65 sim_Y0_p_ask: 299.3754 sim_U0_p_ask: 318.18314 true_Y0_p_ask: 305.9 sim_Z0_c_ask: 227.2765 sim_Z0_p_ask: -159.10435\n",
      "[Train] Epoch 20 Step 12301, lr(0.000040): loss=690.3817, mse=157.9841, mae=9.2955, mape=0.1100, UY-loss=413.5192, DYZ-loss=118.8784\n",
      "[Valid] Epoch 20 Step 12301, lr(0.000040): loss=969.5558, mse=314.4789, mae=14.1742, mape=0.2347, UY-loss=519.8828, DYZ-loss=135.1941\n",
      "sim_Y0_c_ask: 59.452736 sim_U0_c_ask: 60.80336 true_Y0_c_ask: 58.95 sim_Y0_p_ask: 80.22873 sim_U0_p_ask: 80.5566 true_Y0_p_ask: 85.80000000000001 sim_Z0_c_ask: 204.65982 sim_Z0_p_ask: -77.279\n",
      "[Train] Epoch 20 Step 12351, lr(0.000040): loss=767.1165, mse=206.7705, mae=10.8197, mape=0.1184, UY-loss=442.2839, DYZ-loss=118.0622\n",
      "[Valid] Epoch 20 Step 12351, lr(0.000040): loss=963.3105, mse=359.2844, mae=15.1467, mape=0.2952, UY-loss=468.8188, DYZ-loss=135.2074\n",
      "sim_Y0_c_ask: 313.34067 sim_U0_c_ask: 316.81067 true_Y0_c_ask: 315.65 sim_Y0_p_ask: 402.3249 sim_U0_p_ask: 411.91647 true_Y0_p_ask: 425.0 sim_Z0_c_ask: 332.95712 sim_Z0_p_ask: -435.69595\n",
      "[Train] Epoch 21 Step 12401, lr(0.000040): loss=741.9896, mse=187.9408, mae=10.2154, mape=0.1336, UY-loss=431.9381, DYZ-loss=122.1107\n",
      "[Valid] Epoch 21 Step 12401, lr(0.000040): loss=829.5216, mse=276.1572, mae=12.9710, mape=0.2795, UY-loss=424.0669, DYZ-loss=129.2975\n",
      "sim_Y0_c_ask: 208.90729 sim_U0_c_ask: 209.42053 true_Y0_c_ask: 220.8 sim_Y0_p_ask: 1521.8801 sim_U0_p_ask: 1518.3079 true_Y0_p_ask: 1531.5 sim_Z0_c_ask: 494.28387 sim_Z0_p_ask: -560.8926\n",
      "[Train] Epoch 21 Step 12451, lr(0.000040): loss=685.0089, mse=178.8802, mae=9.7063, mape=0.1377, UY-loss=385.5923, DYZ-loss=120.5364\n",
      "[Valid] Epoch 21 Step 12451, lr(0.000040): loss=816.3820, mse=267.5160, mae=12.9724, mape=0.2124, UY-loss=409.7221, DYZ-loss=139.1439\n",
      "sim_Y0_c_ask: 683.8724 sim_U0_c_ask: 682.0967 true_Y0_c_ask: 685.0 sim_Y0_p_ask: 678.80994 sim_U0_p_ask: 684.21497 true_Y0_p_ask: 672.4000000000001 sim_Z0_c_ask: 510.75443 sim_Z0_p_ask: -420.61218\n",
      "[Train] Epoch 21 Step 12501, lr(0.000040): loss=696.4983, mse=151.1561, mae=9.4364, mape=0.1208, UY-loss=416.6836, DYZ-loss=128.6587\n",
      "[Valid] Epoch 21 Step 12501, lr(0.000040): loss=871.2252, mse=293.2357, mae=13.7590, mape=0.2832, UY-loss=444.3480, DYZ-loss=133.6416\n",
      "sim_Y0_c_ask: 279.38885 sim_U0_c_ask: 280.60812 true_Y0_c_ask: 297.9 sim_Y0_p_ask: 165.34369 sim_U0_p_ask: 153.465 true_Y0_p_ask: 152.8 sim_Z0_c_ask: 386.55414 sim_Z0_p_ask: -125.32037\n",
      "[Train] Epoch 21 Step 12551, lr(0.000040): loss=641.7722, mse=157.5214, mae=9.4951, mape=0.1270, UY-loss=372.3180, DYZ-loss=111.9328\n",
      "[Valid] Epoch 21 Step 12551, lr(0.000040): loss=932.5597, mse=328.0007, mae=14.3956, mape=0.2420, UY-loss=454.4691, DYZ-loss=150.0898\n",
      "sim_Y0_c_ask: 710.07477 sim_U0_c_ask: 697.46844 true_Y0_c_ask: 696.85 sim_Y0_p_ask: 431.62375 sim_U0_p_ask: 427.10574 true_Y0_p_ask: 401.3 sim_Z0_c_ask: 493.6612 sim_Z0_p_ask: -244.44904\n",
      "[Train] Epoch 21 Step 12601, lr(0.000040): loss=754.1885, mse=170.7003, mae=9.4023, mape=0.1136, UY-loss=458.1055, DYZ-loss=125.3827\n",
      "[Valid] Epoch 21 Step 12601, lr(0.000040): loss=1025.4905, mse=335.9208, mae=14.8012, mape=0.1976, UY-loss=542.5691, DYZ-loss=147.0006\n",
      "sim_Y0_c_ask: 1556.0352 sim_U0_c_ask: 1553.5082 true_Y0_c_ask: 1558.5 sim_Y0_p_ask: 322.56125 sim_U0_p_ask: 327.09488 true_Y0_p_ask: 335.25 sim_Z0_c_ask: 575.5892 sim_Z0_p_ask: -387.55264\n",
      "[Train] Epoch 21 Step 12651, lr(0.000040): loss=650.4050, mse=148.9573, mae=8.7398, mape=0.1576, UY-loss=378.4333, DYZ-loss=123.0144\n",
      "[Valid] Epoch 21 Step 12651, lr(0.000040): loss=897.1904, mse=276.3876, mae=12.9575, mape=0.2255, UY-loss=486.7211, DYZ-loss=134.0817\n",
      "sim_Y0_c_ask: 825.4639 sim_U0_c_ask: 827.0012 true_Y0_c_ask: 813.85 sim_Y0_p_ask: 191.82703 sim_U0_p_ask: 189.53586 true_Y0_p_ask: 189.75 sim_Z0_c_ask: 568.7879 sim_Z0_p_ask: -493.87958\n",
      "[Train] Epoch 21 Step 12701, lr(0.000040): loss=676.9452, mse=166.3647, mae=9.5540, mape=0.1258, UY-loss=393.2226, DYZ-loss=117.3579\n",
      "[Valid] Epoch 21 Step 12701, lr(0.000040): loss=973.3663, mse=297.1165, mae=13.5697, mape=0.1883, UY-loss=529.9895, DYZ-loss=146.2603\n",
      "sim_Y0_c_ask: 526.539 sim_U0_c_ask: 525.32794 true_Y0_c_ask: 510.7 sim_Y0_p_ask: 93.67862 sim_U0_p_ask: 87.34425 true_Y0_p_ask: 96.65 sim_Z0_c_ask: 518.77954 sim_Z0_p_ask: -131.25406\n",
      "[Train] Epoch 21 Step 12751, lr(0.000040): loss=654.6816, mse=150.5128, mae=9.0024, mape=0.1649, UY-loss=384.4106, DYZ-loss=119.7583\n",
      "[Valid] Epoch 21 Step 12751, lr(0.000040): loss=937.2375, mse=301.4998, mae=13.8874, mape=0.2379, UY-loss=493.5606, DYZ-loss=142.1772\n",
      "sim_Y0_c_ask: 11.404038 sim_U0_c_ask: 12.68775 true_Y0_c_ask: 16.0 sim_Y0_p_ask: 299.66724 sim_U0_p_ask: 308.73523 true_Y0_p_ask: 275.65 sim_Z0_c_ask: 68.20824 sim_Z0_p_ask: -304.7718\n",
      "[Train] Epoch 21 Step 12801, lr(0.000040): loss=679.8847, mse=159.9932, mae=9.5012, mape=0.1179, UY-loss=399.8943, DYZ-loss=119.9972\n",
      "[Valid] Epoch 21 Step 12801, lr(0.000040): loss=834.4728, mse=286.6976, mae=13.6856, mape=0.2039, UY-loss=407.8321, DYZ-loss=139.9432\n",
      "sim_Y0_c_ask: 294.0907 sim_U0_c_ask: 296.30756 true_Y0_c_ask: 287.2 sim_Y0_p_ask: 59.835117 sim_U0_p_ask: 54.485832 true_Y0_p_ask: 57.8 sim_Z0_c_ask: 523.88226 sim_Z0_p_ask: -114.17895\n",
      "[Train] Epoch 21 Step 12851, lr(0.000040): loss=761.3015, mse=201.5739, mae=10.0655, mape=0.1222, UY-loss=429.8413, DYZ-loss=129.8864\n",
      "[Valid] Epoch 21 Step 12851, lr(0.000040): loss=905.2965, mse=260.5880, mae=12.7372, mape=0.2139, UY-loss=499.6271, DYZ-loss=145.0813\n",
      "sim_Y0_c_ask: 178.77611 sim_U0_c_ask: 165.81758 true_Y0_c_ask: 134.05 sim_Y0_p_ask: 31.951195 sim_U0_p_ask: 32.07607 true_Y0_p_ask: 31.8 sim_Z0_c_ask: 286.6922 sim_Z0_p_ask: -9.705632\n",
      "[Train] Epoch 21 Step 12901, lr(0.000040): loss=704.9718, mse=203.3261, mae=10.7620, mape=0.1498, UY-loss=377.9514, DYZ-loss=123.6943\n",
      "[Valid] Epoch 21 Step 12901, lr(0.000040): loss=881.8133, mse=279.1905, mae=13.3102, mape=0.2267, UY-loss=453.9074, DYZ-loss=148.7154\n",
      "sim_Y0_c_ask: 355.49884 sim_U0_c_ask: 351.20337 true_Y0_c_ask: 337.54999999999995 sim_Y0_p_ask: 7.84125 sim_U0_p_ask: 6.4608736 true_Y0_p_ask: 6.25 sim_Z0_c_ask: 343.68454 sim_Z0_p_ask: -18.0196\n",
      "[Train] Epoch 21 Step 12951, lr(0.000040): loss=682.7150, mse=164.5014, mae=9.5006, mape=0.1604, UY-loss=393.1640, DYZ-loss=125.0496\n",
      "[Valid] Epoch 21 Step 12951, lr(0.000040): loss=922.4849, mse=260.0730, mae=12.9851, mape=0.2339, UY-loss=513.0493, DYZ-loss=149.3625\n",
      "sim_Y0_c_ask: 962.53455 sim_U0_c_ask: 963.4531 true_Y0_c_ask: 954.65 sim_Y0_p_ask: 114.52226 sim_U0_p_ask: 116.44617 true_Y0_p_ask: 121.44999999999999 sim_Z0_c_ask: 579.1855 sim_Z0_p_ask: -108.21999\n",
      "[Train] Epoch 22 Step 13001, lr(0.000040): loss=703.0242, mse=171.6298, mae=9.6319, mape=0.1355, UY-loss=408.3757, DYZ-loss=123.0187\n",
      "[Valid] Epoch 22 Step 13001, lr(0.000040): loss=985.7731, mse=349.0789, mae=14.8773, mape=0.1972, UY-loss=483.8096, DYZ-loss=152.8845\n",
      "sim_Y0_c_ask: 12.966789 sim_U0_c_ask: 12.348981 true_Y0_c_ask: 11.05 sim_Y0_p_ask: 121.38466 sim_U0_p_ask: 117.440445 true_Y0_p_ask: 97.35 sim_Z0_c_ask: 70.06527 sim_Z0_p_ask: -279.68256\n",
      "[Train] Epoch 22 Step 13051, lr(0.000040): loss=738.2799, mse=203.7198, mae=10.4538, mape=0.1312, UY-loss=402.5866, DYZ-loss=131.9735\n",
      "[Valid] Epoch 22 Step 13051, lr(0.000040): loss=896.6203, mse=261.2056, mae=12.9267, mape=0.2683, UY-loss=485.2074, DYZ-loss=150.2073\n",
      "sim_Y0_c_ask: 580.82117 sim_U0_c_ask: 578.92773 true_Y0_c_ask: 564.25 sim_Y0_p_ask: 17.533169 sim_U0_p_ask: 15.70089 true_Y0_p_ask: 16.950000000000003 sim_Z0_c_ask: 520.8566 sim_Z0_p_ask: -14.138826\n",
      "[Train] Epoch 22 Step 13101, lr(0.000040): loss=687.6529, mse=184.1441, mae=9.8578, mape=0.1143, UY-loss=385.7297, DYZ-loss=117.7791\n",
      "[Valid] Epoch 22 Step 13101, lr(0.000040): loss=913.4854, mse=305.6587, mae=14.0302, mape=0.2443, UY-loss=471.8647, DYZ-loss=135.9619\n",
      "sim_Y0_c_ask: 0.9291458 sim_U0_c_ask: -6.3540955 true_Y0_c_ask: 1.05 sim_Y0_p_ask: 221.38077 sim_U0_p_ask: 221.87738 true_Y0_p_ask: 225.65 sim_Z0_c_ask: 1.2524979 sim_Z0_p_ask: -509.69174\n",
      "[Train] Epoch 22 Step 13151, lr(0.000040): loss=620.4556, mse=193.7230, mae=10.4437, mape=0.2003, UY-loss=305.1743, DYZ-loss=121.5583\n",
      "[Valid] Epoch 22 Step 13151, lr(0.000040): loss=937.0953, mse=313.9755, mae=14.2428, mape=0.2062, UY-loss=480.5714, DYZ-loss=142.5485\n",
      "sim_Y0_c_ask: 105.27792 sim_U0_c_ask: 96.084236 true_Y0_c_ask: 82.85 sim_Y0_p_ask: 427.97845 sim_U0_p_ask: 426.22516 true_Y0_p_ask: 414.8 sim_Z0_c_ask: 398.83463 sim_Z0_p_ask: -240.43002\n",
      "[Train] Epoch 22 Step 13201, lr(0.000040): loss=731.9655, mse=154.3658, mae=8.8459, mape=0.1275, UY-loss=462.8564, DYZ-loss=114.7432\n",
      "[Valid] Epoch 22 Step 13201, lr(0.000040): loss=1044.4392, mse=339.0291, mae=14.6315, mape=0.2160, UY-loss=560.0433, DYZ-loss=145.3666\n",
      "sim_Y0_c_ask: 161.30234 sim_U0_c_ask: 172.73007 true_Y0_c_ask: 178.25 sim_Y0_p_ask: 521.8231 sim_U0_p_ask: 539.25665 true_Y0_p_ask: 542.0 sim_Z0_c_ask: 296.09045 sim_Z0_p_ask: -316.55588\n",
      "[Train] Epoch 22 Step 13251, lr(0.000040): loss=787.4171, mse=182.7832, mae=10.0419, mape=0.0973, UY-loss=476.6626, DYZ-loss=127.9712\n",
      "[Valid] Epoch 22 Step 13251, lr(0.000040): loss=911.4393, mse=295.0356, mae=13.1690, mape=0.1999, UY-loss=476.3051, DYZ-loss=140.0986\n",
      "sim_Y0_c_ask: 460.92612 sim_U0_c_ask: 461.20135 true_Y0_c_ask: 461.65 sim_Y0_p_ask: 52.925415 sim_U0_p_ask: 45.574757 true_Y0_p_ask: 56.05 sim_Z0_c_ask: 475.3791 sim_Z0_p_ask: -81.54919\n",
      "[Train] Epoch 22 Step 13301, lr(0.000040): loss=643.7090, mse=180.2923, mae=9.4462, mape=0.1285, UY-loss=342.7935, DYZ-loss=120.6232\n",
      "[Valid] Epoch 22 Step 13301, lr(0.000040): loss=968.2811, mse=349.9766, mae=15.0779, mape=0.2612, UY-loss=474.7183, DYZ-loss=143.5861\n",
      "sim_Y0_c_ask: 862.75244 sim_U0_c_ask: 866.5649 true_Y0_c_ask: 862.6500000000001 sim_Y0_p_ask: 69.89314 sim_U0_p_ask: 68.90379 true_Y0_p_ask: 90.3 sim_Z0_c_ask: 544.77826 sim_Z0_p_ask: -111.783844\n",
      "[Train] Epoch 22 Step 13351, lr(0.000040): loss=774.7015, mse=179.4309, mae=10.0424, mape=0.1061, UY-loss=466.4943, DYZ-loss=128.7762\n",
      "[Valid] Epoch 22 Step 13351, lr(0.000040): loss=861.4618, mse=288.9770, mae=13.6463, mape=0.2248, UY-loss=431.7915, DYZ-loss=140.6933\n",
      "sim_Y0_c_ask: 227.04416 sim_U0_c_ask: 222.88898 true_Y0_c_ask: 215.05 sim_Y0_p_ask: 364.0956 sim_U0_p_ask: 362.1201 true_Y0_p_ask: 360.8 sim_Z0_c_ask: 509.31134 sim_Z0_p_ask: -551.3552\n",
      "[Train] Epoch 22 Step 13401, lr(0.000040): loss=599.1147, mse=142.1829, mae=8.9643, mape=0.1363, UY-loss=346.3264, DYZ-loss=110.6054\n",
      "[Valid] Epoch 22 Step 13401, lr(0.000040): loss=957.5648, mse=322.2152, mae=14.6790, mape=0.2301, UY-loss=484.4191, DYZ-loss=150.9305\n",
      "sim_Y0_c_ask: 23.179144 sim_U0_c_ask: 17.93128 true_Y0_c_ask: 31.6 sim_Y0_p_ask: 110.1308 sim_U0_p_ask: 105.910774 true_Y0_p_ask: 94.25 sim_Z0_c_ask: 104.88098 sim_Z0_p_ask: -123.11303\n",
      "[Train] Epoch 22 Step 13501, lr(0.000040): loss=667.8235, mse=153.3481, mae=9.3030, mape=0.0986, UY-loss=388.0932, DYZ-loss=126.3821\n",
      "[Valid] Epoch 22 Step 13501, lr(0.000040): loss=1020.5568, mse=335.9822, mae=14.7065, mape=0.2123, UY-loss=512.9943, DYZ-loss=171.5803\n",
      "sim_Y0_c_ask: 118.73509 sim_U0_c_ask: 110.88046 true_Y0_c_ask: 132.4 sim_Y0_p_ask: 538.67334 sim_U0_p_ask: 540.7424 true_Y0_p_ask: 543.9 sim_Z0_c_ask: 259.86816 sim_Z0_p_ask: -516.40027\n",
      "[Train] Epoch 22 Step 13551, lr(0.000040): loss=594.9657, mse=170.6332, mae=9.4932, mape=0.1122, UY-loss=310.1146, DYZ-loss=114.2179\n",
      "[Valid] Epoch 22 Step 13551, lr(0.000040): loss=939.8549, mse=287.4692, mae=13.3473, mape=0.2323, UY-loss=514.7839, DYZ-loss=137.6017\n",
      "sim_Y0_c_ask: 74.49391 sim_U0_c_ask: 71.79451 true_Y0_c_ask: 59.6 sim_Y0_p_ask: 73.402985 sim_U0_p_ask: 75.33175 true_Y0_p_ask: 65.65 sim_Z0_c_ask: 382.9656 sim_Z0_p_ask: -136.08093\n",
      "[Train] Epoch 23 Step 13601, lr(0.000040): loss=680.3886, mse=157.8246, mae=9.1141, mape=0.1642, UY-loss=394.7592, DYZ-loss=127.8048\n",
      "[Valid] Epoch 23 Step 13601, lr(0.000040): loss=1073.7437, mse=346.4091, mae=14.7593, mape=0.2266, UY-loss=571.6165, DYZ-loss=155.7180\n",
      "sim_Y0_c_ask: 1059.0138 sim_U0_c_ask: 1057.2573 true_Y0_c_ask: 1054.0 sim_Y0_p_ask: 380.28934 sim_U0_p_ask: 389.8474 true_Y0_p_ask: 408.95000000000005 sim_Z0_c_ask: 583.2772 sim_Z0_p_ask: -381.29684\n",
      "[Train] Epoch 23 Step 13651, lr(0.000040): loss=635.2626, mse=186.4836, mae=10.1440, mape=0.1167, UY-loss=326.5427, DYZ-loss=122.2363\n",
      "[Valid] Epoch 23 Step 13651, lr(0.000040): loss=970.1256, mse=316.6801, mae=14.2264, mape=0.2049, UY-loss=503.8927, DYZ-loss=149.5529\n",
      "sim_Y0_c_ask: 758.17737 sim_U0_c_ask: 761.7295 true_Y0_c_ask: 764.0999999999999 sim_Y0_p_ask: 318.4695 sim_U0_p_ask: 327.27356 true_Y0_p_ask: 305.4 sim_Z0_c_ask: 516.84235 sim_Z0_p_ask: -394.83325\n",
      "[Train] Epoch 23 Step 13701, lr(0.000040): loss=707.5955, mse=150.8987, mae=9.4002, mape=0.1431, UY-loss=417.6461, DYZ-loss=139.0507\n",
      "[Valid] Epoch 23 Step 13701, lr(0.000040): loss=1003.6749, mse=321.2478, mae=13.7504, mape=0.2606, UY-loss=523.3345, DYZ-loss=159.0927\n",
      "sim_Y0_c_ask: 74.94726 sim_U0_c_ask: 75.4433 true_Y0_c_ask: 84.30000000000001 sim_Y0_p_ask: 6.368882 sim_U0_p_ask: 5.0798936 true_Y0_p_ask: 19.5 sim_Z0_c_ask: 269.18332 sim_Z0_p_ask: -9.935509\n",
      "[Train] Epoch 23 Step 13751, lr(0.000040): loss=792.7887, mse=189.1332, mae=9.8147, mape=0.2033, UY-loss=470.0110, DYZ-loss=133.6445\n",
      "[Valid] Epoch 23 Step 13751, lr(0.000040): loss=821.1890, mse=218.7051, mae=11.3538, mape=0.2334, UY-loss=463.1932, DYZ-loss=139.2907\n",
      "sim_Y0_c_ask: 649.70557 sim_U0_c_ask: 649.53394 true_Y0_c_ask: 647.0 sim_Y0_p_ask: 168.67471 sim_U0_p_ask: 149.41435 true_Y0_p_ask: 143.7 sim_Z0_c_ask: 540.81757 sim_Z0_p_ask: -106.23252\n",
      "[Train] Epoch 23 Step 13801, lr(0.000040): loss=804.6049, mse=193.4156, mae=10.5025, mape=0.1201, UY-loss=452.1334, DYZ-loss=159.0560\n",
      "[Valid] Epoch 23 Step 13801, lr(0.000040): loss=1102.4988, mse=384.8484, mae=16.0282, mape=0.2240, UY-loss=538.7796, DYZ-loss=178.8707\n",
      "sim_Y0_c_ask: 89.05817 sim_U0_c_ask: 103.34836 true_Y0_c_ask: 93.25 sim_Y0_p_ask: 87.66194 sim_U0_p_ask: 81.1288 true_Y0_p_ask: 64.44999999999999 sim_Z0_c_ask: 150.58463 sim_Z0_p_ask: -94.65788\n",
      "[Train] Epoch 23 Step 13851, lr(0.000040): loss=806.9757, mse=193.6833, mae=10.2738, mape=0.1210, UY-loss=438.8350, DYZ-loss=174.4573\n",
      "[Valid] Epoch 23 Step 13851, lr(0.000040): loss=1064.9247, mse=358.2914, mae=15.7751, mape=0.3240, UY-loss=476.5265, DYZ-loss=230.1068\n",
      "sim_Y0_c_ask: 787.06793 sim_U0_c_ask: 785.418 true_Y0_c_ask: 786.35 sim_Y0_p_ask: 151.64139 sim_U0_p_ask: 142.54704 true_Y0_p_ask: 163.45 sim_Z0_c_ask: 570.849 sim_Z0_p_ask: -107.92176\n",
      "[Train] Epoch 23 Step 13901, lr(0.000040): loss=628.4819, mse=143.5894, mae=9.1608, mape=0.2413, UY-loss=328.4194, DYZ-loss=156.4731\n",
      "[Valid] Epoch 23 Step 13901, lr(0.000040): loss=896.6861, mse=314.3005, mae=14.3407, mape=0.2357, UY-loss=382.5411, DYZ-loss=199.8445\n",
      "sim_Y0_c_ask: 417.48563 sim_U0_c_ask: 418.64258 true_Y0_c_ask: 407.8 sim_Y0_p_ask: 118.34546 sim_U0_p_ask: 108.56815 true_Y0_p_ask: 105.15 sim_Z0_c_ask: 533.4922 sim_Z0_p_ask: -80.44511\n",
      "[Train] Epoch 23 Step 13951, lr(0.000040): loss=735.4915, mse=184.6743, mae=10.0063, mape=0.1321, UY-loss=390.9092, DYZ-loss=159.9079\n",
      "[Valid] Epoch 23 Step 13951, lr(0.000040): loss=1004.4448, mse=308.2303, mae=13.8654, mape=0.2853, UY-loss=504.1714, DYZ-loss=192.0431\n",
      "sim_Y0_c_ask: 90.39438 sim_U0_c_ask: 86.71135 true_Y0_c_ask: 106.30000000000001 sim_Y0_p_ask: 692.20496 sim_U0_p_ask: 692.57336 true_Y0_p_ask: 661.8499999999999 sim_Z0_c_ask: 268.24664 sim_Z0_p_ask: -356.0886\n",
      "[Train] Epoch 23 Step 14001, lr(0.000040): loss=712.0221, mse=177.6853, mae=9.9676, mape=0.1441, UY-loss=385.0406, DYZ-loss=149.2962\n",
      "[Valid] Epoch 23 Step 14001, lr(0.000040): loss=1057.7800, mse=316.8210, mae=14.5622, mape=0.2657, UY-loss=544.0003, DYZ-loss=196.9587\n",
      "sim_Y0_c_ask: 583.35205 sim_U0_c_ask: 596.93756 true_Y0_c_ask: 596.55 sim_Y0_p_ask: 60.8491 sim_U0_p_ask: 54.922977 true_Y0_p_ask: 69.85 sim_Z0_c_ask: 419.08505 sim_Z0_p_ask: -56.307747\n",
      "[Train] Epoch 23 Step 14051, lr(0.000040): loss=704.6400, mse=169.8794, mae=9.6497, mape=0.3227, UY-loss=396.5095, DYZ-loss=138.2511\n",
      "[Valid] Epoch 23 Step 14051, lr(0.000040): loss=936.6045, mse=274.3477, mae=13.5107, mape=0.2668, UY-loss=472.4812, DYZ-loss=189.7756\n",
      "sim_Y0_c_ask: 796.52277 sim_U0_c_ask: 798.2857 true_Y0_c_ask: 795.1 sim_Y0_p_ask: 46.90455 sim_U0_p_ask: 38.226097 true_Y0_p_ask: 43.1 sim_Z0_c_ask: 556.3636 sim_Z0_p_ask: -43.9154\n",
      "[Train] Epoch 23 Step 14101, lr(0.000040): loss=764.4191, mse=185.2582, mae=10.2957, mape=0.1046, UY-loss=444.0899, DYZ-loss=135.0709\n",
      "[Valid] Epoch 23 Step 14101, lr(0.000040): loss=923.8125, mse=330.5620, mae=14.6082, mape=0.2529, UY-loss=439.8392, DYZ-loss=153.4113\n",
      "sim_Y0_c_ask: 545.373 sim_U0_c_ask: 546.08936 true_Y0_c_ask: 549.9 sim_Y0_p_ask: 50.791416 sim_U0_p_ask: 48.955154 true_Y0_p_ask: 57.3 sim_Z0_c_ask: 472.99976 sim_Z0_p_ask: -75.879906\n",
      "[Train] Epoch 23 Step 14151, lr(0.000040): loss=719.6696, mse=160.4613, mae=9.5562, mape=0.1022, UY-loss=424.6681, DYZ-loss=134.5402\n",
      "[Valid] Epoch 23 Step 14151, lr(0.000040): loss=951.0844, mse=324.0596, mae=14.3699, mape=0.2694, UY-loss=474.0800, DYZ-loss=152.9447\n",
      "sim_Y0_c_ask: 563.07043 sim_U0_c_ask: 562.2225 true_Y0_c_ask: 556.0999999999999 sim_Y0_p_ask: 264.4403 sim_U0_p_ask: 263.045 true_Y0_p_ask: 279.45 sim_Z0_c_ask: 512.2933 sim_Z0_p_ask: -156.99892\n",
      "[Train] Epoch 24 Step 14201, lr(0.000040): loss=697.3990, mse=168.8715, mae=9.7041, mape=0.1192, UY-loss=401.1814, DYZ-loss=127.3461\n",
      "[Valid] Epoch 24 Step 14201, lr(0.000040): loss=873.1500, mse=324.1646, mae=14.5876, mape=0.2694, UY-loss=404.6951, DYZ-loss=144.2904\n",
      "sim_Y0_c_ask: 518.9144 sim_U0_c_ask: 519.84937 true_Y0_c_ask: 521.45 sim_Y0_p_ask: 33.679787 sim_U0_p_ask: 24.610401 true_Y0_p_ask: 45.150000000000006 sim_Z0_c_ask: 495.02838 sim_Z0_p_ask: -27.478575\n",
      "[Train] Epoch 24 Step 14251, lr(0.000040): loss=644.9205, mse=162.0483, mae=9.2019, mape=0.1226, UY-loss=359.0786, DYZ-loss=123.7935\n",
      "[Valid] Epoch 24 Step 14251, lr(0.000040): loss=918.2391, mse=318.4643, mae=14.5680, mape=0.1969, UY-loss=464.8632, DYZ-loss=134.9117\n",
      "sim_Y0_c_ask: 762.6426 sim_U0_c_ask: 765.99854 true_Y0_c_ask: 772.85 sim_Y0_p_ask: 238.38657 sim_U0_p_ask: 244.13264 true_Y0_p_ask: 233.65 sim_Z0_c_ask: 526.2328 sim_Z0_p_ask: -326.48428\n",
      "[Train] Epoch 24 Step 14301, lr(0.000040): loss=661.5419, mse=153.6787, mae=9.1250, mape=0.1629, UY-loss=384.7683, DYZ-loss=123.0949\n",
      "[Valid] Epoch 24 Step 14301, lr(0.000040): loss=819.7178, mse=281.6531, mae=13.5659, mape=0.2187, UY-loss=391.2954, DYZ-loss=146.7693\n",
      "sim_Y0_c_ask: 796.5217 sim_U0_c_ask: 795.63306 true_Y0_c_ask: 802.7 sim_Y0_p_ask: 372.12268 sim_U0_p_ask: 376.63522 true_Y0_p_ask: 372.7 sim_Z0_c_ask: 537.43243 sim_Z0_p_ask: -544.12036\n",
      "[Train] Epoch 24 Step 14351, lr(0.000040): loss=722.6801, mse=177.7529, mae=10.1551, mape=0.2279, UY-loss=417.7529, DYZ-loss=127.1743\n",
      "[Valid] Epoch 24 Step 14351, lr(0.000040): loss=866.6108, mse=316.7077, mae=14.1535, mape=0.2798, UY-loss=416.1956, DYZ-loss=133.7077\n",
      "sim_Y0_c_ask: 1335.2075 sim_U0_c_ask: 1334.468 true_Y0_c_ask: 1332.0 sim_Y0_p_ask: 709.3805 sim_U0_p_ask: 706.9808 true_Y0_p_ask: 708.25 sim_Z0_c_ask: 579.5111 sim_Z0_p_ask: -524.61285\n",
      "[Train] Epoch 24 Step 14401, lr(0.000040): loss=743.8561, mse=164.9211, mae=9.6674, mape=0.1419, UY-loss=449.8145, DYZ-loss=129.1205\n",
      "[Valid] Epoch 24 Step 14401, lr(0.000040): loss=903.8435, mse=307.9244, mae=14.1765, mape=0.2036, UY-loss=454.3409, DYZ-loss=141.5782\n",
      "sim_Y0_c_ask: 1082.4153 sim_U0_c_ask: 1083.7067 true_Y0_c_ask: 1078.0 sim_Y0_p_ask: 240.36162 sim_U0_p_ask: 246.64742 true_Y0_p_ask: 213.89999999999998 sim_Z0_c_ask: 575.3964 sim_Z0_p_ask: -331.7283\n",
      "[Train] Epoch 24 Step 14451, lr(0.000040): loss=711.5647, mse=179.1016, mae=9.6219, mape=0.1270, UY-loss=409.7016, DYZ-loss=122.7615\n",
      "[Valid] Epoch 24 Step 14451, lr(0.000040): loss=959.0870, mse=298.1875, mae=13.7416, mape=0.1719, UY-loss=508.6662, DYZ-loss=152.2333\n",
      "sim_Y0_c_ask: 12.190661 sim_U0_c_ask: 12.651996 true_Y0_c_ask: 13.55 sim_Y0_p_ask: 212.51859 sim_U0_p_ask: 211.07462 true_Y0_p_ask: 208.14999999999998 sim_Z0_c_ask: 25.518387 sim_Z0_p_ask: -226.10596\n",
      "[Train] Epoch 24 Step 14501, lr(0.000040): loss=804.3245, mse=225.3714, mae=10.9003, mape=0.1522, UY-loss=448.9968, DYZ-loss=129.9562\n",
      "[Valid] Epoch 24 Step 14501, lr(0.000040): loss=886.0678, mse=297.7856, mae=13.4272, mape=0.2241, UY-loss=449.0189, DYZ-loss=139.2634\n",
      "sim_Y0_c_ask: 5.411657 sim_U0_c_ask: 11.42209 true_Y0_c_ask: 9.0 sim_Y0_p_ask: 43.821358 sim_U0_p_ask: 39.020042 true_Y0_p_ask: 40.5 sim_Z0_c_ask: 20.863138 sim_Z0_p_ask: -36.02249\n",
      "[Train] Epoch 24 Step 14551, lr(0.000040): loss=581.6044, mse=160.0629, mae=9.0432, mape=0.3299, UY-loss=304.8082, DYZ-loss=116.7334\n",
      "[Valid] Epoch 24 Step 14551, lr(0.000040): loss=939.4235, mse=294.3588, mae=13.6629, mape=0.2720, UY-loss=506.6464, DYZ-loss=138.4184\n",
      "sim_Y0_c_ask: 333.768 sim_U0_c_ask: 323.65973 true_Y0_c_ask: 322.7 sim_Y0_p_ask: 366.48145 sim_U0_p_ask: 366.88403 true_Y0_p_ask: 338.9 sim_Z0_c_ask: 429.17224 sim_Z0_p_ask: -408.4289\n",
      "[Train] Epoch 24 Step 14601, lr(0.000040): loss=737.8637, mse=167.7316, mae=9.6118, mape=0.1327, UY-loss=438.4582, DYZ-loss=131.6739\n",
      "[Valid] Epoch 24 Step 14601, lr(0.000040): loss=906.0245, mse=310.6299, mae=14.0638, mape=0.2548, UY-loss=451.1950, DYZ-loss=144.1995\n",
      "sim_Y0_c_ask: 165.8256 sim_U0_c_ask: 161.01707 true_Y0_c_ask: 198.05 sim_Y0_p_ask: 36.798523 sim_U0_p_ask: 32.3643 true_Y0_p_ask: 30.549999999999997 sim_Z0_c_ask: 468.99854 sim_Z0_p_ask: -36.64533\n",
      "[Train] Epoch 24 Step 14651, lr(0.000040): loss=667.7968, mse=158.3867, mae=8.7996, mape=0.1123, UY-loss=374.0079, DYZ-loss=135.4023\n",
      "[Valid] Epoch 24 Step 14651, lr(0.000040): loss=823.3809, mse=272.1198, mae=13.1291, mape=0.2240, UY-loss=415.0791, DYZ-loss=136.1820\n",
      "sim_Y0_c_ask: 520.18365 sim_U0_c_ask: 513.07886 true_Y0_c_ask: 505.05 sim_Y0_p_ask: 321.54443 sim_U0_p_ask: 325.35864 true_Y0_p_ask: 301.25 sim_Z0_c_ask: 481.40714 sim_Z0_p_ask: -363.71106\n",
      "[Train] Epoch 24 Step 14701, lr(0.000040): loss=772.4490, mse=204.7610, mae=10.6817, mape=0.1343, UY-loss=433.3152, DYZ-loss=134.3727\n",
      "[Valid] Epoch 24 Step 14701, lr(0.000040): loss=1002.4227, mse=301.2936, mae=13.3566, mape=0.2134, UY-loss=555.5416, DYZ-loss=145.5876\n",
      "sim_Y0_c_ask: 1531.0278 sim_U0_c_ask: 1539.215 true_Y0_c_ask: 1536.0 sim_Y0_p_ask: 41.02282 sim_U0_p_ask: 31.70563 true_Y0_p_ask: 37.0 sim_Z0_c_ask: 527.4229 sim_Z0_p_ask: -16.748878\n",
      "[Train] Epoch 25 Step 14751, lr(0.000040): loss=730.0088, mse=175.1551, mae=9.7873, mape=0.1132, UY-loss=406.7123, DYZ-loss=148.1414\n",
      "[Valid] Epoch 25 Step 14751, lr(0.000040): loss=1045.5803, mse=371.3326, mae=15.2904, mape=0.1888, UY-loss=525.0845, DYZ-loss=149.1634\n",
      "sim_Y0_c_ask: 453.05563 sim_U0_c_ask: 451.7813 true_Y0_c_ask: 455.1 sim_Y0_p_ask: 57.039078 sim_U0_p_ask: 41.621857 true_Y0_p_ask: 67.35 sim_Z0_c_ask: 434.7504 sim_Z0_p_ask: -30.852135\n",
      "[Train] Epoch 25 Step 14801, lr(0.000040): loss=573.2908, mse=159.9715, mae=9.5381, mape=0.1343, UY-loss=295.5836, DYZ-loss=117.7357\n",
      "[Valid] Epoch 25 Step 14801, lr(0.000040): loss=967.5672, mse=305.5000, mae=13.9102, mape=0.2435, UY-loss=500.2406, DYZ-loss=161.8266\n",
      "sim_Y0_c_ask: 331.75946 sim_U0_c_ask: 335.55603 true_Y0_c_ask: 315.15 sim_Y0_p_ask: 113.28908 sim_U0_p_ask: 114.82555 true_Y0_p_ask: 100.35 sim_Z0_c_ask: 439.7715 sim_Z0_p_ask: -117.806076\n",
      "[Train] Epoch 25 Step 14851, lr(0.000040): loss=682.5469, mse=157.5791, mae=9.4459, mape=0.1475, UY-loss=395.8313, DYZ-loss=129.1366\n",
      "[Valid] Epoch 25 Step 14851, lr(0.000040): loss=935.9406, mse=315.6581, mae=14.4399, mape=0.2585, UY-loss=457.3631, DYZ-loss=162.9194\n",
      "sim_Y0_c_ask: 27.75676 sim_U0_c_ask: 22.386675 true_Y0_c_ask: 22.15 sim_Y0_p_ask: 687.963 sim_U0_p_ask: 686.9578 true_Y0_p_ask: 688.8499999999999 sim_Z0_c_ask: 111.01904 sim_Z0_p_ask: -553.219\n",
      "[Train] Epoch 25 Step 14901, lr(0.000040): loss=718.3939, mse=150.0870, mae=8.6721, mape=0.1797, UY-loss=443.8797, DYZ-loss=124.4272\n",
      "[Valid] Epoch 25 Step 14901, lr(0.000040): loss=872.7352, mse=309.6029, mae=14.5335, mape=0.2721, UY-loss=414.8308, DYZ-loss=148.3015\n",
      "sim_Y0_c_ask: 80.64049 sim_U0_c_ask: 77.10589 true_Y0_c_ask: 114.65 sim_Y0_p_ask: 15.675943 sim_U0_p_ask: 13.870778 true_Y0_p_ask: 13.9 sim_Z0_c_ask: 286.37146 sim_Z0_p_ask: -10.191632\n",
      "[Train] Epoch 25 Step 14951, lr(0.000040): loss=629.7859, mse=168.6019, mae=9.5958, mape=0.1636, UY-loss=337.6741, DYZ-loss=123.5099\n",
      "[Valid] Epoch 25 Step 14951, lr(0.000040): loss=960.2571, mse=299.0321, mae=14.0905, mape=0.2717, UY-loss=509.9557, DYZ-loss=151.2694\n",
      "sim_Y0_c_ask: 212.57938 sim_U0_c_ask: 218.29176 true_Y0_c_ask: 217.3 sim_Y0_p_ask: 197.47556 sim_U0_p_ask: 210.80397 true_Y0_p_ask: 208.0 sim_Z0_c_ask: 446.9051 sim_Z0_p_ask: -244.7156\n",
      "[Train] Epoch 25 Step 15001, lr(0.000040): loss=718.8420, mse=179.1796, mae=10.1052, mape=0.1504, UY-loss=408.0446, DYZ-loss=131.6178\n",
      "[Valid] Epoch 25 Step 15001, lr(0.000040): loss=938.8375, mse=338.0884, mae=14.2506, mape=0.2329, UY-loss=434.4034, DYZ-loss=166.3456\n",
      "sim_Y0_c_ask: 90.710144 sim_U0_c_ask: 84.25854 true_Y0_c_ask: 81.9 sim_Y0_p_ask: 8.083225 sim_U0_p_ask: 6.046885 true_Y0_p_ask: 21.75 sim_Z0_c_ask: 252.05135 sim_Z0_p_ask: -14.672776\n",
      "[Train] Epoch 25 Step 15051, lr(0.000040): loss=646.0759, mse=153.4365, mae=9.1334, mape=0.1209, UY-loss=353.1659, DYZ-loss=139.4734\n",
      "[Valid] Epoch 25 Step 15051, lr(0.000040): loss=957.7770, mse=271.0004, mae=13.2910, mape=0.2021, UY-loss=536.6279, DYZ-loss=150.1487\n",
      "sim_Y0_c_ask: 457.25848 sim_U0_c_ask: 459.5715 true_Y0_c_ask: 468.7 sim_Y0_p_ask: 432.09906 sim_U0_p_ask: 429.43042 true_Y0_p_ask: 423.05 sim_Z0_c_ask: 504.0478 sim_Z0_p_ask: -499.78766\n",
      "[Train] Epoch 25 Step 15101, lr(0.000040): loss=695.4128, mse=196.5657, mae=10.3093, mape=0.1051, UY-loss=366.2714, DYZ-loss=132.5756\n",
      "[Valid] Epoch 25 Step 15101, lr(0.000040): loss=872.0181, mse=294.2145, mae=13.7819, mape=0.2840, UY-loss=443.6113, DYZ-loss=134.1922\n",
      "sim_Y0_c_ask: 0.32565123 sim_U0_c_ask: -3.9624164 true_Y0_c_ask: 1.275 sim_Y0_p_ask: 69.252655 sim_U0_p_ask: 66.00755 true_Y0_p_ask: 62.5 sim_Z0_c_ask: 2.6835055 sim_Z0_p_ask: -81.76299\n",
      "[Train] Epoch 25 Step 15151, lr(0.000040): loss=765.4155, mse=191.4267, mae=10.2358, mape=0.1439, UY-loss=449.9292, DYZ-loss=124.0596\n",
      "[Valid] Epoch 25 Step 15151, lr(0.000040): loss=839.8807, mse=248.8115, mae=12.5518, mape=0.2037, UY-loss=464.3443, DYZ-loss=126.7249\n",
      "sim_Y0_c_ask: 190.29558 sim_U0_c_ask: 190.50102 true_Y0_c_ask: 189.2 sim_Y0_p_ask: 27.677883 sim_U0_p_ask: 22.969193 true_Y0_p_ask: 40.75 sim_Z0_c_ask: 427.12048 sim_Z0_p_ask: -26.0099\n",
      "[Train] Epoch 25 Step 15201, lr(0.000040): loss=692.0581, mse=125.2242, mae=8.1603, mape=0.1025, UY-loss=438.8862, DYZ-loss=127.9476\n",
      "[Valid] Epoch 25 Step 15201, lr(0.000040): loss=942.5114, mse=294.8733, mae=13.6837, mape=0.2145, UY-loss=493.3129, DYZ-loss=154.3252\n",
      "sim_Y0_c_ask: 380.16595 sim_U0_c_ask: 381.3988 true_Y0_c_ask: 397.0 sim_Y0_p_ask: 342.26544 sim_U0_p_ask: 347.96698 true_Y0_p_ask: 339.8 sim_Z0_c_ask: 493.11353 sim_Z0_p_ask: -356.26312\n",
      "[Train] Epoch 25 Step 15251, lr(0.000040): loss=607.7355, mse=147.8535, mae=8.6924, mape=0.1233, UY-loss=330.3051, DYZ-loss=129.5769\n",
      "[Valid] Epoch 25 Step 15251, lr(0.000040): loss=1019.4552, mse=336.0424, mae=14.6843, mape=0.2361, UY-loss=519.6572, DYZ-loss=163.7556\n",
      "sim_Y0_c_ask: 389.7034 sim_U0_c_ask: 396.81494 true_Y0_c_ask: 385.45000000000005 sim_Y0_p_ask: 81.94604 sim_U0_p_ask: 80.77641 true_Y0_p_ask: 68.5 sim_Z0_c_ask: 363.27216 sim_Z0_p_ask: -114.732735\n",
      "[Train] Epoch 25 Step 15301, lr(0.000040): loss=713.6943, mse=169.5692, mae=9.6709, mape=0.1397, UY-loss=414.1162, DYZ-loss=130.0090\n",
      "[Valid] Epoch 25 Step 15301, lr(0.000040): loss=959.3094, mse=320.7874, mae=14.2422, mape=0.2003, UY-loss=460.8871, DYZ-loss=177.6350\n"
     ]
    }
   ],
   "source": [
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "boundaries = [5000, 10000]\n",
    "learing_rates = [4e-3, 4e-4, 4e-5]\n",
    "learing_rate = tf.train.piecewise_constant(global_step, boundaries=boundaries, values=learing_rates)\n",
    "\n",
    "train_loss = tf.train.AdamOptimizer(learing_rate).minimize(_loss, global_step=global_step)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "print(\"Ready...\")\n",
    "pretime = datetime.datetime.today()\n",
    "\n",
    "train_losses = []\n",
    "train_mapes = []\n",
    "train_mses = []\n",
    "train_maes = []\n",
    "valid_losses = []\n",
    "valid_mapes = []\n",
    "valid_mses = []\n",
    "valid_maes = []\n",
    "dtimes = []\n",
    "\n",
    "# 'tau', 'K', 'S', 'bid(C)', 'ask(C)', 'bid(P)', 'ask(P)', 'Y(C)', 'Z(C)', 'Y(P)', 'Z(P)', 'mid(C)', 'mid(P)'\n",
    "#  0.     1.   2.   3.        4.        5.        6.        7.      8.      9.      10      11        12\n",
    "train = np.array(idata_train)\n",
    "valid = np.array(idata_valid)\n",
    "\n",
    "# Training: \n",
    "print(\"Training...\")\n",
    "for epoch in range(10001): \n",
    "    \n",
    "    train_c = train.copy()\n",
    "    train_p = train.copy()\n",
    "    np.random.shuffle(train_c)\n",
    "    np.random.shuffle(train_p)\n",
    "    \n",
    "    for i in range(0, len(train), I): \n",
    "        \n",
    "        curdata_c = train_c[i:i+I, :]\n",
    "        curdata_p = train_p[i:i+I, :]\n",
    "        if (len(curdata_c) < I): \n",
    "            break\n",
    "        \n",
    "        dws = [np.random.normal(0., 1., (I,M,1)) for n in range(N)]\n",
    "        X0_c = curdata_c[:,2].reshape([I,1])\n",
    "        X0_p = curdata_p[:,2].reshape([I,1])\n",
    "        K_c = curdata_c[:,1].reshape([I,1,1])\n",
    "        K_p = curdata_p[:,1].reshape([I,1,1])\n",
    "        T_c = curdata_c[:,0].reshape([I,1,1])\n",
    "        T_p = curdata_p[:,0].reshape([I,1,1])\n",
    "        true_Y0_c_ask = curdata_c[:,11].reshape([I,1])\n",
    "        true_Y0_c_bid = curdata_c[:,11].reshape([I,1])\n",
    "        true_Y0_p_ask = curdata_p[:,12].reshape([I,1])\n",
    "        true_Y0_p_bid = curdata_p[:,12].reshape([I,1])\n",
    "        \n",
    "        feed_dict = {tensor: value \n",
    "            for value, tensor \n",
    "            in zip(dws+[X0_c,X0_p,true_Y0_c_ask,true_Y0_p_ask,K_c,K_p,T_c,T_p], \n",
    "                   _dws+[_X0_c_ask,_X0_p_ask,_true_Y0_c_ask,_true_Y0_p_ask,_K_c_ask,_K_p_ask,_T_c_ask,_T_p_ask])}\n",
    "        feed_dict[is_training] = True\n",
    "        \n",
    "        curstep, _, lr, loss, curmse, curmae, curmape, curUYloss, curDYZloss = sess.run(\n",
    "            [global_step, train_loss, learing_rate, \n",
    "             _loss, _mse, _mae, _mape, _loss_UY, _loss_DYZ], \n",
    "            feed_dict=feed_dict)\n",
    "        \n",
    "        if (curstep-1) % 50 == 0: \n",
    "            train_losses.append(loss)\n",
    "            train_mapes.append(curmape)\n",
    "            train_mses.append(curmse)\n",
    "            train_maes.append(curmae)\n",
    "            \n",
    "            # Print\n",
    "            sim_Y0_c_ask, sim_Y0_p_ask, sim_Z0_c_ask, sim_Z0_p_ask, sim_U0_c_ask, sim_U0_p_ask = sess.run(\n",
    "                [_Y0_c_ask, _Y0_p_ask, _Z0_c_ask, _Z0_p_ask, _U0_c_ask, _U0_p_ask], \n",
    "                feed_dict=feed_dict)\n",
    "            print(\"sim_Y0_c_ask:\", sim_Y0_c_ask.reshape([-1])[0], \n",
    "                  \"sim_U0_c_ask:\", sim_U0_c_ask.reshape([-1])[0], \n",
    "                  \"true_Y0_c_ask:\", true_Y0_c_ask.reshape([-1])[0], \n",
    "                  \"sim_Y0_p_ask:\", sim_Y0_p_ask.reshape([-1])[0], \n",
    "                  \"sim_U0_p_ask:\", sim_U0_p_ask.reshape([-1])[0], \n",
    "                  \"true_Y0_p_ask:\", true_Y0_p_ask.reshape([-1])[0], \n",
    "                  \"sim_Z0_c_ask:\", sim_Z0_c_ask.reshape([-1])[0], \n",
    "                  \"sim_Z0_p_ask:\", sim_Z0_p_ask.reshape([-1])[0], \n",
    "            )\n",
    "\n",
    "            print(\"[Train] Epoch %d Step %d, lr(%.6f): loss=%.4f, mse=%.4f, mae=%.4f, mape=%.4f, UY-loss=%.4f, DYZ-loss=%.4f\" % (\n",
    "                epoch, curstep, lr, loss, curmse, curmae, curmape, curUYloss, curDYZloss))\n",
    "            \n",
    "            curdata_c = valid[np.random.choice(len(valid), I), :]\n",
    "            curdata_p = valid[np.random.choice(len(valid), I), :]\n",
    "            \n",
    "            dws = [np.random.normal(0., 1., (I,M,1)) for n in range(N)]\n",
    "            X0_c = curdata_c[:,2].reshape([I,1])\n",
    "            X0_p = curdata_p[:,2].reshape([I,1])\n",
    "            K_c = curdata_c[:,1].reshape([I,1,1])\n",
    "            K_p = curdata_p[:,1].reshape([I,1,1])\n",
    "            T_c = curdata_c[:,0].reshape([I,1,1])\n",
    "            T_p = curdata_p[:,0].reshape([I,1,1])\n",
    "            true_Y0_c_ask = curdata_c[:,11].reshape([I,1])\n",
    "            true_Y0_c_bid = curdata_c[:,11].reshape([I,1])\n",
    "            true_Y0_p_ask = curdata_p[:,12].reshape([I,1])\n",
    "            true_Y0_p_bid = curdata_p[:,12].reshape([I,1])\n",
    "\n",
    "            feed_dict = {tensor: value \n",
    "                for value, tensor \n",
    "                in zip(dws+[X0_c,X0_p,true_Y0_c_ask,true_Y0_p_ask,K_c,K_p,T_c,T_p], \n",
    "                       _dws+[_X0_c_ask,_X0_p_ask,_true_Y0_c_ask,_true_Y0_p_ask,_K_c_ask,_K_p_ask,_T_c_ask,_T_p_ask])}\n",
    "            feed_dict[is_training] = True\n",
    "            loss, curmse, curmae, curmape, curUYloss, curDYZloss = sess.run(\n",
    "                [_loss, _mse, _mae, _mape, _loss_UY, _loss_DYZ], \n",
    "                feed_dict=feed_dict)\n",
    "            \n",
    "            print(\"[Valid] Epoch %d Step %d, lr(%.6f): loss=%.4f, mse=%.4f, mae=%.4f, mape=%.4f, UY-loss=%.4f, DYZ-loss=%.4f\" % (\n",
    "                epoch, curstep, lr, loss, curmse, curmae, curmape, curUYloss, curDYZloss))\n",
    "            \n",
    "            valid_losses.append(loss)\n",
    "            valid_mapes.append(curmape)\n",
    "            valid_mses.append(curmse)\n",
    "            valid_maes.append(curmae)\n",
    "            \n",
    "    if curstep > 2 * boundaries[-1] - boundaries[-2]: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-04-05 15:10:21] The model is saved to: ./gPricing-(N=16)/model\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model: \n",
    "dirpath = \"./gPricing-(N=%d)\" % N\n",
    "saver = tf.train.Saver()\n",
    "savpth = saver.save(sess, '%s/model' % dirpath)\n",
    "curtime = pd.to_datetime(\n",
    "    pd.datetime.utcnow(), utc=True).tz_convert('Asia/Shanghai')\n",
    "logs = \"[%s] The model is saved to: %s\" % (\n",
    "    curtime.strftime(\"%Y-%m-%d %H:%M:%S\"), savpth)\n",
    "print(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training results: \n",
    "traindata = pd.DataFrame(index=np.arange(0,len(train_losses)*50,50))\n",
    "traindata[\"train_losses\"] = train_losses\n",
    "traindata[\"train_mapes\"] = train_mapes\n",
    "traindata[\"train_mses\"] = train_mses\n",
    "traindata[\"train_maes\"] = train_maes\n",
    "traindata[\"valid_losses\"] = valid_losses\n",
    "traindata[\"valid_mapes\"] = valid_mapes\n",
    "traindata[\"valid_mses\"] = valid_mses\n",
    "traindata[\"valid_maes\"] = valid_maes\n",
    "traindata.to_csv(\"%s/Training-STATS-BS-(N=%d).csv\"%(dirpath,N), encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x259.2 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss\n",
    "fig = plt.figure(figsize=[6,3.6])\n",
    "plt.plot(traindata[\"train_losses\"][0::1], label=r\"Training Loss\", \n",
    "         alpha=0.7, linewidth=0.6, marker=\"+\", markersize=4, linestyle=\"-\")\n",
    "plt.plot(traindata[\"valid_losses\"][0::1], label=r\"Validation Loss\", \n",
    "         alpha=0.7, linewidth=0.6, marker=\"x\", markersize=4, linestyle=\"--\") \n",
    "plt.ylim([0, 10000])\n",
    "# plt.xlim([0,40000])\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(r\"[$g$-pricing] Training & Validation Loss ($N=%d$)\"%N)\n",
    "plt.legend()\n",
    "plt.grid(linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"%s/fig-loss-gprice-(N=%d).pdf\"%(dirpath,N), format=\"pdf\", bbox_inches='tight', pad_inches=0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
